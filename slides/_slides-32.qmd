---
title: "Single cell RNA-Seq:"
subtitle: "Clustering, Dimensionality reduction, and cell-type annotation"
author: "Kristen Wells"
---

```{r}
#| label: packages
#| echo: false
#| include: false
#| message: false
#| warning: false

library(here)
library(ggplot2)
library(DiagrammeR)
library(SingleCellExperiment)
library(scater)
library(scran)
library(AnnotationHub)
library(Matrix)
library(cowplot)
```


## Contact Info

Greetings experimentalist humans `r emo::ji("wave")`

<i class="fa fa-envelope"></i> &nbsp; [kristen.wells-wrasman@cuanschutz.edu](mailto:kristen.wells-wrasman@cuanschutz.edu) <br>

RBI Informatics Fellows [Office hours](https://medschool.cuanschutz.edu/rbi/training-and-education/rbi-office-hours)

<i class="fa fa-envelope"></i> &nbsp; [rbi.fellows@cuanschutz.edu](mailto:rbi.fellows@cuanschutz.edu)
<br>


## Learning Objectives

:::: {.columns}

::: {.column .nonincremental}
### Lecture 1
- Identify key quality control issues with single cell RNA-seq data and perform filtering onto exclude poor quality cells
- Interact with single cell data using Bioconductor

:::

::: {.column .nonincremental}
### Lecture 2
- Perform analysis to identify cell types in single cell data by using unsupervised clustering methods and comparing to public datasets
- Describe the importance and reasoning for conducting each step of the analysis

:::

::::


## Learning key
* We will switch between lecture and your exercise `qmd`.
* To denote a slide that corresponds to your exercise, I will include `r emo::ji("keyboard")` in the slide title

## Analysis steps revisited {.smaller}

:::: {.columns}

::: {.column width="50%}

```{r}
#| echo: false
#| out-height: '70%'
#| out-width: '70%'

library(DiagrammeR)
grViz("
digraph workflow {
  graph [layout = dot,
         rankdir = TD]

  node [shape = cicle,
        style = filled,
        fontcolor = black,
        fontname = 'Helvetica']

  # green
  node [fillcolor = '#009E73']
  load [label= 'Import data\ntximport::tximport()\nSingleCellExperiment()\ncounts()']

  # blue
  node [fillcolor = '#56B4E9']
  cell_qc [label = 'QC cells\n addPerCellQCMetrics()\n plotColData()']
  norm [label = 'Normalize UMI counts\nquickCluster()\n computeSumFactors()\n logNormCounts()']

  # yellow
  node [fillcolor = '#F0E442']
  feature [label = 'Identify variable genes\nmodelGeneVarByPoisson()\n getTopHVGs()']
  dim_red [label = 'Dimensionality reduction via PCA \n runPCA()']
  cluster [label = 'Clustering\n clusterCells()']
  viz [label = 'Make 2D-Visualization\nrunUMAP()']

  # blue
  node [fillcolor = '#56B4E9']

  markers [label = 'Discover cell type markers \nscoreMarkers()']
  annot [label = 'Annotate cell types\nclustifyr and SingleR']

  edge [color = black
        fontname = 'Helvetica']

  load -> cell_qc
  cell_qc -> norm
  norm -> feature
  norm -> markers
  feature -> dim_red
  dim_red -> cluster
  dim_red -> viz
  cluster -> markers
  markers -> annot

  edge [color = 'grey'
        style = 'dashed']
  annot -> cell_qc [label = 'Repeat\n as needed']
  annot -> feature
  annot -> dim_red
  annot -> cluster
}")
```

:::

::: {.column width="50%}

- Normalize and log transform UMI counts to correct for sequencing depth.

- Select genes with high variance to use for clustering and UMAP generation

- Use PCA to reduce the size of the dataset to ~20-50 dimensions

- Use UMAP or tSNE to further reduce the PCA matrix into 2D for visualization

- Use clustering on PCA matrix to identify clusters of related cells.

- Find marker genes that are specifically expressed in each cluster.

- Compare the gene expression profile of each cluster to public data to help annotate the cell type.

:::

::::


# TL;DR `r emo::ji("keyboard")`

```r
# normalize data
clusters <- quickCluster(sce)
sce <- computeSumFactors(sce, clusters=clusters)
sce <- logNormCounts(sce)

# get variable genes
dec <- modelGeneVarByPoisson(sce)
top <- getTopHVGs(dec, prop=0.1)

# get PCA and UMAP
sce <- runPCA(sce, subset_row = top)
sce <- runUMAP(sce, dimred = "PCA")

# cluster cells
sce$clusters <- clusterCells(sce, use.dimred = "PCA")

# get marker genes
mrks <- scoreMarkers(sce, sce$clusters)

...
```

## Rerun steps from previous class `r emo::ji("keyboard")`


```{r}
#| label: prep-sce
#| warning: false
#| message: false
#| echo: true

# load data
library(tximport)
tx <- tximport(
  here("data/block-rna/scrna/pbmc/alevin/quants_mat.gz"),
  type = "alevin"
)

# setup gene ids
sce <- SingleCellExperiment(list(counts = tx$counts))
ah <- AnnotationHub()
ens_db <- ah[["AH113665"]]

gene_names <- mapIds(ens_db,
  keys = rownames(sce),
  keytype = "GENEID",
  column = "SYMBOL"
)

rowData(sce)$gene <- gene_names
rowData(sce)$gene_id <- rownames(sce)
rownames(sce) <- uniquifyFeatureNames(
  rowData(sce)$gene_id,
  rowData(sce)$gene
)

# drop non/low expressed genes
rowData(sce)$n_cells <- rowSums(counts(sce) > 0)
sce <- sce[rowData(sce)$n_cells >= 10, ]

# basic QC
is_mito <- startsWith(rowData(sce)$gene, "MT-")
sce <- addPerCellQCMetrics(sce, subsets = list(Mito = is_mito))
sce$pass_qc <- sce$subsets_Mito_percent < 20 & sce$sum > 1000 & sce$detected > 500
sce <- sce[, sce$pass_qc]
```


## Normalization refresher `r emo::ji("keyboard")`  {.smaller}

`quickCluster()`: Crude clustering to group related cells into groups with similar expression profiles

`computeSumFactors()`: Pool counts across clusters to establish an average cell profile for each cluster. Then use deconvolution to estimate a cell-specific scaling factor for
normalization

`logNormCounts()`: Apply scaling factors (size factors) to counts and log transform
with a pseudocount.

```{r}
#| warning: false
#| echo: true

set.seed(20231023)
clusters <- quickCluster(sce)
sce <- computeSumFactors(sce, clusters = clusters)
sce <- logNormCounts(sce)

logcounts(sce)[50:60, 1:4]
```


## Variable gene selection {.smaller}

- Genes that have high variance across cells are genes that tend to be differentially expressed between cell types

- Low variance genes are usually low-expressed or "house-keeping" genes whose expression will not help us distinguish between cell populations

- Including these genes could potentially introduce more technical variation rather then helpful biological variation.

- Keeping uninteresting genes will increase the computational burden and likely either not improve or be deleterious to the clustering.

## Variable gene selection `r emo::ji("keyboard")` {.smaller}

`modelGeneVarByPoisson()`: Fit curve, using Poisson distribution, to variance against the mean expression distribution. Estimate technical (Poisson estimate) and biological (the residuals from the Poisson) variance for each gene.

`getTopHVGs()`: Filter output from `modelGeneVarByPoisson` to select top variable genes. Use `prop` to identify the proportion of genes to call highly variable or `n` to identify a number. Often starting between 1000-2000 is best.

```{r}
?getTopHVGs
```

## Variable gene selection `r emo::ji("keyboard")` {.smaller}

`modelGeneVarByPoisson()`: Fit curve, using Poisson distribution, to variance against the mean expression distribution. Estimate technical (Poisson estimate) and biological (the residuals from the Poisson) variance for each gene.

`getTopHVGs()`: Filter output from `modelGeneVarByPoisson` to select top variable genes. Use `prop` to identify the proportion of genes to call highly variable or `n` to identify a number. Often starting between 1000-2000 is best.

```{r}
#| echo: true

set.seed(00010101)
dec <- modelGeneVarByPoisson(sce)
top <- getTopHVGs(dec, prop = 0.1)
top[1:4]
```

## Variable gene selection `r emo::ji("keyboard")`  {.smaller}
We can plot mean expression against variance to see the trend and visualize the top variable genes. These are often marker genes of specific cell populations.

```{r}
#| fig-width: 9
#| fig-height: 9
#| echo: true
#| fig.alt: "Description of the plot - PLEASE FILL IN"

top_genes <- as.data.frame(dec[top[1:10], ])
top_genes$genes <- rownames(top_genes)

ggplot(as.data.frame(dec), aes(mean, total)) +
  geom_point() +
  geom_text(
    data = top_genes,
    aes(label = genes)
  ) +
  stat_function(
    fun = function(x) metadata(dec)$trend(x),
    linetype = "dashed",
    colour = "blue"
  )
```

## Variable gene selection {.smaller}

```r
dec <- modelGeneVarByPoisson(sce)
top <- getTopHVGs(dec, prop = 0.1)
```

```{r}
#| fig-width: 9
#| fig-height: 9
#| echo: true
#| fig.alt: "Description of the plot - PLEASE FILL IN"

dec_df <- as.data.frame(dec)
dec_df$genes <- rownames(dec_df)
dec_df$variable_gene <- dec_df$genes %in% top

ggplot(dec_df, aes(mean, total)) +
  geom_point(aes(color = variable_gene),
    size = 0.75
  ) +
  stat_function(
    fun = function(x) metadata(dec)$trend(x),
    linetype = "dashed",
    colour = "blue"
  )
```


## Dimensionality reduction {.smaller}


Dimensionality reduction is the concept of transforming high dimensional data and representing it with a smaller set of dimensions.

We can reduce the # of dimensions without loosing much information because many features (genes) are highly correlated which can be approximated with fewer dimensions.

This is analogous to reducing the gene expression data into a set of metagenes that represents the expression of many correlated genes.

Using fewer dimensions makes computation much quicker and as we will see will reorder the data in a manner that still captures the heterogeneity in the data.

## Dimensionality reduction via PCA {.smaller}

We will use PCA to reduce the dimensionality of the data from 20,000 genes to ~10-50 principle components.

[PCA](http://setosa.io/ev/principal-component-analysis/) takes a matrix of features (genes) and samples (cells) and transforms the matrix into a new set of features known as a principal components. A principal component is a linear combination of the original genes that is oriented to capture variance in the dataset.

`PC1` is a vector through the dataset oriented in a direction that spans the most variation in the data.  The second component is another linear combination of the original variables but is uncorrelated to the first component (points in an orthogonal direction).

In a geometric sense, PCA produces a new coordinate system whereby instead of the axes being each gene, the axes are each a PC and the first axis points through the largest spread in the data.

## PCA in 2 dimensions {.smaller}

In this two dimensional space, PCA minimizes the distances from a line and every point in the x and y direction (think of a regression line). For a great walk through of how PCA works, see [section 7.3 in Modern Statistics for Modern Biology](https://web.stanford.edu/class/bios221/book/07-chap.html#dimension-reduction)

```{r}
#| label: pca-intro
#| echo: false
#| message: false
#| fig.alt: "Description of the plot - PLEASE FILL IN"
library(MASS)
library(ggrepel)
library(dplyr)
# generate some correlated variables, scale, and make tidy
set.seed(42)
sim <- MASS::mvrnorm(
  100,
  c(0, 0),
  matrix(
    c(1, 0.95, 0.95, 1),
    2,
    2
  )
) %>%
  scale() %>%
  as.data.frame() %>%
  tibble::rownames_to_column("id") %>%
  arrange(V1, V2) %>%
  rename(gene_1 = V1, gene_2 = V2) %>%
  as_tibble() %>%
  mutate(id = row_number())

# select points to label for visualization
max_min_points <- slice(sim, c(1:5, 95:100))

# make a plot
og_plt <- ggplot(sim, aes(gene_1, gene_2)) +
  geom_point() +
  geom_text_repel(
    data = max_min_points,
    aes(label = id)
  ) +
  # scale y axis to same as x
  ylim(
    min(sim$gene_1),
    max(sim$gene_2)
  )

# run pca
pc <- prcomp(sim[, c(2:3)],
  center = FALSE,
  scale. = FALSE
)

# function to make a pretty labeled plot
plot_labeled_pca <- function(input_data,
                             pca_obj) {
  # tidy the pc matrix
  pc_x <- pca_obj$x %>%
    as.data.frame() %>%
    mutate(id = input_data$id)

  # select points to label
  max_min_points <- slice(pc_x, c(1:5, 95:100))
  # compute variance explained
  percent_var <- (100 * pca_obj$sdev^2 /
    sum(pca_obj$sdev^2)) %>%
    signif(3)
  # plot the data
  pca_plt <- ggplot(pc_x, aes(PC1, PC2)) +
    geom_point() +
    geom_text_repel(
      data = max_min_points,
      aes(label = id)
    ) +
    labs(
      x = paste("PC1 ", percent_var[1], "%"),
      y = paste("PC2 ", percent_var[2], "%")
    ) +
    # make axes symmetric
    ylim(c(
      min(pc_x$PC1),
      max(pc_x$PC1)
    ))

  pca_plt
}

pca_plt <- plot_labeled_pca(sim, pc)

plot_grid(og_plt, pca_plt)
```

## PCA with more dimensions {.smaller}
* If we add more dimensions, we now need to fit this line in a much higher dimensional space while still minimizing the distance of each point from the line.
* We end up with the same number of PCs as the number of our initial dimensions
  * In our 2-D example, we get two PCs
  * Adding more genes increases the number of PCs.

What if we had more dimensions that are uninteresting variance/noise? How does this impact the PCA?

```{r}
#| echo: false

# generate a matrix of random numbers
# drawn from a normal dist. to simulate noise
set.seed(20181214)
more_genes <- matrix(
  rnorm(1000,
    mean = 0,
    sd = 0.25
  ),
  nrow = 100,
  ncol = 10
)
# add column names
colnames(more_genes) <- paste0(
  "gene_noise_",
  1:ncol(more_genes)
)
# add the matrix to the simulation data_frame by column
sim_2 <- cbind(sim, more_genes)
sim_2[1:5, 2:6]
```

```{r}
#| fig.height: 7
#| fig.width: 7
#| echo: false
plot(sim_2[, 2:7])
```


## PCA as dimensional reduction {.smaller}
* PC 1 and PC 2 capture less of the total variance (from capturing 100% of the variance to capturing about 80% of the variance)
* Additionally, the points are spread more and differently because the distance had to be minimized in a higher dimensional space
* However adding random noise does not dramatically change PC1 and PC2

```{r}
#| echo: false
#| fig.alt: "Description of the plot - PLEASE FILL IN"
pc2 <- prcomp(sim_2[, 2:ncol(sim_2)],
  center = FALSE,
  scale. = FALSE
)

pca_plt <- pca_plt + labs(subtitle = "2 correlated dimensions")
pc2_plt <- plot_labeled_pca(sim_2, pc2) + labs(subtitle = "2 correlated dimensions, 10 noise dimensions")
plot_grid(pca_plt, pc2_plt)
```


## computing PCA with scater `r emo::ji("keyboard")` {.smaller}

`runPCA()`: computes an approximate truncated PCA, returning 50 PCs by default.

`reducedDim(sce, "PCA")`: function to access or assign reduced dimensionality results

`plotPCA()`: plot 2 or more PC components

`plotReducedDim()`: plot 2 or more dimensions or arbitrary `reducedDim()` matrix


```{r}
#| fig.width: 9
#| fig.height: 9
#| echo: true

set.seed(101010011) # runPCA uses a specialize form of PCA that has a random component
sce <- runPCA(sce, subset_row = top)
plotPCA(sce, color_by = "CD3D")
```

## computing PCA with scater `r emo::ji("keyboard")` {.smaller}

`runPCA()`: computes an approximate truncated PCA, returning 50 PCs by default.

`reducedDim(sce, "PCA")`: function to access or assign reduced dimensionality results

`plotPCA()`: plot 2 or more PC components

`plotReducedDim()`: plot 2 or more dimensions or arbitrary `reducedDim()` matrix


```{r}
#| fig.width: 9
#| fig.height: 9
#| echo: true

plotPCA(sce, ncomponents = 4, colour_by = "CD3D")
```

## How many PCs to retain? `r emo::ji("keyboard")` {.smaller}
* In general the # of PCs to use for downstream steps depends on the complexity and heterogeneity in the data, as well as the biological question. For this analysis we will retain the top 30, but you should explore how the downstream steps are affected by including fewer or more PCs.

* In practice picking fewer PCs will identify fewer subpopulations, and picking more PCs will find more subpopulations, at the expense of potentially increased noise and longer runtime.

```{r}
#| echo: true
#| fig.width: 9
#| fig.height: 9
percent.var <- attr(reducedDim(sce), "percentVar")
plot(percent.var, log = "y", xlab = "PC", ylab = "Variance explained (%)", pch = 16)
```

## How is PCA data stored? `r emo::ji("keyboard")`

```{r}
#| echo: true

reducedDim(sce, "PCA")[1:4, 1:4] # the PCA is stored in the reducedDim() slot

# we can subset the PCA to fewer dimensions, e.g. 30
reducedDim(sce, "PCA") <- reducedDim(sce, "PCA")[, 1:30]
```

## Which dimensional reduction to use {.smaller}
:::: {.columns}

::: {.column}

### PCA
* Used by early studies (and bulk methods)
* In bulk studies, we expect to have a large amount of variation captured by PC1 (>50%)
* Best for small and simple data sets
* In large single cell studies lots of information is present at the higher principal components

:::

::: {.column}

### UMAP
* Popular in current single cell studies
* Does a good job of preserving local differences between cells while balancing global differences

:::

::::

## Projecting PCs into 2 dimensions (UMAP, tSNE, etc.) `r emo::ji("keyboard")`  {.smaller}


Non-linear dimensionallty reductions are commonly used to project the PCA matrix into 2 dimensions for visualization

This entails trying to reduce the ~10-50 PCA dimensions into a 2 dimensional space.

To do this the algorithm performs non-linear transformations that distort the true distances between cells

Attempts to balance global and local differences to produce visualization that capture variation in data.

`runUMAP()` and `runTSNE()`


```{r}
#| echo: true

set.seed(1234323523)
sce <- runUMAP(sce, dimred = "PCA")
reducedDims(sce)
```

## Plotting the UMAP `r emo::ji("keyboard")`
```{r}
#| echo: true
#| fig.width: 9
#| fig.height: 9
plotUMAP(sce)
```

## Plotting the UMAP `r emo::ji("keyboard")`
We can also color by any gene expression
```{r}
#| echo: true
#| fig.width: 9
#| fig.height: 9
plotUMAP(sce, colour_by = "CD3D")
```

## Plotting the UMAP `r emo::ji("keyboard")`
```{r}
#| echo: true
#| fig.width: 9
#| fig.height: 9
plotUMAP(sce, colour_by = "CD79A")
```

## Parameters affect the visualization  {.smaller}


:::: {.columns}

::: {.column}

```{r}
set.seed(101010101)
plotUMAP(sce) + ggtitle("spread = 1, min_dist = 0.01") +
  theme(plot.title = element_text(size = 22))
```
:::

::: {.column}

```{r}
set.seed(101010101)
sce <- runUMAP(sce, dimred = "PCA", spread = 2)
plotUMAP(sce) + ggtitle("spread = 2, min_dist = 0.01") +
  theme(plot.title = element_text(size = 22))
```

:::


::: {.column}

```{r}
set.seed(101010101)
sce <- runUMAP(sce, dimred = "PCA", spread = 1, min_dist = 0.5)
plotUMAP(sce) + ggtitle("spread = 1, min_dist = 0.5") +
  theme(plot.title = element_text(size = 22))
```

:::

::: {.column}

```{r}
set.seed(101010101)
sce <- runUMAP(sce, dimred = "PCA", spread = 1, min_dist = 0.01, n_neighbors = 3)
plotUMAP(sce) + ggtitle("spread = 1, min_dist = 0.5, k =3") +
  theme(plot.title = element_text(size = 22))
```

:::
::::


## Clustering {.smaller}

We use clustering to assign cells to discrete cell populations. This is a simplification of the true complexity of the underlying data.

Clustering is a data analysis tool rather than a result. We can increase, decrease, merge, or subset clusters at our whim by changing clustering parameters, the # of PCs used, the # of variable genes, and the particular cell subsets analyzed.

There is no correct or valid number of clusters. It depends on what biological question you are trying to explore and at what granularity you want to ask the question.

>[A]sking for an unqualified “best” clustering is akin to asking for the best magnification on a microscope without any context - OSCA book


## Graph based clustering {.smaller .nonincremental}

Approach:

- identify the K nearest neighbors of each cell in the PCA matrix (e.g. k = 10)
- weight the connection between cells based on "connectivity" of shared nearest neighbors (total number, proportion, average rank of neighbors, etc.)
- apply a community detection algorithm to cluster the shared nearest neighbor graph (walktrap, louvain, leiden, etc.)
- `clusterCells()`


```{r}
#| label: clustering
#| echo: false
#| fig.width: 12
#| fig.height: 12
#| message: false
library(igraph)
snn_clusters <- clusterCells(sce,
  use.dimred = "PCA",
  full = TRUE
)
sce$clusters <- snn_clusters$clusters
v_size <- 1

# use snn graph for the layout
set.seed(11000)
lo <- layout_with_fr(snn_clusters$objects$graph)

col_pal <- scater:::.get_palette("tableau20")
snn_graph <- snn_clusters$objects$graph
V(snn_graph)$color <- col_pal[as.integer(sce$clusters)]
plot.igraph(snn_graph,
  layout = lo,
  edge.width = E(snn_clusters$objects$graph)$weight * 0.01,
  vertex.label = NA,
  vertex.size = v_size,
  vertex.frame.color = NA
)
```

## Clustering `r emo::ji("keyboard")` {.smaller}
**Note that the clustering is performed on the PCA matrix not the 2D UMAP plot**

```{r}
#| echo: true
set.seed(10101010)
clusters <- clusterCells(sce, use.dimred = "PCA")
sce$clusters <- clusters
table(clusters)
```

## Clustering `r emo::ji("keyboard")` {.smaller}

The parameters of the clustering can be changed by changing the `NNGraphParam`. Here are the defaults:

```{r}
#| echo: true
#| fig.width: 9
#| fig.height: 9
#| message: false

library(bluster)
set.seed(10101010)
clusters <- clusterCells(sce,
  use.dimred = "PCA",
  BLUSPARAM = NNGraphParam(
    k = 10,
    type = "rank",
    cluster.fun = "walktrap"
  )
)
table(clusters)
```

## Clustering `r emo::ji("keyboard")` {.smaller}

The parameters of the clustering can be changed by changing the `NNGraphParam`. Here are the defaults:

```r
library(bluster)
set.seed(10101010)
clusters <- clusterCells(sce,
  use.dimred = "PCA",
  BLUSPARAM = NNGraphParam(
    k = 10,
    type = "rank",
    cluster.fun = "walktrap"
  )
)
table(clusters)
```

## Clustering `r emo::ji("keyboard")` {.smaller}


```{r}
#| echo: true
#| fig.width: 9
#| fig.height: 9
sce$clusters <- clusters

color_palette <- colorRampPalette(
  colors = RColorBrewer::brewer.pal(n = 9, name = "Set1")
)(length(unique(clusters)))
```

## Clustering `r emo::ji("keyboard")` {.smaller}

```{r}
plotUMAP(sce, colour_by = "clusters") +
  ggplot2::scale_color_manual(values = color_palette)
```

## Clustering `r emo::ji("keyboard")` {.smaller}

Generally increasing the # of neighbors will decrease the number of clusters and vice versa.

```{r}
#| echo: true
#| fig.width: 9
#| fig.height: 9
set.seed(12121212)

clusters <- clusterCells(sce,
  use.dimred = "PCA",
  BLUSPARAM = NNGraphParam(
    k = 100,
    type = "rank",
    cluster.fun = "walktrap"
  )
)

sce$coarse_clusters <- clusters

color_palette2 <- colorRampPalette(
  colors = RColorBrewer::brewer.pal(n = 9, name = "Set1")
)(length(unique(clusters)))
```

## Clustering `r emo::ji("keyboard")` {.smaller}

```{r}
plotUMAP(sce, colour_by = "coarse_clusters") +
  ggplot2::scale_color_manual(values = color_palette2)
```

## Clustering `r emo::ji("keyboard")` {.smaller}

What clusters are the genes S100A8, CD79A and CD3G most highly expressed in? We can use the `plotExpression()` function to visualize the expression data in each cluster.


```{r}
#| echo: true
#| fig.width: 9
#| fig.height: 6
plotExpression(sce,
  features = c("S100A8", "CD79A", "CD3G"), x = "clusters",
  color_by = "clusters"
) +
  ggplot2::scale_color_manual(values = color_palette)
```

## How many clusters? {.smaller}
Clustering algorithms produce clusters, even if there isn’t anything meaningfully different between cells. Determining the optimal number of clusters can be tricky and also dependent on the biological question.

Some guidelines:

1) Cluster the data into a small number of clusters to identify cell types, then recluster to generate additional clusters to define sub-populations of cell types.

2) To determine if the data is overclustered examine differentially expressed genes between clusters. If the clusters have few or no differentially expressed genes then the data is likely overclustered. Similar clusters can be merged post-hoc if necessary as sometimes it is difficult to use 1 clustering approach for many diverse cell populations. Using a reference-based approach to name cell types will also often merge similar clusters.

3) A hybrid approach is to first annotate major cell types using a small # of clusters (e.g. B-cell, T-cell, Myeloid, etc.), then subset the SingleCellExperiment object for each cluster and perform additional clustering to obtain 'subclusters' (e.g. b-cell-subset 1, b-cell-subset 2, t-cell-subset-1, etc.)

## Identifying marker genes using scoreMarkers() {.smaller}
Clustering algorithms produce clusters, even if there isn’t anything meaningfully different between cells. Determining the optimal number of clusters can be tricky and also dependent on the biological question.

Some guidelines:

1) Cluster the data into a small number of clusters to identify cell types, then recluster to generate additional clusters to define sub-populations of cell types.

2) To determine if the data is overclustered examine differentially expressed genes between clusters. If the clusters have few or no differentially expressed genes then the data is likely overclustered. Similar clusters can be merged post-hoc if necessary as sometimes it is difficult to use 1 clustering approach for many diverse cell populations. Using a reference-based approach to name cell types will also often merge similar clusters.

3) A hybrid approach is to first annotate major cell types using a small # of clusters (e.g. B-cell, T-cell, Myeloid, etc.), then subset the SingleCellExperiment object for each cluster and perform additional clustering to obtain 'subclusters' (e.g. b-cell-subset 1, b-cell-subset 2, t-cell-subset-1, etc.)

## Identifying marker genes using scoreMarkers()  `r emo::ji("keyboard")` {.smaller}

```{r}
#| echo: true
mrks <- scoreMarkers(sce, sce$clusters)
mrks
```

## How do we identify marker genes? `r emo::ji("keyboard")` {.smaller}
To identify marker genes we will need to decide of cutoffs based on effect sizes. There are many reported by scoreMarkers().

```{r}
#| echo: true

colnames(mrks[[1]])
```

## How do we identify marker genes? {.smaller}
What is a marker gene?
* Differentially expressed between cluster 1 and all others?
  * This could be too strict, what if the same gene marks clusters 1-8 but not 9? We would miss that as a marker
* Differentially expressed between some or any pairwise clusters

The output of scoreMarkers() allows you to filter the data in many different ways depending on what type of marker you want to identify. Importantly it doesn't hide the complexity of this data. I highly recommend reading the chapter on [marker gene detection](https://bioconductor.org/books/3.17/OSCA.basic/marker-detection.html#motivation-2) from the OSCA book to understand how best to identify markers depending on the dataset you are analyzing.

## How do we identify marker genes? {.smaller}
* We will use `AUC` to rank markers
  * Probability that a randomly chosen observation from our cluster of interest is greater than a randomly chosen obsevation from the other cluster
  * Value of 1 = upregulated in the cluster of interest, 0 = downregulated, 0.5 = no difference.
* Other ranking options include log fold change or fold change in the detection rate
* Can chose `mean`, `min`, `median`, `max`, or `rank` for potential ranking

Paraphrasing from the OSCA book:
* The most obvious summary statistic is the mean. For cluster X, a large mean effect size (>0.5 for the AUCs) indicates that the gene is upregulated in X compared to the average of the other groups.
* Another summary statistic is the median, where a large value indicates that the gene is upregulated in  X compared to most (>50%) other clusters.
* The minimum value (min.*) is the most stringent summary for identifying upregulated genes, as a large value indicates that the gene is upregulated in X compared to all other clusters.
* The maximum value (max.*) is the least stringent summary for identifying upregulated genes, as a large value can be obtained if there is strong upregulation in X compared to any other cluster.
*  The minimum rank, a.k.a., “min-rank” (rank.*) is the smallest rank of each gene across all pairwise comparisons. Specifically, genes are ranked within each pairwise comparison based on decreasing effect size, and then the smallest rank across all comparisons is reported for each gene. If a gene has a small min-rank, we can conclude that it is one of the top upregulated genes in at least one comparison of  X to another cluster.

## Cluster 1 genes `r emo::ji("keyboard")` {.smaller}
Plotting top genes ranked by `mean.AUC` for cluster 1.

```{r}
#| echo: true
#| fig.width: 9
#| fig.height: 6
cluster1_markers <- as.data.frame(mrks[[1]]) |> tibble::rownames_to_column("gene")

ordered <- cluster1_markers |>
  dplyr::filter(mean.AUC > 0.5) |>
  dplyr::arrange(desc(mean.AUC))

plotExpression(sce,
  features = head(ordered$gene),
  x = "clusters",
  colour_by = "clusters",
  color = color_palette
)
```

## Top marker heatmap `r emo::ji("keyboard")` {.smaller}
Next we will extract the top N markers from each cluster, ranked on `mean.AUC`, then plot the average expression of these markers in each cluster as a heatmap.

```{r}
#| echo: true

n_top_markers <- 5

top_markers <- purrr::map_dfr(mrks, ~ {
  .x |>
    as.data.frame() |>
    tibble::rownames_to_column("gene") |>
    dplyr::filter(mean.AUC > 0.5) |>
    dplyr::arrange(desc(mean.AUC)) |>
    dplyr::slice(1:n_top_markers)
}, .id = "cluster")

top_markers[1:10, 1:2]
```

## Top marker heatmap `r emo::ji("keyboard")` {.smaller}
Next we will extract the top N markers from each cluster, ranked on `mean.AUC`, then plot the average expression of these markers in each cluster as a heatmap.

```{r}
#| echo: true
#| fig.width: 9
#| fig.height: 9
plotGroupedHeatmap(sce,
  features = unique(top_markers$gene),
  group = "clusters",
  center = TRUE,
  zlim = c(-3, 3)
)
```

## Some differnetial expression thoughts {.smaller}
* Differential expression in single cell RNA-seq should be interpreted with caution
* Data is very overpowered
  * Individual cells are treated as independent replicates (often using a Wilcoxin test)
  * They are however NOT independent
    * Come from the same sample
    * Come from identical processing
    * Come from highly correlated environments
  * This means that p-values will be inflated and there will be many false negatives
  * Most methods don't account for batch effects and # of DE genes does not change with increase variability between batches
* If you are performing DE between samples, it is better to use a pseudobulk approach and control for batch effect
* More info in two articles: [false-discoveries](https://www.nature.com/articles/s41467-021-25960-2), [pseudoreplication bias](https://www.nature.com/articles/s41467-021-21038-1)

## Annotating cell types {.smaller}

* Early days of single cell used manual cluster annotation
  * Using visual inspection of key genes using expertise in the lab
* Now it is becomming more comon to compare your dataset to another dataset or a reference
  * Leads to more reproducability and agreement across publications
  * Not biased to only a handful of genes, instead thousand of genes are used
  * Correlation and machine learning approaches are common
* Packages include `clustifyr`, `SingleR`, `SignacX`, and `Azimuth`


## Annotating cell types {.smaller}
We we use [`clustifyr`](https://rnabioco.github.io/clustifyr/) which was developed by a previous RBI fellow Rui Fu. There are also many other methods (e.g. `SingleR`)

* `clustifyr` compares the average gene expression in each cluster to a reference matrix that contains average gene signatures of reference cell types.
* The reference can be built from other single cell data, bulk-rna-seq, or other sources.
* Ranked spearman correlation is used to compare the reference to the clusters.
* Only the variable genes are used for the correlation.
  * Fewer variable genes (ie 1000) are recommended as too many genes leads to high correlations across the board (think of a lot of zero values).

In order to compare our dataset we need to use a publicly available reference dataset. Thankfully many datasets have been organized into a separate package: [clustifyrdatahub](https://github.com/rnabioco/clustifyrdatahub). This is an extension of the `ExperimentHub` package on bioconductor that allows you to easily download and cache external datasets.

## Annotating cell types `r emo::ji("keyboard")` {.smaller}
```{r}
#| message: false
#| echo: true

library(clustifyr)
library(clustifyrdatahub)

# get reference dataset derived from a microarray experiment of sorted immune cell types
ref_hema_microarray()[1:5, 1:5]
```

## Annotating cell types `r emo::ji("keyboard")` {.smaller}
```{r}
#| echo: true

res <- clustify(
  sce, # SingleCellExperiment object
  ref_mat = ref_hema_microarray(), # cell type reference data
  cluster_col = "clusters", # column in metadata with clusters
  # don't add to SingleCellExperiment object, just return results
  obj_out = FALSE,
  # use variable genes for comparison
  query_genes = top,
)

res[1:12, 1:4]
```

## Annotating cell types `r emo::ji("keyboard")` {.smaller}
```{r}
#| echo: true

#| fig.height: 5
#| fig.width: 5
library(ComplexHeatmap)
Heatmap(t(res))
```

## Annotating cell types `r emo::ji("keyboard")` {.smaller}
We can use `cor_to_call` to pull out the highest correlation for each cluster
```{r}
#| echo: true

cor_to_call(res) # assign cluster to highest correlation cell type (above a threshold). Cell types lower than a threshold will be assigned as unassigned.
```

## Annotating cell types `r emo::ji("keyboard")` {.smaller}
Or we can insert the classification results into the SingleCellExperiment object directly which will be called `type`.
```{r}
#| echo: true

set.seed(42)
sce <- clustify(
  sce, # seurat object
  ref_mat = ref_hema_microarray(), # cell type reference data
  cluster_col = "clusters", # column in metadata with clusters
  obj_out = TRUE,
  # use variable genes for comparison
  query_genes = top
)

plotUMAP(sce, colour_by = "type")
```

## Saving and sharing objects
1) You can share your SingleCellExperiment objects with collaborators by saving the object as an `.rds` file.

2) If you plan on publishing the data, then the best practices are to upload the UMI count matrix and your colData() data.frame containing the cell type annotations.

To save the UMI count matrix use write10xcounts() from the DropletUtils Bioconductor package.
``` r
mat <- counts(sce)
write10xCounts("path/to/output", mat)
```

## Saving and sharing objects
When saving the `colData()` it is also a nice gesture to include the UMAP coordinates that you used for the main visualizations in your manuscript. The clustering and UMAP coordinates are very hard to reproduce because of the non-deterministic elements of the algorithms.

``` r
cbind(colData(sce), reducedDim(sce, "UMAP")) |>
  rownames_to_column("cell") |> ()
  write_csv("cell-level-metadata.csv")
```

## Saving and sharing objects
* In addition to sharing count tables, in most cases (except for some cases of human data), you must publish your fastq files
* Make sure these are always protected using the 3-2-1 strategy:
  * 3 copies
  * 2 storage types
  * 1 off site
* For me, this is:
  * Peta library active allocation
  * Peta library archive allocation
  * AWS glacial storage (with version control)
  * Nightly backup between each
  * Changing the permissions to read only for fastq files

## Saving and sharing objects
* It is also best practice to share your code
* Keep your code on github
  * Version control - if you make a mistake it's easy to go back
  * Github counts as a backup for your scripts. The sever goes down, you can recover everything from github
  * Easy to change a repo to public when your manuscript is accepted
