[
  {
    "objectID": "zzz.html",
    "href": "zzz.html",
    "title": "dummy file so that downlit ends up",
    "section": "",
    "text": "dummy file so that downlit ends up\nin the renv lock file.\n\nlibrary(downlit)\nlibrary(pak)\n# library(gitcreds)"
  },
  {
    "objectID": "resources/bootcamp-resources.html",
    "href": "resources/bootcamp-resources.html",
    "title": "Bootcamp resources",
    "section": "",
    "text": "Installing R\nInstalling RStudio\n\n\n\n\n\nAdvanced R\nComputational Genomics with R\nR for Data Science (R4DS)\nFundamentals of Data Visualization\n\nQuick reference:\n\nData tidying\nYour labels are too small.. Use cowplot themes to automatically adjust.\n\n\n\n\n\nThe Tidyverse is a collection of libaries implementing a principled approach to data analysis.\nBioconductor is a collection of libraries focused on biological data analysis.\nggplot2\ncowplot\nggthemes\n\n\n\n\nThe tidyverse cheat sheets are indispensible references.\nQuick reference:\n\nRStudio\nRmarkdown\ntidyr\ndplyr\nggplot2\n\n\n\n\n\ngt\ngtExtras\ngt table making contests",
    "crumbs": [
      "Resources",
      "Bootcamp resources"
    ]
  },
  {
    "objectID": "resources/bootcamp-resources.html#r-rstudio",
    "href": "resources/bootcamp-resources.html#r-rstudio",
    "title": "Bootcamp resources",
    "section": "",
    "text": "Installing R\nInstalling RStudio\n\n\n\n\n\nAdvanced R\nComputational Genomics with R\nR for Data Science (R4DS)\nFundamentals of Data Visualization\n\nQuick reference:\n\nData tidying\nYour labels are too small.. Use cowplot themes to automatically adjust.\n\n\n\n\n\nThe Tidyverse is a collection of libaries implementing a principled approach to data analysis.\nBioconductor is a collection of libraries focused on biological data analysis.\nggplot2\ncowplot\nggthemes\n\n\n\n\nThe tidyverse cheat sheets are indispensible references.\nQuick reference:\n\nRStudio\nRmarkdown\ntidyr\ndplyr\nggplot2\n\n\n\n\n\ngt\ngtExtras\ngt table making contests",
    "crumbs": [
      "Resources",
      "Bootcamp resources"
    ]
  },
  {
    "objectID": "resources/bootcamp-resources.html#statistics",
    "href": "resources/bootcamp-resources.html#statistics",
    "title": "Bootcamp resources",
    "section": "Statistics",
    "text": "Statistics\n\nPractical Statistics for Data Scientists covers several fundamental concepts with code for both R and Python.\nModern Statistics for Modern Biology is written by two leading figures in computational biology and contains several examples using Bioconductor.\nStatistics for Biologists is a collection of articles on statistical topic.",
    "crumbs": [
      "Resources",
      "Bootcamp resources"
    ]
  },
  {
    "objectID": "resources/bootcamp-resources.html#miscellaneous",
    "href": "resources/bootcamp-resources.html#miscellaneous",
    "title": "Bootcamp resources",
    "section": "Miscellaneous",
    "text": "Miscellaneous\n\nProject-oriented workflows\nOrganizing projects\nHappy Git with R",
    "crumbs": [
      "Resources",
      "Bootcamp resources"
    ]
  },
  {
    "objectID": "resources/block-dna-resources.html",
    "href": "resources/block-dna-resources.html",
    "title": "Resources for the DNA block",
    "section": "",
    "text": "These studies below laid the methodological groundwork for high throughput chromatin characterization by DNA sequencing. Some of the authors are here at CU Anschutz!\n\n\n\n\n\n\nTip\n\n\n\nData sets from these studies would be excellent choices as starting points for your final projects.\n\n\n\n\nHesselberth JR, Chen X, Zhang Z, Sabo PJ, Sandstrom R, Reynolds AP, Thurman RE, Neph S, Kuehn MS, Noble WS, Fields S, Stamatoyannopoulos JA. Global mapping of protein-DNA interactions in vivo by digital genomic footprinting. Nat Methods. 2009 19305407; PMCID: PMC2668528. [Link]\n\n\n\nBuenrostro JD, Giresi PG, Zaba LC, Chang HY, Greenleaf WJ. Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position. Nat Methods. 2013 PMID: 24097267; PMCID: PMC3959825. [Link]\n\n\n\nRamachandran S, Ahmad K, Henikoff S. Transcription and Remodeling Produce Asymmetrically Unwrapped Nucleosomal Intermediates. Mol Cell. 2017 PMID: 29225036; PMCID: PMC6421108. [Link]\n\n\n\nSkene PJ, Henikoff S. An efficient targeted nuclease strategy for high-resolution mapping of DNA binding sites. Elife. 2017 PMID: 28079019; PMCID: PMC5310842. [Link]\nKaya-Okur HS, Wu SJ, Codomo CA, Pledger ES, Bryson TD, Henikoff JG, Ahmad K, Henikoff S. CUT&Tag for efficient epigenomic profiling of small samples and single cells. Nat Commun. 2019 PMID: 31036827; PMCID: PMC6488672. [Link]",
    "crumbs": [
      "Resources",
      "DNA Block resources"
    ]
  },
  {
    "objectID": "resources/block-dna-resources.html#foundational-work",
    "href": "resources/block-dna-resources.html#foundational-work",
    "title": "Resources for the DNA block",
    "section": "",
    "text": "These studies below laid the methodological groundwork for high throughput chromatin characterization by DNA sequencing. Some of the authors are here at CU Anschutz!\n\n\n\n\n\n\nTip\n\n\n\nData sets from these studies would be excellent choices as starting points for your final projects.\n\n\n\n\nHesselberth JR, Chen X, Zhang Z, Sabo PJ, Sandstrom R, Reynolds AP, Thurman RE, Neph S, Kuehn MS, Noble WS, Fields S, Stamatoyannopoulos JA. Global mapping of protein-DNA interactions in vivo by digital genomic footprinting. Nat Methods. 2009 19305407; PMCID: PMC2668528. [Link]\n\n\n\nBuenrostro JD, Giresi PG, Zaba LC, Chang HY, Greenleaf WJ. Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position. Nat Methods. 2013 PMID: 24097267; PMCID: PMC3959825. [Link]\n\n\n\nRamachandran S, Ahmad K, Henikoff S. Transcription and Remodeling Produce Asymmetrically Unwrapped Nucleosomal Intermediates. Mol Cell. 2017 PMID: 29225036; PMCID: PMC6421108. [Link]\n\n\n\nSkene PJ, Henikoff S. An efficient targeted nuclease strategy for high-resolution mapping of DNA binding sites. Elife. 2017 PMID: 28079019; PMCID: PMC5310842. [Link]\nKaya-Okur HS, Wu SJ, Codomo CA, Pledger ES, Bryson TD, Henikoff JG, Ahmad K, Henikoff S. CUT&Tag for efficient epigenomic profiling of small samples and single cells. Nat Commun. 2019 PMID: 31036827; PMCID: PMC6488672. [Link]",
    "crumbs": [
      "Resources",
      "DNA Block resources"
    ]
  },
  {
    "objectID": "resources/block-dna-resources.html#software-well-use-in-class",
    "href": "resources/block-dna-resources.html#software-well-use-in-class",
    "title": "Resources for the DNA block",
    "section": "Software we’ll use in class",
    "text": "Software we’ll use in class\n\nRead over the GViz vignette to understand how we’ll use it to vissualize genome-scale data on a reference sequence.\nRead over the valr vignette to understand how we’ll do BEDtools-like (see below) analysis within RStudio.\nLook over the ComplexHeatmap and EnrichedHeatmap documentation, especially XXX. These tools will help us make “meta-plots”: figures that plot genomic signals relative to features.",
    "crumbs": [
      "Resources",
      "DNA Block resources"
    ]
  },
  {
    "objectID": "resources/block-dna-resources.html#other-important-tools",
    "href": "resources/block-dna-resources.html#other-important-tools",
    "title": "Resources for the DNA block",
    "section": "Other important tools",
    "text": "Other important tools\nThese are other tools I’ll mention in class. We’re not going to use them directly, but they are important tools in upstream data processing and analysis.\n\nAlignment software\nBowtie2 and BWA are popular choices for short read alignment. They are fast, free, and well-maintained.\n\n\nPeak calling\nMACS is the gold-standard in peak calling. It models read coverage as a Poisson process, straightforward identification of regions of higher than expected coverage (i.e., peaks) to be identified using a single parameter (lambda) that captures the mean and variance of read coverage.\n\n\nInterval analysis\n\nBEDtools is the “Swiss Army knife” of genome interval analysis. It provides a host of command-line tools that can be linked together for powerful genome signal manipulation.",
    "crumbs": [
      "Resources",
      "DNA Block resources"
    ]
  },
  {
    "objectID": "resources/block-dna-resources.html#experimental-rigor-in-chromatin-analysis",
    "href": "resources/block-dna-resources.html#experimental-rigor-in-chromatin-analysis",
    "title": "Resources for the DNA block",
    "section": "Experimental rigor in chromatin analysis",
    "text": "Experimental rigor in chromatin analysis\nThese studies identified pervasive artifacts in genomewide chromatin analysis and provide recommendations and solutions to the issues.\nTeytelman L, Thurtle DM, Rine J, van Oudenaarden A. Highly expressed loci are vulnerable to misleading ChIP localization of multiple unrelated proteins. Proc Natl Acad Sci U S A. 2013 Nov 12;110(46):18602-7. doi: 10.1073/pnas.1316064110. Epub 2013 Oct 30. PMID: 24173036; PMCID: PMC3831989.\nShah RN, Grzybowski AT, Cornett EM, Johnstone AL, Dickson BM, Boone BA, Cheek MA, Cowles MW, Maryanski D, Meiners MJ, Tiedemann RL, Vaughan RM, Arora N, Sun ZW, Rothbart SB, Keogh MC, Ruthenburg AJ. Examining the Roles of H3K4 Methylation States with Systematically Characterized Antibodies. Mol Cell. 2018 Oct 4;72(1):162-177.e7. doi: 10.1016/j.molcel.2018.08.015. Epub 2018 Sep 20. PMID: 30244833; PMCID: PMC6173622.",
    "crumbs": [
      "Resources",
      "DNA Block resources"
    ]
  },
  {
    "objectID": "problem-sets/ps-14.html",
    "href": "problem-sets/ps-14.html",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\nAttaching package: 'janitor'\n\n\nThe following object is masked from 'package:rstatix':\n\n    make_clean_names\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nhere() starts at /home/runner/work/molb-7950/molb-7950\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1, 6, 9, 14, 15, 24:28)]\nbiochem &lt;- biochem[, keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\", \"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename gender to sex\nb &lt;- inner_join(biochem, weight, by = \"subject_name\") |&gt;\n  na.omit() |&gt;\n  rename(sex = gender)"
  },
  {
    "objectID": "problem-sets/ps-14.html#problem-1",
    "href": "problem-sets/ps-14.html#problem-1",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Problem # 1",
    "text": "Problem # 1\nCan mouse sex explain mouse cholesterol? {.smaller}"
  },
  {
    "objectID": "problem-sets/ps-14.html#step-1-null-hypothesis-and-variable-specification",
    "href": "problem-sets/ps-14.html#step-1-null-hypothesis-and-variable-specification",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "STEP 1: Null hypothesis and variable specification",
    "text": "STEP 1: Null hypothesis and variable specification\n\\(\\mathcal{H}_0:\\)\n\n?? is the response variable\n\n\n?? is the explanatory variable"
  },
  {
    "objectID": "problem-sets/ps-14.html#step-2-fit-linear-model-and-examine-results",
    "href": "problem-sets/ps-14.html#step-2-fit-linear-model-and-examine-results",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "STEP 2: Fit linear model and examine results",
    "text": "STEP 2: Fit linear model and examine results\nFit summary:\nCoefficient summary:"
  },
  {
    "objectID": "problem-sets/ps-14.html#collecting-residuals-and-other-information",
    "href": "problem-sets/ps-14.html#collecting-residuals-and-other-information",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Collecting residuals and other information",
    "text": "Collecting residuals and other information\nadd residuals and other information"
  },
  {
    "objectID": "problem-sets/ps-14.html#step-4-visualize-the-error-around-fit",
    "href": "problem-sets/ps-14.html#step-4-visualize-the-error-around-fit",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "STEP 4: Visualize the error around fit",
    "text": "STEP 4: Visualize the error around fit\n\n# plot of data with mean and colored by residuals"
  },
  {
    "objectID": "problem-sets/ps-14.html#step-3-visualize-the-error-around-the-null-mean-weight",
    "href": "problem-sets/ps-14.html#step-3-visualize-the-error-around-the-null-mean-weight",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "STEP 3: Visualize the error around the null (mean weight)",
    "text": "STEP 3: Visualize the error around the null (mean weight)"
  },
  {
    "objectID": "problem-sets/ps-14.html#plot-the-fit-error-and-the-null-error-as-2-panels",
    "href": "problem-sets/ps-14.html#plot-the-fit-error-and-the-null-error-as-2-panels",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Plot the fit error and the null error as 2 panels",
    "text": "Plot the fit error and the null error as 2 panels"
  },
  {
    "objectID": "problem-sets/ps-14.html#calculate-r2",
    "href": "problem-sets/ps-14.html#calculate-r2",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Calculate \\(R^2\\)\n",
    "text": "Calculate \\(R^2\\)\n\n\\(R^2 = 1 - \\displaystyle \\frac {SS_{fit}}{SS_{null}}\\)\ncheck agains Rsq in your fit"
  },
  {
    "objectID": "problem-sets/ps-14.html#compare-to-traditional-t-test",
    "href": "problem-sets/ps-14.html#compare-to-traditional-t-test",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Compare to traditional t-test",
    "text": "Compare to traditional t-test"
  },
  {
    "objectID": "problem-sets/ps-14.html#provide-your-interpreation-of-the-result",
    "href": "problem-sets/ps-14.html#provide-your-interpreation-of-the-result",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Provide your interpreation of the result",
    "text": "Provide your interpreation of the result"
  },
  {
    "objectID": "problem-sets/ps-12.html",
    "href": "problem-sets/ps-12.html",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\nAttaching package: 'janitor'\n\n\nThe following object is masked from 'package:rstatix':\n\n    make_clean_names\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nhere() starts at /home/runner/work/molb-7950/molb-7950\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1, 6, 9, 14, 15, 24:28)]\nbiochem &lt;- biochem[, keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\", \"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename gender to sex\nb &lt;- inner_join(biochem, weight, by = \"subject_name\") |&gt;\n  na.omit() |&gt;\n  rename(sex = gender)"
  },
  {
    "objectID": "problem-sets/ps-12.html#problem-1",
    "href": "problem-sets/ps-12.html#problem-1",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Problem # 1",
    "text": "Problem # 1\nDoes mouse sex explain mouse total cholesterol levels? Make sure to run chunks above.\n1. Examine and specify the variable(s) (1 pt)\n\nThe response variable y is \\(??\\)\nThe explantory variable x is \\(??\\)\n\nMake a violin plot: (2 pt)\nresponse variable on the y-axis\nexplanatory variable on the x-axis\nGet n, mean, median, sd (1 pt)\nIs it normally distribute? (1 pt)\n\nAnswer here\n\nIs it variance similar between groups? (1 pt)\n\nAnswer here\n\nWhat kind of test are you picking and why? (1 pt)\n\nAnswer here\n\n2. Declare null hypothesis \\(\\mathcal{H}_0\\) (1 pt)\n\\(\\mathcal{H}_0\\) is that \\(??\\) does not explain \\(??\\)\n3. Calculate test-statistic, exact p-value and plot (2 pt)\n\nMy interpretation of the result\n\n\n# i have pre-selected some families to compare\nmyfams &lt;- c(\n  \"B1.5:E1.4(4) B1.5:A1.4(5)\",\n  \"F1.3:A1.2(3) F1.3:E2.2(3)\",\n  \"A1.3:D1.2(3) A1.3:H1.2(3)\",\n  \"D5.4:G2.3(4) D5.4:C4.3(4)\"\n)\n\n# only keep the familys in myfams\nbfam &lt;- b |&gt;\n  filter(family %in% myfams) |&gt;\n  droplevels()\n\n# simplify family names and make factor\nbfam$family &lt;- gsub(pattern = \"\\\\..*\", replacement = \"\", x = bfam$family) |&gt;\n  as.factor()\n\n\n# make B1 the reference (most similar to overall mean)\nbfam$family &lt;- relevel(x = bfam$family, ref = \"B1\")"
  },
  {
    "objectID": "problem-sets/ps-12.html#problem-2",
    "href": "problem-sets/ps-12.html#problem-2",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Problem # 2",
    "text": "Problem # 2\nDoes mouse family explain mouse total cholesterol levels? Make sure to run chunk above.\n1. Examine and specify the variable(s) (1 pt)\n\nThe response variable y is \\(??\\)\nThe explanatory variable x is \\(??\\)\n\nMake a plot: (2 pt)\nresponse variable on the y-axis\nexplanatory variable on the x-axis\nGet n, mean, median, sd (1 pt)\nIs it normally distribute? (1 pt)\n\nAnswer here\n\nIs it variance similar between groups? (1 pt)\n\nAnswer here\n\nWhat kind of test are you picking and why? (1 pt)\n\nAnswer here ### 2. Declare null hypothesis \\(\\mathcal{H}_0\\)\n\n\n\\(\\mathcal{H}_0\\) is that \\(??\\) does not explain \\(??\\) (1 pt)\n3. Calculate test-statistic, exact p-value and plot (2 pt)\n\nMy interpretation of the result"
  },
  {
    "objectID": "problem-sets/ps-08.html",
    "href": "problem-sets/ps-08.html",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "",
    "text": "In this problem set, you’ll work with the Brauer gene expression dataset to practice comprehensive tidyverse skills including data tidying, transformation, joins, pivoting, string manipulation, and statistical modeling using broom. The dataset contains gene expression measurements for yeast genes under different nutrient limitations and growth rates.\n\nBefore we start tidying and analyzing the data, take a moment to predict what you might find.\n\nQuestion: What patterns do you expect to see in gene expression across different nutrients and growth rates?\nHypothesis: Genes involved in nutrient uptake and metabolism will show higher expression under their respective limiting conditions.\nHypohtesis: The different nutrient conditions will cause distinct gene expression profiles."
  },
  {
    "objectID": "problem-sets/ps-08.html#predictions",
    "href": "problem-sets/ps-08.html#predictions",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "",
    "text": "Before we start tidying and analyzing the data, take a moment to predict what you might find.\n\nQuestion: What patterns do you expect to see in gene expression across different nutrients and growth rates?\nHypothesis: Genes involved in nutrient uptake and metabolism will show higher expression under their respective limiting conditions.\nHypohtesis: The different nutrient conditions will cause distinct gene expression profiles."
  },
  {
    "objectID": "problem-sets/ps-08.html#load-required-libraries",
    "href": "problem-sets/ps-08.html#load-required-libraries",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n2.1 Load Required Libraries",
    "text": "2.1 Load Required Libraries\n\nCode# Load required libraries"
  },
  {
    "objectID": "problem-sets/ps-08.html#load-the-data",
    "href": "problem-sets/ps-08.html#load-the-data",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n2.2 Load the Data",
    "text": "2.2 Load the Data\nTask 1: Load the raw Brauer gene expression data and examine its structure. What makes this data “messy” or untidy?\nBreadcrumbs: Use read_tsv() to load the data from the URL. Examine column names and the first few rows. Think about tidy data principles - what issues do you see with the current format?\n\nCode#|label: data-loading-02\n\n# Load the Brauer gene expression data\nurl &lt;- \"https://github.com/rnabioco/molb-7950/raw/refs/heads/main/data/bootcamp/brauer_gene_exp_raw.tsv.gz\"\n\n\n\nCode# Examine the structure of the data"
  },
  {
    "objectID": "problem-sets/ps-08.html#create-a-tidy-dataset",
    "href": "problem-sets/ps-08.html#create-a-tidy-dataset",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n3.1 Create a Tidy Dataset",
    "text": "3.1 Create a Tidy Dataset\nTask 3: Transform the wide-format expression data into a long format suitable for analysis.\nBreadcrumbs:\n\nFirst select the relevant columns (systematic_name and the expression columns (G0.05, etc))\nThen use pivot_longer() to convert expression columns to rows\nThe column names contain both nutrient type (G) and growth rate (0.05) information - use separate_wider_position() to split the first character (nutrient abbreviation) from the numeric rate. The key here is to specify widths = c(nutrient_abbr = 1, rate = 4) to split after the first character, and put the rest into rate. Not all the rates have 4 characters, so use too_few = \"align_start\" to handle that.\n\nCreate a nutrient lookup table to convert abbreviations to full names. The lookup table should look like this:\n# A tibble: 6 × 2\n  nutrient_abbr nutrient\n  &lt;chr&gt;         &lt;chr&gt;\n1 G             Glucose\n2 N             Ammonia\n3 P             Phosphate\n4 S             Sulfate\n5 L             Leucine\n6 U             Uracil\n\nUse that table with a join function to add full nutrient names to the tidied data.\nConvert the rate column to numeric and select the final columns in the desired order\nRemove any NA values from systematic_name and exp_level using filter()"
  },
  {
    "objectID": "problem-sets/ps-08.html#explore-expression-patterns",
    "href": "problem-sets/ps-08.html#explore-expression-patterns",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n4.1 Explore Expression Patterns",
    "text": "4.1 Explore Expression Patterns\nTask 6: Calculate summary statistics for gene expression by nutrient type.\nBreadcrumbs: - Use group_by() and summarize() to calculate mean, median, and standard deviation of expression values for each nutrient. Which nutrients show the highest variability in expression?*\n\nCode# Calculate summary statistics by nutrient\n\n\n\nCode# Find genes with extreme expression values\n\n\nInspect the results and note any patterns you observe in high and low expression genes across different nutrient-rate combinations.\nNext, make a boxplot to visualize the distribution of expression levels for each nutrient condition. What insights can you draw from the plot?\n\nCode#|"
  },
  {
    "objectID": "problem-sets/ps-08.html#identify-high-and-low-expression",
    "href": "problem-sets/ps-08.html#identify-high-and-low-expression",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n4.2 Identify High and Low Expression",
    "text": "4.2 Identify High and Low Expression\nTask 7: Find genes with extreme expression values under different conditions.\nBreadcrumbs: For each nutrient-rate combination, identify the top 5 highest and lowest expressing genes. Use slice_max() and slice_min() or ranking functions. What patterns do you notice?\n\nCode# Find genes with extreme expression values"
  },
  {
    "objectID": "problem-sets/ps-08.html#linear-models-for-individual-genes",
    "href": "problem-sets/ps-08.html#linear-models-for-individual-genes",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n5.1 Linear Models for Individual Genes",
    "text": "5.1 Linear Models for Individual Genes\nTask 8: Fit linear models to examine how each gene’s expression responds to growth rate within each nutrient condition.\nBreadcrumbs:\n\nUse reframe() with broom::tidy(lm(exp_level ~ rate)) for each gene-nutrient combination\nUse .by = c(nutrient, systematic_name) to group the modeling\nThis creates a tidy data frame of model coefficients\n\n\nCode# Fit linear models for each gene-nutrient combination\nbrauer_models_tbl &lt;-\n  brauer_tidy_tbl |&gt;\n  reframe(\n    broom::tidy(lm(exp_level ~ rate)),\n    .by = c(nutrient, systematic_name)\n  )\n\n\nThe above should give you a tibble that looks like this:\n# A tibble: 66,430 × 7\n   nutrient  systematic_name term        estimate std.error statistic p.value\n   &lt;chr&gt;     &lt;chr&gt;           &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 Glucose   YNL049C         (Intercept)   -0.263    0.0441    -5.98  0.00394\n 2 Glucose   YNL049C         rate           0.714    0.226      3.16  0.0343\n 3 Ammonia   YNL049C         (Intercept)    0.153    0.247      0.619 0.569\n 4 Ammonia   YNL049C         rate          -1.09     1.27      -0.862 0.437\n 5 Phosphate YNL049C         (Intercept)   -0.465    0.161     -2.89  0.0444\n 6 Phosphate YNL049C         rate           2.07     0.825      2.51  0.0657\n 7 Sulfate   YNL049C         (Intercept)   -0.419    0.157     -2.67  0.0558\n 8 Sulfate   YNL049C         rate           2.23     0.807      2.77  0.0503\n 9 Leucine   YNL049C         (Intercept)    0.193    0.0313     6.16  0.00352\n10 Leucine   YNL049C         rate          -0.177    0.161     -1.10  0.332\n# ℹ 66,420 more rows\n# ℹ Use `print(n = ...)` to see more rows"
  },
  {
    "objectID": "problem-sets/ps-08.html#analyze-slope-coefficients",
    "href": "problem-sets/ps-08.html#analyze-slope-coefficients",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n5.2 Analyze Slope Coefficients",
    "text": "5.2 Analyze Slope Coefficients\nTask 9: Examine the slope terms to identify genes that significantly respond to growth rate changes.\nBreadcrumbs: Filter for slope terms (not intercepts). Use q-value correction for multiple testing. Create histograms of p-values by nutrient. Which genes show the strongest positive or negative relationships with growth rate?\n\nCode# Analyze slope coefficients"
  },
  {
    "objectID": "problem-sets/ps-08.html#analyze-intercept-terms",
    "href": "problem-sets/ps-08.html#analyze-intercept-terms",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n5.3 Analyze Intercept Terms",
    "text": "5.3 Analyze Intercept Terms\nTask 10: Use intercept terms to identify genes with unusual baseline expression under specific nutrient limitations.\nBreadcrumbs: Filter for intercept terms. Center intercepts around each gene’s mean across nutrients using group_by() and mutate(). Use top_n() to find genes with extreme centered intercepts.\n\nCode# Analyze intercept terms"
  },
  {
    "objectID": "problem-sets/ps-08.html#hypothesis",
    "href": "problem-sets/ps-08.html#hypothesis",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n6.1 Hypothesis",
    "text": "6.1 Hypothesis\nState one or more hypotheses you want to test using this data."
  },
  {
    "objectID": "problem-sets/ps-08.html#explore-analyze",
    "href": "problem-sets/ps-08.html#explore-analyze",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n6.2 Explore / Analyze",
    "text": "6.2 Explore / Analyze\nGenerate some tables or plots to explore your hypothesis."
  },
  {
    "objectID": "problem-sets/ps-08.html#interpreation",
    "href": "problem-sets/ps-08.html#interpreation",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n6.3 Interpreation",
    "text": "6.3 Interpreation\nInterpret your results. What do they mean in the context of your hypothesis? Were you able to support or refute your hypothesis?"
  },
  {
    "objectID": "problem-sets/ps-04.html",
    "href": "problem-sets/ps-04.html",
    "title": "R Bootcamp Problem Set 4",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Aug 29"
  },
  {
    "objectID": "problem-sets/ps-04.html#problem-set",
    "href": "problem-sets/ps-04.html#problem-set",
    "title": "R Bootcamp Problem Set 4",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Aug 29"
  },
  {
    "objectID": "problem-sets/ps-04.html#grading-rubric",
    "href": "problem-sets/ps-04.html#grading-rubric",
    "title": "R Bootcamp Problem Set 4",
    "section": "Grading rubric",
    "text": "Grading rubric\n\nEverything is good: full points\nPartially correct answer: depends on how many steps are correct\nReasonable attempt: half points"
  },
  {
    "objectID": "problem-sets/ps-04.html#question-1-5-points",
    "href": "problem-sets/ps-04.html#question-1-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 1 5 points\n",
    "text": "Question 1 5 points\n\n\nLoad the tidyverse and here packages using library().\nImport datasets: data/data_rna_protein.csv.gz using read_csv() and here().\n\ndata_rna_protein.csv.gz: This is a combined dataset from an RNAseq and SILAC proteomics experiment, where a transcription factor (TF) was differentially expressed and the fold change in RNA and protein calculated between TF-expressing and non-expressing cells.\n\nlibrary(tidyverse)\nlibrary(here)\n\nexp_tbl &lt;- read_csv(\n  here(___)\n)"
  },
  {
    "objectID": "problem-sets/ps-04.html#question-2-5-points",
    "href": "problem-sets/ps-04.html#question-2-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 2 5 points\n",
    "text": "Question 2 5 points\n\nLet’s build a data processing workflow step by step. This teaches you how to build complex pipelines gradually - a key skill in data analysis.\nStep 1: First, explore the data so you know what you’re working with. Use glimpse() to see column types and summary() to see distributions:\n\n# Always explore your data first!\n\nStep 2: Select only the columns we need:\n\n\ngeneid (gene identifier)\n\niDUX4_logFC (RNA fold change)\n\niDUX4_fdr (RNA pvalue)\n\nhl.ratio (protein fold change)\n\npval (protein pvalue)\n\nUse select() and list the columns you want to keep:\n\nexp_tbl |&gt;\n  select(___)\n\nStep 3: Rename columns for clarity (this makes your code more readable).\nUse dplyr::rename() with the pattern new_name = old_name, ...:\n\nexp_tbl |&gt;\n  select(___) |&gt;\n  rename(\n    ___ = ___,\n    # etc\n  )\n\nStep 4: Clean the data by removing rows with missing values. Use drop_na() to remove rows with any missing values, and distinct() to remove duplicate rows:\n\nexp_tbl |&gt;\n  select(___) |&gt;\n  rename(\n    ___ = ___,\n    # etc\n  ) |&gt;\n  ___() |&gt; # Remove rows with any missing values\n  ___() # Remove duplicate rows\n\nStep 5: Finally, arrange the data and save it. Use arrange() to sort by RNA fold change (high to low), then protein fold change (low to high):\n\nexp_tbl_subset &lt;- exp_tbl |&gt;\n  select(___) |&gt;\n  rename(\n    ___ = ___,\n    # etc\n  ) |&gt;\n  ___() |&gt; # Remove rows with any missing values\n  ___() |&gt; # Remove duplicate rows\n  # Sort by RNA fold change (high to low), then protein fold change (low to high)\n  ___(___, ___)\n\nexp_tbl_subset"
  },
  {
    "objectID": "problem-sets/ps-04.html#question-3-5-points",
    "href": "problem-sets/ps-04.html#question-3-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 3 5 points\n",
    "text": "Question 3 5 points\n\nLet’s practice good data analysis habits by checking for potential issues. Quality control is essential in real data analysis.\nCheck for duplicates and missing values:\n\nUse count() to check for duplicate genes\nUse summarize() with across() to count missing values in all columns\nUse summary statistics to understand data distributions\n\n\n# Check for duplicate genes (there shouldn't be any after distinct())\nexp_tbl_subset |&gt;\n  count(___) |&gt;\n  ___(n &gt; 1) # Any genes appearing more than once?\n\n\n# Summary of missing values by column\nexp_tbl_subset |&gt;\n  summarize(\n    # first blank select variables\n    # second blank applies a function to count NA values\n    across(___, ___)\n  )\n\n\n# Look at the distribution of our main variables\nexp_tbl_subset |&gt;\n  summarize(\n    across(\n      # specify the variables to summarize\n      ___,\n      list(\n        # mean\n        mean = ~ mean(., na.rm = TRUE),\n        # now do median\n        ___ = ~ ___(., na.rm = TRUE),\n        # and sd\n        ___ = ~ ___(., na.rm = TRUE)\n      )\n    ),\n    .groups = \"drop\"\n  )"
  },
  {
    "objectID": "problem-sets/ps-04.html#question-4-5-points",
    "href": "problem-sets/ps-04.html#question-4-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 4 5 points\n",
    "text": "Question 4 5 points\n\nHow well do the overall rna_FC and protein_FC values correlate in this experiment? We’ll explore this with visualization and statistics.\nStep 1: Create a scatter plot of rna_FC vs protein_FC using ggplot(). Use:\n\n\naes() to map x and y variables\n\ngeom_point() to create the scatter plot\n\nlabs() to add informative axis labels and title\n\n\nggplot(\n  ___,\n  aes(\n    x = ___,\n    y = ___\n  )\n) +\n  # ad points\n  ___() +\n  # add labels\n  labs(\n    x = \"___\",\n    y = \"___\",\n    title = \"___\"\n  )\n\nStep 2: Add reference lines to help interpret the correlation. Use:\n\n\ngeom_abline(slope = 1, intercept = 0) for perfect correlation line\n\ngeom_smooth(method = \"lm\", se = FALSE) for the computed trend line\nadjust the geom_point() aesthetic to alpha = 0.6, making points slightly transparent for better visualization\n\n\nggplot(\n  ___,\n  aes(\n    x = ___,\n    y = ___\n  )\n) +\n  # Add transparent points (change the ???)\n  geom_???(alpha = 0.6) +\n  # Add the perfect correlation line (change the ???)\n  geom_???(slope = 1, intercept = 0, color = \"red\", linewidth = 1) +\n  # Add the computed trend line (change the ???)\n  geom_???(method = \"lm\", se = FALSE, color = \"blue\", linewidth = 1) +\n  labs(\n    x = \"___\",\n    y = \"___\",\n    title = \"___\"\n  )\n\nStep 3: Calculate the correlation coefficient using cor(). Use Spearman correlation since it’s robust to outliers. Use ?cor to see the function documentation. You will need to specify two vectors for the calculation, and it’s easiest to provide them using the $ operator to extract columns from the data frame.\n\nrna_prot_cor &lt;- cor(\n  # specify the first vector\n  ___,\n  # specify the second vector\n  ___,\n  method = \"spearman\"\n)\n\nrna_prot_cor\n\nAnswer\n[ YOUR ANSWER HERE ]"
  },
  {
    "objectID": "problem-sets/ps-04.html#submit",
    "href": "problem-sets/ps-04.html#submit",
    "title": "R Bootcamp Problem Set 4",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of this Posit Cloud project into the problem set on Canvas."
  },
  {
    "objectID": "problem-sets/ps-02.html",
    "href": "problem-sets/ps-02.html",
    "title": "Problem Set 2 Key",
    "section": "",
    "text": "Each problem below is worth 4 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Aug 27.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-sets/ps-02.html#problem-set",
    "href": "problem-sets/ps-02.html#problem-set",
    "title": "Problem Set 2 Key",
    "section": "",
    "text": "Each problem below is worth 4 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Aug 27.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-sets/ps-02.html#question-1",
    "href": "problem-sets/ps-02.html#question-1",
    "title": "Problem Set 2 Key",
    "section": "Question 1",
    "text": "Question 1\nStart by loading the libraries you need for analysis below. When in doubt, start by loading the tidyverse package. You should also load here.\n\nlibrary(___)\nlibrary(___)\n\nNow import the dataset data_transcript_exp_subset using the readr package. Use read_csv() to import the file.\nThe file is located at data/data_transcript_exp_subset.csv.gz - use here() to create the complete path.\n\nexp_tbl &lt;- read_csv(___)\n\nexp_tbl"
  },
  {
    "objectID": "problem-sets/ps-02.html#question-2",
    "href": "problem-sets/ps-02.html#question-2",
    "title": "Problem Set 2 Key",
    "section": "Question 2",
    "text": "Question 2\nExplore the dataset. Is this dataset tidy? If not, why not?\nThis data frame is a subset (100 lines) of transcript-level gene expression data where transcript abundance was measured at two different time points of a certain treatment conducted in triplicates. The column names have the format of molecule_time_replicate\nFirst, explore the structure of the dataset using some of the functions we learned in class. Try using glimpse(), summary(), and names() to understand the data structure.\nAdd more code chunks as needed to separate the different steps of your exploration.\n\nx\n\n\nnames(x)\n\nComment on whether this dataset is tidy, and if not, list the reasons why.\nHint: In a tidy dataframe, every column represents a single variable and every row represents a single observation\nAnswer\n[YOUR ANSWER HERE]"
  },
  {
    "objectID": "problem-sets/ps-02.html#question-3",
    "href": "problem-sets/ps-02.html#question-3",
    "title": "Problem Set 2 Key",
    "section": "Question 3",
    "text": "Question 3\nHow will you reshape the data frame so that each row has only one experimental observation?\nBefore we reshape, let’s think about what we want:\n\nWhich column should stay the same? (The transcript ID)\nWhich columns contain the measurements? (All the others)\nWhat should we call the new column names?\n\nUse pivot_longer() to reshape the data. You’ll want to:\n\nKeep the ensembl_transcript_id column as-is (cols)\nCreate a new column for the condition names (names_to)\nCreate a new column for the values (values_to)\n\n\n# Reshape the data so each row is one observation\nexp_tbl_long &lt;-\n  pivot_longer(\n    x,\n    cols = ___,\n    names_to = ___,\n    values_to = ___\n  )\n\nexp_tbl_long\n\nQuestion 4\nHow will you modify the dataframe so that multiple variables are not present in a single column?\nUse separate_wider_delim() to split the condition column into separate variables. You need to:\n\nSpecify which column to separate (cols)\nSpecify the delimiter character (delim)\nProvide the new column names (names)\n\n\nexp_tbl_tidy &lt;-\n  separate_wider_delim(\n    exp_tbl_long,\n    cols = ___,\n    delim = ___,\n    names = ___\n  )\n\nexp_tbl_tidy\n\nQuestion 5\nHow will you save your output as a TSV file?\nUse write_tsv() from the readr package to save your tidy data. Provide the data object and a filename.\nHint: Use the readr cheatsheet at the bottom of this page to figure this out.\nAfter running your new code, you should have a new file called transcripts.tidy.tsv in your working directory.\n\nwrite_tsv(exp_tbl_tidy, \"transcripts.tidy.tsv\")\n\nQuestion 6\nCan you reverse the process? How would you go from tidy back to wide format?\nUse pivot_wider() to go from the tidy format back to the original wide format. You need to:\n\nSpecify where the new column names come from (names_from)\nSpecify where the values come from (values_from)\nSpecify how to combine the names (names_sep)\n\n\npivot_wider(\n  exp_tbl_tidy,\n  names_from = ___,\n  values_from = ___,\n  names_sep = ___\n)\n\nAfter this, your new data should look like the original tibble you started with."
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html",
    "href": "problem-set-keys/ps-key-04.html",
    "title": "R Bootcamp Problem Set 4",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Sept 1."
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#problem-set",
    "href": "problem-set-keys/ps-key-04.html#problem-set",
    "title": "R Bootcamp Problem Set 4",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Sept 1."
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#grading-rubric",
    "href": "problem-set-keys/ps-key-04.html#grading-rubric",
    "title": "R Bootcamp Problem Set 4",
    "section": "Grading rubric",
    "text": "Grading rubric\n\nEverything is good: full points\nPartially correct answer: depends on how many steps are correct\nReasonable attempt: half points"
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#question-1-5-points",
    "href": "problem-set-keys/ps-key-04.html#question-1-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 1 5 points\n",
    "text": "Question 1 5 points\n\n\nLoad the tidyverse and here packages using library().\nImport datasets: data/data_rna_protein.csv.gz using read_csv() and here().\n\ndata_rna_protein.csv.gz: This is a combined dataset from an RNAseq and SILAC proteomics experiment, where a transcription factor (TF) was differentially expressed and the fold change in RNA and protein calculated between TF-expressing and non-expressing cells.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950\n\nexp_tbl &lt;- read_csv(\n  here(\"data/bootcamp/data_rna_protein.csv.gz\")\n)\n\nRows: 21282 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): geneid\ndbl (16): iDUX4_logFC, iDUX4_logCPM, iDUX4_LR, iDUX4_pval, iDUX4_fdr, hl.rat...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#question-2-5-points",
    "href": "problem-set-keys/ps-key-04.html#question-2-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 2 5 points\n",
    "text": "Question 2 5 points\n\nLet’s build a data processing workflow step by step. This teaches you how to build complex pipelines gradually - a key skill in data analysis.\nStep 1: First, explore the data so you know what you’re working with. Use glimpse() to see column types and summary() to see distributions:\n\n# Always explore your data first!\nexp_tbl |&gt; glimpse()\n\nRows: 21,282\nColumns: 17\n$ geneid         &lt;chr&gt; \"RFPL1\", \"DUXA\", \"RFPL2\", \"LEUTX\", \"RFPL3S\", \"ZSCAN5C\",…\n$ iDUX4_logFC    &lt;dbl&gt; 9.366333, 8.728522, 8.582827, 8.136148, 8.031894, 7.837…\n$ iDUX4_logCPM   &lt;dbl&gt; 8.568344, 9.740241, 9.760915, 8.702694, 5.563714, 6.532…\n$ iDUX4_LR       &lt;dbl&gt; 2910.21184, 5195.45733, 4397.04659, 3276.44418, 392.901…\n$ iDUX4_pval     &lt;dbl&gt; 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 1.93e-87, 5.12e…\n$ iDUX4_fdr      &lt;dbl&gt; 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 8.64e-86, 5.76e…\n$ hl.ratio       &lt;dbl&gt; 4.415276, 8.919536, 3.032258, 7.151629, NA, 3.910093, N…\n$ area           &lt;dbl&gt; 222742.2, 3523464.3, 119468.9, 1579141.5, NA, 307343.6,…\n$ protein.length &lt;dbl&gt; 317, 204, 378, 168, NA, 496, NA, NA, 465, NA, 474, NA, …\n$ rep            &lt;dbl&gt; 3.760000, 3.500000, 3.888889, 3.333333, NA, 4.000000, N…\n$ IQR            &lt;dbl&gt; 1.952243, 6.435921, 1.694725, 5.303046, NA, 0.000000, N…\n$ QCoD           &lt;dbl&gt; 0.4421564, 0.7215533, 0.5588985, 0.7415158, NA, 0.00000…\n$ count          &lt;dbl&gt; 25, 32, 9, 6, NA, 1, NA, NA, 21, NA, 10, NA, 1, 80, NA,…\n$ mean           &lt;dbl&gt; 0.004465732, -0.003224870, 0.024341945, -0.009047206, N…\n$ sd             &lt;dbl&gt; 0.17197783, 0.13994973, 0.29149227, 0.38073424, NA, 2.0…\n$ zscore         &lt;dbl&gt; 25.647554, 63.756902, 10.319026, 18.807544, NA, 1.89808…\n$ pval           &lt;dbl&gt; 4.500000e-145, 0.000000e+00, 5.780000e-25, 6.550000e-79…\n\nexp_tbl |&gt; summary()\n\n    geneid           iDUX4_logFC       iDUX4_logCPM       iDUX4_LR        \n Length:21282       Min.   :-3.4751   Min.   : 1.264   Min.   :    0.000  \n Class :character   1st Qu.:-0.9996   1st Qu.: 3.385   1st Qu.:    2.068  \n Mode  :character   Median :-0.3772   Median : 4.780   Median :    9.049  \n                    Mean   :-0.1574   Mean   : 4.801   Mean   :   53.971  \n                    3rd Qu.: 0.3977   3rd Qu.: 6.064   3rd Qu.:   30.949  \n                    Max.   : 9.3663   Max.   :14.915   Max.   :13648.327  \n                    NA's   :8950      NA's   :8950     NA's   :8950       \n   iDUX4_pval       iDUX4_fdr         hl.ratio             area          \n Min.   :0.0000   Min.   :0.0000   Min.   :-19.6540   Min.   :     7952  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: -0.3842   1st Qu.:   290641  \n Median :0.0026   Median :0.0052   Median : -0.0529   Median :   545151  \n Mean   :0.1341   Mean   :0.1520   Mean   : -0.0306   Mean   :  1112496  \n 3rd Qu.:0.1504   3rd Qu.:0.2002   3rd Qu.:  0.2283   3rd Qu.:  1014351  \n Max.   :0.9976   Max.   :0.9980   Max.   : 19.3091   Max.   :878105037  \n NA's   :8950     NA's   :8950     NA's   :15969      NA's   :15969      \n protein.length        rep             IQR               QCoD          \n Min.   :  19.0   Min.   :3.000   Min.   : 0.0000   Min.   :-7521.713  \n 1st Qu.: 260.0   1st Qu.:3.333   1st Qu.: 0.3805   1st Qu.:   -2.960  \n Median : 433.0   Median :3.495   Median : 0.8014   Median :    0.000  \n Mean   : 603.4   Mean   :3.446   Mean   : 1.1079   Mean   :   -1.100  \n 3rd Qu.: 728.0   3rd Qu.:3.560   3rd Qu.: 1.1911   3rd Qu.:    2.122  \n Max.   :8797.0   Max.   :4.000   Max.   :26.1119   Max.   : 3618.200  \n NA's   :15969    NA's   :15969   NA's   :15969     NA's   :15969      \n     count             mean               sd             zscore        \n Min.   :   1.0   Min.   :-0.1496   Min.   :0.0152   Min.   :-77.7125  \n 1st Qu.:   2.0   1st Qu.:-0.0024   1st Qu.:0.1453   1st Qu.: -1.1955  \n Median :   8.0   Median : 0.0024   Median :0.3121   Median : -0.1833  \n Mean   :  42.1   Mean   : 0.0239   Mean   :0.6794   Mean   :  0.2260  \n 3rd Qu.:  31.0   3rd Qu.: 0.0315   3rd Qu.:1.3565   3rd Qu.:  0.7153  \n Max.   :2646.0   Max.   : 0.3272   Max.   :2.5400   Max.   :105.5495  \n NA's   :15969    NA's   :15969     NA's   :15969    NA's   :15969     \n      pval       \n Min.   :0.0000  \n 1st Qu.:0.0315  \n Median :0.3171  \n Mean   :0.3816  \n 3rd Qu.:0.7035  \n Max.   :1.0000  \n NA's   :15969   \n\n\nStep 2: Select only the columns we need:\n\n\ngeneid (gene identifier)\n\niDUX4_logFC (RNA fold change)\n\niDUX4_fdr (RNA pvalue)\n\nhl.ratio (protein fold change)\n\npval (protein pvalue)\n\nUse select() and list the columns you want to keep:\n\nexp_tbl |&gt;\n  select(geneid, iDUX4_logFC, iDUX4_fdr, hl.ratio, pval)\n\n# A tibble: 21,282 × 5\n   geneid   iDUX4_logFC iDUX4_fdr hl.ratio       pval\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 RFPL1           9.37 0             4.42  4.50e-145\n 2 DUXA            8.73 0             8.92  0        \n 3 RFPL2           8.58 0             3.03  5.78e- 25\n 4 LEUTX           8.14 0             7.15  6.55e- 79\n 5 RFPL3S          8.03 8.64e- 86    NA    NA        \n 6 ZSCAN5C         7.84 5.76e-169     3.91  5.77e-  2\n 7 USP29           7.71 4.48e- 36    NA    NA        \n 8 FAM189A2        7.68 1.46e- 41    NA    NA        \n 9 CCNA1           7.66 0             5.11  7.10e-169\n10 ZNF280A         7.55 2.35e- 54    NA    NA        \n# ℹ 21,272 more rows\n\n\nStep 3: Rename columns for clarity (this makes your code more readable).\nUse dplyr::rename() with the pattern new_name = old_name, ...:\n\nexp_tbl |&gt;\n  select(geneid, iDUX4_logFC, iDUX4_fdr, hl.ratio, pval) |&gt;\n  rename(\n    rna_FC = iDUX4_logFC,\n    rna_pval = iDUX4_fdr,\n    protein_FC = hl.ratio,\n    protein_pval = pval\n  )\n\n# A tibble: 21,282 × 5\n   geneid   rna_FC  rna_pval protein_FC protein_pval\n   &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 RFPL1      9.37 0               4.42    4.50e-145\n 2 DUXA       8.73 0               8.92    0        \n 3 RFPL2      8.58 0               3.03    5.78e- 25\n 4 LEUTX      8.14 0               7.15    6.55e- 79\n 5 RFPL3S     8.03 8.64e- 86      NA      NA        \n 6 ZSCAN5C    7.84 5.76e-169       3.91    5.77e-  2\n 7 USP29      7.71 4.48e- 36      NA      NA        \n 8 FAM189A2   7.68 1.46e- 41      NA      NA        \n 9 CCNA1      7.66 0               5.11    7.10e-169\n10 ZNF280A    7.55 2.35e- 54      NA      NA        \n# ℹ 21,272 more rows\n\n\nStep 4: Clean the data by removing rows with missing values. Use drop_na() to remove rows with any missing values, and distinct() to remove duplicate rows:\n\nexp_tbl |&gt;\n  select(geneid, iDUX4_logFC, iDUX4_fdr, hl.ratio, pval) |&gt;\n  rename(\n    rna_FC = iDUX4_logFC,\n    rna_pval = iDUX4_fdr,\n    protein_FC = hl.ratio,\n    protein_pval = pval\n  ) |&gt;\n  drop_na() |&gt; # Remove rows with any missing values\n  distinct() # Remove duplicate rows\n\n# A tibble: 4,931 × 5\n   geneid   rna_FC  rna_pval protein_FC protein_pval\n   &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 RFPL1      9.37 0               4.42    4.50e-145\n 2 DUXA       8.73 0               8.92    0        \n 3 RFPL2      8.58 0               3.03    5.78e- 25\n 4 LEUTX      8.14 0               7.15    6.55e- 79\n 5 ZSCAN5C    7.84 5.76e-169       3.91    5.77e-  2\n 6 CCNA1      7.66 0               5.11    7.10e-169\n 7 PRAMEF1    7.54 0               4.82    3.49e- 76\n 8 TPRX1      7.29 2.41e-132       7.35    2.85e-  4\n 9 PRAMEF12   7.25 0               7.55    0        \n10 RFPL4B     7.16 0               7.46    0        \n# ℹ 4,921 more rows\n\n\nStep 5: Finally, arrange the data and save it. Use arrange() to sort by RNA fold change (high to low), then protein fold change (low to high):\n\nexp_tbl_subset &lt;- exp_tbl |&gt;\n  select(geneid, iDUX4_logFC, iDUX4_fdr, hl.ratio, pval) |&gt;\n  rename(\n    rna_FC = iDUX4_logFC,\n    rna_pval = iDUX4_fdr,\n    protein_FC = hl.ratio,\n    protein_pval = pval\n  ) |&gt;\n  drop_na() |&gt;\n  distinct() |&gt;\n  arrange(desc(rna_FC), protein_FC) # Sort by RNA fold change (high to low), then protein fold change (low to high)\n\nexp_tbl_subset\n\n# A tibble: 4,931 × 5\n   geneid   rna_FC  rna_pval protein_FC protein_pval\n   &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 RFPL1      9.37 0               4.42    4.50e-145\n 2 DUXA       8.73 0               8.92    0        \n 3 RFPL2      8.58 0               3.03    5.78e- 25\n 4 LEUTX      8.14 0               7.15    6.55e- 79\n 5 ZSCAN5C    7.84 5.76e-169       3.91    5.77e-  2\n 6 CCNA1      7.66 0               5.11    7.10e-169\n 7 PRAMEF1    7.54 0               4.82    3.49e- 76\n 8 TPRX1      7.29 2.41e-132       7.35    2.85e-  4\n 9 PRAMEF12   7.25 0               7.55    0        \n10 RFPL4B     7.16 0               7.46    0        \n# ℹ 4,921 more rows"
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#question-3-5-points",
    "href": "problem-set-keys/ps-key-04.html#question-3-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 3 5 points\n",
    "text": "Question 3 5 points\n\nLet’s practice good data analysis habits by checking for potential issues. Quality control is essential in real data analysis.\nCheck for duplicates and missing values:\n\nUse count() to check for duplicate genes\nUse summarize() with across() to count missing values in all columns\nUse summary statistics to understand data distributions\n\n\n# Check for duplicate genes (there shouldn't be any after distinct())\ndup_tbl &lt;-\n  exp_tbl_subset |&gt;\n  count(geneid) |&gt;\n  filter(n &gt; 1) # Any genes appearing more than once?\n\nThere are 14 duplicate genes in the dataset.\n\n# Summary of missing values by column\nexp_tbl_subset |&gt;\n  summarize(\n    across(everything(), ~ sum(is.na(.)))\n  )\n\n# A tibble: 1 × 5\n  geneid rna_FC rna_pval protein_FC protein_pval\n   &lt;int&gt;  &lt;int&gt;    &lt;int&gt;      &lt;int&gt;        &lt;int&gt;\n1      0      0        0          0            0\n\n\n\n# Look at the distribution of our main variables\nexp_tbl_subset |&gt;\n  summarize(\n    across(\n      c(rna_FC, protein_FC),\n      list(\n        mean = ~ mean(., na.rm = TRUE),\n        median = ~ median(., na.rm = TRUE),\n        sd = ~ sd(., na.rm = TRUE)\n      )\n    ),\n    .groups = \"drop\"\n  )\n\n# A tibble: 1 × 6\n  rna_FC_mean rna_FC_median rna_FC_sd protein_FC_mean protein_FC_median\n        &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;           &lt;dbl&gt;             &lt;dbl&gt;\n1      -0.176        -0.309      1.12         -0.0376           -0.0543\n# ℹ 1 more variable: protein_FC_sd &lt;dbl&gt;\n\n\nFor your reference, here are three different ways to write the same function inside across(). They all compute the mean while ignoring NA values.\n\nexp_tbl_subset |&gt;\n  summarize(\n    across(\n      c(rna_FC, protein_FC),\n      list(\n        # Three different ways to write the same function\n        mean1 = ~ mean(., na.rm = TRUE),\n        mean2 = function(x) mean(, na.rm = TRUE),\n        mean3 = \\(x) mean(x, na.rm = TRUE),\n      )\n    )\n  )"
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#question-4-5-points",
    "href": "problem-set-keys/ps-key-04.html#question-4-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 4 5 points\n",
    "text": "Question 4 5 points\n\nHow well do the overall rna_FC and protein_FC values correlate in this experiment? We’ll explore this with visualization and statistics.\nStep 1: Create a scatter plot of rna_FC vs protein_FC using ggplot(). Use:\n\n\naes() to map x and y variables\n\ngeom_point() to create the scatter plot\n\nlabs() to add informative axis labels and title\n\n\nggplot(\n  exp_tbl_subset,\n  aes(\n    x = rna_FC,\n    y = protein_FC\n  )\n) +\n  geom_point() +\n  labs(\n    x = \"RNA Fold Change (log2)\",\n    y = \"Protein Fold Change (log2)\",\n    title = \"RNA vs Protein Expression Changes\"\n  )\n\n\n\n\n\n\n\nStep 2: Add reference lines to help interpret the correlation. Use:\n\n\ngeom_abline(slope = 1, intercept = 0) for perfect correlation line\n\ngeom_smooth(method = \"lm\", se = FALSE) for the computed trend line\nadjust the geom_point() aesthetic to alpha = 0.6, making points slightly transparent for better visualization\n\n\nggplot(\n  exp_tbl_subset,\n  aes(\n    x = rna_FC,\n    y = protein_FC\n  )\n) +\n  geom_point(alpha = 0.6) + # Make points a bit transparent\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linewidth = 1) + # Perfect correlation line\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\", linewidth = 1) + # Actual relationship\n  labs(\n    x = \"RNA Fold Change (log2)\",\n    y = \"Protein Fold Change (log2)\",\n    title = \"RNA vs Protein Expression Changes\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nStep 3: Calculate the correlation coefficient using cor(). Use Spearman correlation since it’s robust to outliers. Use ?cor to see the function documentation. You will need to specify two vectors for the calculation, and it’s easiest to provide them using the $ operator to extract columns from the data frame.\n\nrna_prot_cor &lt;- cor(\n  exp_tbl_subset$rna_FC,\n  exp_tbl_subset$protein_FC,\n  method = \"spearman\"\n)\n\nrna_prot_cor\n\n[1] 0.3458433\n\n\nAnswer\nThe green line shows perfect correlation (y = x), and the blue line shows the actual relationship in our data. The Spearman correlation is 0.346, indicating a strong positive correlation between RNA and protein changes, but not perfect correlation."
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#submit",
    "href": "problem-set-keys/ps-key-04.html#submit",
    "title": "R Bootcamp Problem Set 4",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of this Posit Cloud project into the problem set on Canvas."
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html",
    "href": "problem-set-keys/ps-key-02.html",
    "title": "Problem Set 2 Key",
    "section": "",
    "text": "Each problem below is worth 4 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Aug 27.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html#problem-set",
    "href": "problem-set-keys/ps-key-02.html#problem-set",
    "title": "Problem Set 2 Key",
    "section": "",
    "text": "Each problem below is worth 4 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Aug 27.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html#question-1",
    "href": "problem-set-keys/ps-key-02.html#question-1",
    "title": "Problem Set 2 Key",
    "section": "Question 1",
    "text": "Question 1\nStart by loading the libraries you need for analysis below. When in doubt, start by loading the tidyverse package. You should also load here.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950\n\n\nNow import the dataset data_transcript_exp_subset using the readr package. Use read_csv() to import the file.\nThe file is located at data/data_transcript_exp_subset.csv.gz - use here() to create the complete path.\n\nx &lt;- read_csv(here(\"data/bootcamp/data_transcript_exp_subset.csv.gz\"))\n\nRows: 100 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): ensembl_transcript_id\ndbl (6): rna_0h_rep1, rna_0h_rep2, rna_0h_rep3, rna_14h_rep1, rna_14h_rep2, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html#question-2",
    "href": "problem-set-keys/ps-key-02.html#question-2",
    "title": "Problem Set 2 Key",
    "section": "Question 2",
    "text": "Question 2\nExplore the dataset. Is this dataset tidy? If not, why not?\nThis data frame is a subset (100 lines) of transcript-level gene expression data where transcript abundance was measured at two different time points of a certain treatment conducted in triplicates. The column names have the format of molecule_time_replicate\nFirst, explore the structure of the dataset using some of the functions we learned in class. Try using glimpse(), summary(), and names() to understand the data structure.\n\nx\n\n# A tibble: 100 × 7\n   ensembl_transcript_id        rna_0h_rep1 rna_0h_rep2 rna_0h_rep3 rna_14h_rep1\n   &lt;chr&gt;                              &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n 1 ENST00000327044.6_51_2298          243         322         303         177   \n 2 ENST00000338591.7_360_2034          19          17          15           9   \n 3 ENST00000379389.4_176_647           45          53          48          11   \n 4 ENST00000379370.6_1158_6186         42          50          52          32   \n 5 ENST00000379339.5_212_1352          17          19          25           3   \n 6 ENST00000263741.11_1328_1496        27.5        33.7        36.3        22.5 \n 7 ENST00000360001.10_285_1350        158         170.        171.        121   \n 8 ENST00000263741.11_315_1338        148.        162.        158.        116.  \n 9 ENST00000379198.3_138_1002          11          21          23           6   \n10 ENST00000347370.6_475_1096          27.3        23.8        28.5         7.33\n# ℹ 90 more rows\n# ℹ 2 more variables: rna_14h_rep2 &lt;dbl&gt;, rna_14h_rep3 &lt;dbl&gt;\n\n\n\n# Let's explore the data more systematically\n# Look at the column names\nnames(x)\n\n[1] \"ensembl_transcript_id\" \"rna_0h_rep1\"           \"rna_0h_rep2\"          \n[4] \"rna_0h_rep3\"           \"rna_14h_rep1\"          \"rna_14h_rep2\"         \n[7] \"rna_14h_rep3\"         \n\n\n\nsummary(x)\n\n ensembl_transcript_id  rna_0h_rep1       rna_0h_rep2        rna_0h_rep3      \n Length:100            Min.   :   0.00   Min.   :    0.00   Min.   :    0.00  \n Class :character      1st Qu.:  10.70   1st Qu.:   11.88   1st Qu.:   11.12  \n Mode  :character      Median :  27.41   Median :   31.05   Median :   31.91  \n                       Mean   : 173.31   Mean   :  196.08   Mean   :  186.10  \n                       3rd Qu.:  87.08   3rd Qu.:  105.00   3rd Qu.:   88.33  \n                       Max.   :9802.00   Max.   :11144.00   Max.   :10619.00  \n  rna_14h_rep1       rna_14h_rep2       rna_14h_rep3     \n Min.   :   0.000   Min.   :   0.000   Min.   :   0.000  \n 1st Qu.:   3.875   1st Qu.:   3.962   1st Qu.:   5.000  \n Median :  10.435   Median :   9.665   Median :   9.665  \n Mean   : 102.875   Mean   :  93.370   Mean   : 111.515  \n 3rd Qu.:  41.000   3rd Qu.:  38.750   3rd Qu.:  48.750  \n Max.   :5292.000   Max.   :5090.000   Max.   :6012.000  \n\n\n\nglimpse(x)\n\nRows: 100\nColumns: 7\n$ ensembl_transcript_id &lt;chr&gt; \"ENST00000327044.6_51_2298\", \"ENST00000338591.7_…\n$ rna_0h_rep1           &lt;dbl&gt; 243.00, 19.00, 45.00, 42.00, 17.00, 27.50, 158.0…\n$ rna_0h_rep2           &lt;dbl&gt; 322.00, 17.00, 53.00, 50.00, 19.00, 33.67, 169.6…\n$ rna_0h_rep3           &lt;dbl&gt; 303.00, 15.00, 48.00, 52.00, 25.00, 36.33, 171.3…\n$ rna_14h_rep1          &lt;dbl&gt; 177.00, 9.00, 11.00, 32.00, 3.00, 22.50, 121.00,…\n$ rna_14h_rep2          &lt;dbl&gt; 177.00, 5.00, 5.00, 31.00, 0.00, 29.17, 124.17, …\n$ rna_14h_rep3          &lt;dbl&gt; 239.00, 8.00, 14.00, 30.00, 2.00, 27.33, 155.33,…\n\n\nComment on whether this dataset is tidy, and if not, list the reasons why.\nHint: In a tidy dataframe, every column represents a single variable and every row represents a single observation\nAnswer\nIt is not tidy because: 1. The time points and replicates are not in their own columns 2. Multiple variables (molecule type, time, replicate) are encoded in column names 3. Each row contains multiple observations (different time points and replicates)"
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html#question-3",
    "href": "problem-set-keys/ps-key-02.html#question-3",
    "title": "Problem Set 2 Key",
    "section": "Question 3",
    "text": "Question 3\nHow will you reshape the data frame so that each row has only one experimental observation?\nBefore we reshape, let’s think about what we want:\n\nWhich column should stay the same? (The transcript ID)\nWhich columns contain the measurements? (All the others)\nWhat should we call the new column names?\n\nUse pivot_longer() to reshape the data. You’ll want to:\n\nKeep the ensembl_transcript_id column as-is (use cols = -ensembl_transcript_id)\nCreate a new column for the condition names (use names_to = \"condition\")\nCreate a new column for the values (use values_to = \"count\")\n\n\n# Reshape the data so each row is one observation\nx_long &lt;-\n  pivot_longer(\n    x,\n    cols = -ensembl_transcript_id, # everything except the ID column\n    names_to = \"condition\", # new column for the condition names\n    values_to = \"count\" # new column for the count values\n  )\n\nx_long\n\n# A tibble: 600 × 3\n   ensembl_transcript_id      condition    count\n   &lt;chr&gt;                      &lt;chr&gt;        &lt;dbl&gt;\n 1 ENST00000327044.6_51_2298  rna_0h_rep1    243\n 2 ENST00000327044.6_51_2298  rna_0h_rep2    322\n 3 ENST00000327044.6_51_2298  rna_0h_rep3    303\n 4 ENST00000327044.6_51_2298  rna_14h_rep1   177\n 5 ENST00000327044.6_51_2298  rna_14h_rep2   177\n 6 ENST00000327044.6_51_2298  rna_14h_rep3   239\n 7 ENST00000338591.7_360_2034 rna_0h_rep1     19\n 8 ENST00000338591.7_360_2034 rna_0h_rep2     17\n 9 ENST00000338591.7_360_2034 rna_0h_rep3     15\n10 ENST00000338591.7_360_2034 rna_14h_rep1     9\n# ℹ 590 more rows\n\n\nQuestion 4\nHow will you modify the dataframe so that multiple variables are not present in a single column?\nUse separate_wider_delim() to split the condition column into separate variables. You need to:\n\nSpecify which column to separate (condition)\nSpecify the delimiter character (delim = \"_\")\nProvide the new column names (names = c(\"molecule\", \"timepoint\", \"replicate\"))\n\n\nx_tidy &lt;-\n  separate_wider_delim(\n    x_long,\n    condition,\n    delim = \"_\",\n    names = c(\"molecule\", \"timepoint\", \"replicate\")\n  )\n\nx_tidy\n\n# A tibble: 600 × 5\n   ensembl_transcript_id      molecule timepoint replicate count\n   &lt;chr&gt;                      &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;\n 1 ENST00000327044.6_51_2298  rna      0h        rep1        243\n 2 ENST00000327044.6_51_2298  rna      0h        rep2        322\n 3 ENST00000327044.6_51_2298  rna      0h        rep3        303\n 4 ENST00000327044.6_51_2298  rna      14h       rep1        177\n 5 ENST00000327044.6_51_2298  rna      14h       rep2        177\n 6 ENST00000327044.6_51_2298  rna      14h       rep3        239\n 7 ENST00000338591.7_360_2034 rna      0h        rep1         19\n 8 ENST00000338591.7_360_2034 rna      0h        rep2         17\n 9 ENST00000338591.7_360_2034 rna      0h        rep3         15\n10 ENST00000338591.7_360_2034 rna      14h       rep1          9\n# ℹ 590 more rows\n\n\nQuestion 5\nHow will you save your output as a TSV file?\nUse write_tsv() from the readr package to save your tidy data. Provide the data object and a filename.\nHint: Use the readr cheatsheet at the bottom of this page to figure this out.\nAfter running your new code, you should have a new file called transcripts.tidy.tsv in your working directory.\n\nwrite_tsv(x_tidy, \"transcripts.tidy.tsv\")\n\nQuestion 6\nCan you reverse the process? How would you go from tidy back to wide format?\nUse pivot_wider() to go from the tidy format back to the original wide format. You need to:\n\nSpecify where the new column names come from (names_from = c(molecule, timepoint, replicate))\nSpecify where the values come from (values_from = count)\nSpecify how to combine the names (names_sep = \"_\")\n\n\n# Going back to wide format\npivot_wider(\n  x_tidy,\n  names_from = c(molecule, timepoint, replicate),\n  values_from = count,\n  names_sep = \"_\"\n)\n\n# A tibble: 100 × 7\n   ensembl_transcript_id        rna_0h_rep1 rna_0h_rep2 rna_0h_rep3 rna_14h_rep1\n   &lt;chr&gt;                              &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n 1 ENST00000327044.6_51_2298          243         322         303         177   \n 2 ENST00000338591.7_360_2034          19          17          15           9   \n 3 ENST00000379389.4_176_647           45          53          48          11   \n 4 ENST00000379370.6_1158_6186         42          50          52          32   \n 5 ENST00000379339.5_212_1352          17          19          25           3   \n 6 ENST00000263741.11_1328_1496        27.5        33.7        36.3        22.5 \n 7 ENST00000360001.10_285_1350        158         170.        171.        121   \n 8 ENST00000263741.11_315_1338        148.        162.        158.        116.  \n 9 ENST00000379198.3_138_1002          11          21          23           6   \n10 ENST00000347370.6_475_1096          27.3        23.8        28.5         7.33\n# ℹ 90 more rows\n# ℹ 2 more variables: rna_14h_rep2 &lt;dbl&gt;, rna_14h_rep3 &lt;dbl&gt;"
  },
  {
    "objectID": "prepare/prepare-08.html",
    "href": "prepare/prepare-08.html",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look through this study from Brauer et al. This is a rich data set for exploring relationships between gene expression and cellular physiology. Focus on familiarizing yourself with the design of the experiment.\n\nBrauer MJ, Huttenhower C, Airoldi EM, Rosenstein R, Matese JC, Gresham D, Boer VM, Troyanskaya OG, Botstein D. Coordination of growth rate, cell cycle, stress response, and metabolic activity in yeast. Mol Biol Cell. 2008 Jan;19(1):352-67. doi: 10.1091/mbc.e07-08-0779. Epub 2007 Oct 24. PMID: 17959824; PMCID: PMC2174172."
  },
  {
    "objectID": "prepare/prepare-08.html#prepare",
    "href": "prepare/prepare-08.html#prepare",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look through this study from Brauer et al. This is a rich data set for exploring relationships between gene expression and cellular physiology. Focus on familiarizing yourself with the design of the experiment.\n\nBrauer MJ, Huttenhower C, Airoldi EM, Rosenstein R, Matese JC, Gresham D, Boer VM, Troyanskaya OG, Botstein D. Coordination of growth rate, cell cycle, stress response, and metabolic activity in yeast. Mol Biol Cell. 2008 Jan;19(1):352-67. doi: 10.1091/mbc.e07-08-0779. Epub 2007 Oct 24. PMID: 17959824; PMCID: PMC2174172."
  },
  {
    "objectID": "prepare/prepare-04.html",
    "href": "prepare/prepare-04.html",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look over the ggplot2 cheatsheet.\nWe’ll be using the basic ggplot2 structure with ggplot(), aes(), and various geom_*() functions like geom_point(), geom_bar(), and geom_histogram(). Pay special attention to the aesthetics section (color, size, shape) and the faceting functions facet_wrap() and facet_grid()."
  },
  {
    "objectID": "prepare/prepare-04.html#prepare",
    "href": "prepare/prepare-04.html#prepare",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look over the ggplot2 cheatsheet.\nWe’ll be using the basic ggplot2 structure with ggplot(), aes(), and various geom_*() functions like geom_point(), geom_bar(), and geom_histogram(). Pay special attention to the aesthetics section (color, size, shape) and the faceting functions facet_wrap() and facet_grid()."
  },
  {
    "objectID": "prepare/prepare-02.html",
    "href": "prepare/prepare-02.html",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look over the tidyr cheatsheet.\nWe’ll be using the pivot_*, separate(), and unite() functions, and discuss handling NA values. We won’t cover the nesting appproaches tomorrow so you can skip for now (skip the back page)."
  },
  {
    "objectID": "prepare/prepare-02.html#prepare",
    "href": "prepare/prepare-02.html#prepare",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look over the tidyr cheatsheet.\nWe’ll be using the pivot_*, separate(), and unite() functions, and discuss handling NA values. We won’t cover the nesting appproaches tomorrow so you can skip for now (skip the back page)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MOLB 7950: Informatics and Statistics for Molecular Biology",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMOLB 7950 - Fall 2025 Schedule\n\n\nClasses held in-person from 9:00-10:30am in AHSB 2200\n\n\n\nDate\nBlock\nTopic\nInstructor\nTitle\n\nLinks\n\n\n\nPrepare\nSlides\nExercises\nHW\nKey\n\n\n\n\nWeek 1\n\n\n01\nMon, Aug 25, 2025\nBootcamp\nR\nHesselberth\nIntro to R & RStudio\n📖\n📄\n💪\n🧠\n🔑\n\n\n02\nTue, Aug 26, 2025\nBootcamp\nR\nHesselberth\nTidy data & tidyr\n📖\n📄\n💪\n🧠\n🔑\n\n\n03\nWed, Aug 27, 2025\nBootcamp\nR\nHesselberth\ndplyr\n📖\n📄\n💪\n🧠\n🔑\n\n\n04\nThu, Aug 28, 2025\nBootcamp\nR\nHesselberth\nggplot2\n📖\n📄\n💪\n🧠\n🔑\n\n\n05\nFri, Aug 29, 2025\nBootcamp\nR\nHesselberth\nggplot2\n.\n📄\n💪\n🧠\n.\n\n\nWeek 2\n\n\n06\nMon, Sep 1, 2025\n-\n-\n-\nNO CLASS - LABOR DAY\n.\n.\n.\n.\n.\n\n\n07\nTue, Sep 2, 2025\nBootcamp\nR\nHesselberth\ntidyverse odds & ends\n📖\n📄\n💪\n.\n.\n\n\n08\nWed, Sep 3, 2025\nBootcamp\nR\nHesselberth\nputting it all together\n📖\n.\n💪\n🧠\n.\n\n\n09\nThu, Sep 4, 2025\nBootcamp\nR\nHesselberth\nputting it all together\n.\n.\n.\n.\n.\n\n\n10\nFri, Sep 5, 2025\nBootcamp\nStatistics\nMukherjee\nStats intro and history\n.\n📄\n💪\n.\n.\n\n\nWeek 3\n\n\n11\nMon, Sep 8, 2025\nBootcamp\nStatistics\nMukherjee\nProbability and descriptive stats\n.\n📄\n💪\n🧠\n.\n\n\n12\nTue, Sep 9, 2025\nBootcamp\nStatistics\nMukherjee\nHypothesis testing\n.\n📄\n💪\n🧠\n.\n\n\n13\nWed, Sep 10, 2025\nBootcamp\nStatistics\nMukherjee\nHypothesis testing\n.\n📄\n💪\n🧠\n.\n\n\n14\nThu, Sep 11, 2025\nBootcamp\nStatistics\nMukherjee\nExploratory data analysis\n.\n📄\n💪\n🧠\n.\n\n\n15\nFri, Sep 12, 2025\nBootcamp\nStatistics\nMukherjee\nBig data concerns\n.\n📄\n💪\n🧠\n.\n\n\nWeek 4\n\n\n16\nMon, Sep 15, 2025\nDNA\nMapping chromatin structure and transactions\nHesselberth\nExperimental overview\n.\n.\n.\n.\n.\n\n\n17\nWed, Sep 17, 2025\nDNA\nChromatin-centric methods\nHesselberth\nInformation from fragment length distributions\n.\n.\n.\n.\n.\n\n\n18\nFri, Sep 19, 2025\nDNA\nChromatin-centric methods\nHesselberth\nMeta-plots and heatmaps\n.\n.\n.\n.\n.\n\n\nWeek 5\n\n\n19\nMon, Sep 22, 2025\nDNA\nWhere do proteins bind in the genome?\nHesselberth\nExperimental overview\n.\n.\n.\n.\n.\n\n\n20\nWed, Sep 24, 2025\nDNA\nFactor-centric methods\nHesselberth\nPeak calling\n.\n.\n.\n.\n.\n\n\n21\nFri, Sep 26, 2025\nDNA\nFactor-centric methods\nHesselberth\nSequence motif analysis\n.\n.\n.\n.\n.\n\n\nWeek 6\n\n\n22\nMon, Sep 29, 2025\nRNA\nRNA-seq Overview\nMukherjee\nConcepts and techniques\n.\n.\n.\n.\n.\n\n\n23\nWed, Oct 1, 2025\nRNA\nImport, filtering, QC\nMukherjee\nmetrics and sample similarity\n.\n.\n.\n.\n.\n\n\n24\nFri, Oct 3, 2025\nRNA\nDifferential Gene Expression\nMukherjee\nDESeq2\n.\n.\n.\n.\n.\n\n\nWeek 7\n\n\n25\nMon, Oct 6, 2025\nRNA\nAlternative Splicing\nMukherjee\nrMATS\n.\n.\n.\n.\n.\n\n\n26\nWed, Oct 8, 2025\nRNA\nReview Proposals\nHesselberth\nReview Proposals\n.\n.\n.\n.\n.\n\n\n27\nFri, Oct 10, 2025\nRNA\nRBP-RNA 1\nMukherjee\nCLIP-seq\n.\n.\n.\n.\n.\n\n\nWeek 8\n\n\n28\nMon, Oct 13, 2025\nRNA\nRBP-RNA 2\nMukherjee\nData integrations\n.\n.\n.\n.\n.\n\n\n29\nWed, Oct 15, 2025\nRNA\nLong-read sequencing\nHesselberth\n-\n.\n.\n.\n.\n.\n\n\n30\nFri, Oct 17, 2025\n-\n-\n-\nNO CLASS: MOLB RETREAT\n.\n.\n.\n.\n.\n\n\nWeek 9\n\n\n31\nMon, Oct 20, 2025\nRNA\nSingle-cell\nWells-Wrasman\n-\n.\n.\n.\n.\n.\n\n\n32\nWed, Oct 22, 2025\nRNA\nSingle-cell\nWells-Wrasman\n-\n.\n.\n.\n.\n.\n\n\n33\nFri, Oct 24, 2025\n-\n-\n-\nNO CLASS: CSDV RETREAT\n.\n.\n.\n.\n.\n\n\nWeek 10\n\n\n34\nMon, Oct 27, 2025\nFinal\n-\n-\nFinal project presentations\n.\n.\n.\n.\n.\n\n\n35\nWed, Oct 29, 2025\nFinal\n-\n-\nFinal project presentations\n.\n.\n.\n.\n.",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "exercises/ex-14.html",
    "href": "exercises/ex-14.html",
    "title": "Stats Bootcamp - class 14",
    "section": "",
    "text": "# we are reading the data directly from the internet\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1,6,9,14,15,24:28)]\nbiochem &lt;- biochem[,keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\",\"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename sex to sex\nb &lt;- inner_join(biochem, weight, by=\"subject_name\") |&gt;\n  na.omit() |&gt;\n  rename(sex=gender)"
  },
  {
    "objectID": "exercises/ex-14.html#prepare-mouse-biochem-data",
    "href": "exercises/ex-14.html#prepare-mouse-biochem-data",
    "title": "Stats Bootcamp - class 14",
    "section": "",
    "text": "# we are reading the data directly from the internet\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1,6,9,14,15,24:28)]\nbiochem &lt;- biochem[,keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\",\"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename sex to sex\nb &lt;- inner_join(biochem, weight, by=\"subject_name\") |&gt;\n  na.omit() |&gt;\n  rename(sex=gender)"
  },
  {
    "objectID": "exercises/ex-14.html#learning-objectives",
    "href": "exercises/ex-14.html#learning-objectives",
    "title": "Stats Bootcamp - class 14",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\nFormulate and Execute null hypothesis testing\n\nIdentify and Perform the proper statistical test for data type/comparison\n\nCalculate and Interpret p-values"
  },
  {
    "objectID": "exercises/ex-14.html#random-variables",
    "href": "exercises/ex-14.html#random-variables",
    "title": "Stats Bootcamp - class 14",
    "section": "Random variables",
    "text": "Random variables\nResponse Variable ( y - aka dependent or outcome variable): this variable is predicted or its variation is explained by the explanatory variable. In an experiment, this is the outcome that is measured following manipulation of the explanatory variable.\nExplanatory Variable ( x - aka independent or predictor variable): explains variations in the response variable. In an experiment, it is manipulated by the researcher."
  },
  {
    "objectID": "exercises/ex-14.html#the-simplicity-underlying-common-tests",
    "href": "exercises/ex-14.html#the-simplicity-underlying-common-tests",
    "title": "Stats Bootcamp - class 14",
    "section": "The simplicity underlying common tests",
    "text": "The simplicity underlying common tests\nMost of the common statistical models (t-test, correlation, ANOVA; etc.) are special cases of linear models or a very close approximation. This simplicity means that there is less to learn. It all comes down to:\n\n\\(y = a \\cdot x + b\\)\n\nThis needless complexity multiplies when students try to rote learn the parametric assumptions underlying each test separately rather than deducing them from the linear model."
  },
  {
    "objectID": "exercises/ex-14.html#stats-equation-for-a-line",
    "href": "exercises/ex-14.html#stats-equation-for-a-line",
    "title": "Stats Bootcamp - class 14",
    "section": "Stats equation for a line",
    "text": "Stats equation for a line\nModel:\n\\(y\\) equals the intercept (\\(\\beta_0\\)) pluss a slope (\\(\\beta_1\\)) times \\(x\\).\n\\(y = \\beta_0 + \\beta_1 x \\qquad \\qquad \\mathcal{H}_0: \\beta_1 = 0\\)\n… which is the same as \\(y = b + a \\cdot x\\).\nThe short hand for this in R: y ~ 1 + x\nR interprets this as:\ny = 1*number + x*othernumber\nThe task of t-tests, lm, etc., is simply to find the numbers that best predict \\(y\\)."
  },
  {
    "objectID": "exercises/ex-14.html#appropriate-statistical-test-cheatsheet",
    "href": "exercises/ex-14.html#appropriate-statistical-test-cheatsheet",
    "title": "Stats Bootcamp - class 14",
    "section": "Appropriate statistical test cheatsheet",
    "text": "Appropriate statistical test cheatsheet"
  },
  {
    "objectID": "exercises/ex-14.html#comparing-means-between-two-groups",
    "href": "exercises/ex-14.html#comparing-means-between-two-groups",
    "title": "Stats Bootcamp - class 14",
    "section": "Comparing means between two groups",
    "text": "Comparing means between two groups\nWe will compare mouse \\(weight\\) by \\(sex\\).\n\n# plot weight by sex\np_ws &lt;- ggplot(b,\n               aes(x = sex, y = weight)) +\n  geom_jitter(size=1) +\n  geom_hline(yintercept = mean(b$weight),\n             color = \"red\") +\n  theme_cowplot()\n\n\n# plot weight by sex with mean weight and mean weight by sex\np_ws2 &lt;- ggplot(b,\n                aes(x = sex, y = weight)) +\n  geom_jitter(size=1) +\n  geom_hline(yintercept = mean(b$weight),\n             color = \"red\") +\n stat_summary(fun = \"mean\", geom = \"point\",  fill = \"blue\", shape = 23, size=3) +\n  theme_cowplot()\n\nplot_grid(p_ws, p_ws2, ncol = 2, labels = c(\"weight\",\"weight by sex\"), scale = c(1,1))"
  },
  {
    "objectID": "exercises/ex-14.html#step-1-can-mouse-sex-explain-mouse-weight",
    "href": "exercises/ex-14.html#step-1-can-mouse-sex-explain-mouse-weight",
    "title": "Stats Bootcamp - class 14",
    "section": "STEP 1: Can mouse sex explain mouse weight?",
    "text": "STEP 1: Can mouse sex explain mouse weight?\nModel: \\(y_{i} = \\beta_0 \\cdot 1+ \\beta_1 \\cdot x_{i}\\)\nNull Hypothesis: \\(\\mathcal{H}_0: \\beta_1 = 0\\)\n\\(\\mathcal{H}_0:\\) mouse \\(sex\\) does NOT explain \\(weight\\)\nAlternative Hypothesis: \\(\\mathcal{H}_1: \\beta_1 \\neq 0\\)\n\\(\\mathcal{H}_1:\\) mouse \\(sex\\) does explain \\(weight\\)\nImportant: \\(x_{i}\\) is an indicator (0 or 1) saying whether data point i was sampled from one or the other group (female or male).\nWe will explore this in more detail soon."
  },
  {
    "objectID": "exercises/ex-14.html#step-2-fit-linear-model-and-examine-results",
    "href": "exercises/ex-14.html#step-2-fit-linear-model-and-examine-results",
    "title": "Stats Bootcamp - class 14",
    "section": "STEP 2: Fit linear model and examine results",
    "text": "STEP 2: Fit linear model and examine results\n\nfit_ws &lt;-\n\nFit summary:\n\n??(fit_ws) |&gt;\n  gt() |&gt;\n  fmt_number(columns = r.squared:statistic, decimals = 3)\n\nCoefficient summary:\n\n??(fit_ws) |&gt;\n  gt() |&gt;\n  fmt_number(columns =estimate:statistic, decimals = 3)"
  },
  {
    "objectID": "exercises/ex-14.html#collecting-residuals-and-other-information",
    "href": "exercises/ex-14.html#collecting-residuals-and-other-information",
    "title": "Stats Bootcamp - class 14",
    "section": "Collecting residuals and other information",
    "text": "Collecting residuals and other information\nadd residuals and other information\n\n#augment\nb_ws &lt;-\n\n\n# mean weight\navg_w &lt;-\n\n# mean weight female\navg_wf &lt;-\n\n\n# mean weight male\navg_wm &lt;-"
  },
  {
    "objectID": "exercises/ex-14.html#step-3-visualize-the-error-around-fit",
    "href": "exercises/ex-14.html#step-3-visualize-the-error-around-fit",
    "title": "Stats Bootcamp - class 14",
    "section": "STEP 3: Visualize the error around fit",
    "text": "STEP 3: Visualize the error around fit\n\n# plot of data with mean and colored by residuals\n\np_ws &lt;- ggplot(b_ws,\n               aes(x = sex, y = weight)) +\n  geom_point(position = position_jitter(),\n             aes(color = .resid)) +\n  scale_color_gradient2(low = \"blue\",\n                        mid = \"black\",\n                        high = \"yellow\") +\n    geom_hline(yintercept = ??,\n               color = \"darkgrey\") +\n  geom_segment(aes(x=.5, xend=1.5,\n                   y=??, yend=??),\n               color=\"red\") +\n    geom_segment(aes(x=1.5, xend=2.5,\n                     y=??), yend=??,\n                 color=\"red\") +\n  theme_cowplot()\n\np_ws"
  },
  {
    "objectID": "exercises/ex-14.html#step-3-visualize-the-error-around-the-null-mean-weight",
    "href": "exercises/ex-14.html#step-3-visualize-the-error-around-the-null-mean-weight",
    "title": "Stats Bootcamp - class 14",
    "section": "STEP 3: Visualize the error around the null (mean weight)",
    "text": "STEP 3: Visualize the error around the null (mean weight)\n\np_w &lt;- ggplot(b_ws,\n               aes(x = sex, y = weight)) +\n  geom_point(position = position_jitter(),\n             aes(color = weight-avg_w)) +\n  scale_color_gradient2(low = \"blue\",\n                        mid = \"black\",\n                        high = \"yellow\") +\n    geom_hline(yintercept = avg_w,\n               color = \"darkgrey\") +\n  theme_cowplot()\n\np_w"
  },
  {
    "objectID": "exercises/ex-14.html#compare-fit-error-to-null-error-graphically",
    "href": "exercises/ex-14.html#compare-fit-error-to-null-error-graphically",
    "title": "Stats Bootcamp - class 14",
    "section": "Compare fit error to null error graphically",
    "text": "Compare fit error to null error graphically\n\nplot_grid(p_ws, p_w, ncol = 2, labels = c(\"weight by sex\",\"weight by intercept\"))\n\nWe are fitting 2 lines to the data. For the weight by sex model of the fit (left), we fit 2 lines. For the weight by null model (right) we fit 1 line."
  },
  {
    "objectID": "exercises/ex-14.html#exceptions-mice-with-highest-residuals",
    "href": "exercises/ex-14.html#exceptions-mice-with-highest-residuals",
    "title": "Stats Bootcamp - class 14",
    "section": "Exceptions: mice with highest residuals",
    "text": "Exceptions: mice with highest residuals\n\nb_ws |&gt;\n  arrange(??) |&gt;\n  top_n(15) |&gt;\n  select(subject_name,weight,sex,.resid,.fitted) |&gt;\n  gt() |&gt;\n  fmt_number(decimals = 2)"
  },
  {
    "objectID": "exercises/ex-14.html#matrices-interlude-begin",
    "href": "exercises/ex-14.html#matrices-interlude-begin",
    "title": "Stats Bootcamp - class 14",
    "section": "Matrices Interlude Begin\n",
    "text": "Matrices Interlude Begin\n\n\nHow do we go from 2 fit lines to 1 equation\n\nSince we don’t want to calculate any of this by hand, the framework needs to be flexible such that a computer can execute for different flavors of comparison (cont y vs cont x, cont y vs 2 or more categorical x, …)."
  },
  {
    "objectID": "exercises/ex-14.html#lets-focus-on-just-a-few-mice",
    "href": "exercises/ex-14.html#lets-focus-on-just-a-few-mice",
    "title": "Stats Bootcamp - class 14",
    "section": "Let’s focus on just a few mice",
    "text": "Let’s focus on just a few mice\nRemember that:\\(weight\\) is \\(y\\)\\(F_{avg}\\) is the average \\(weight\\) of \\(females\\)\\(M_{avg}\\) is the average \\(weight\\) of \\(males\\)\n. . .\nA048054885, female\\(y_{85}= 1 \\cdot F_{avg} + 0 \\cdot M_{avg} + residual_{85}\\)\nA067109771, female\\(y_{71}= 1 \\cdot F_{avg} + 0 \\cdot M_{avg} + residual_{71}\\)\n. . .\nA066822351, male\\(y_{51}= 0 \\cdot F_{avg} + 1 \\cdot M_{avg} + residual_{51}\\)\nA048274362, male\\(y_{62}= 0 \\cdot F_{avg} + 1 \\cdot M_{avg} + residual_{62}\\)"
  },
  {
    "objectID": "exercises/ex-14.html#lets-focus-on-just-a-few-mice-1",
    "href": "exercises/ex-14.html#lets-focus-on-just-a-few-mice-1",
    "title": "Stats Bootcamp - class 14",
    "section": "Let’s focus on just a few mice",
    "text": "Let’s focus on just a few mice\n\nb_ws |&gt;\n  filter(subject_name %in% c(\"A048054885\",\"A067109771\",\"A066822351\",\"A048274362\")) |&gt;\n  select(subject_name, weight, sex, .fitted, .resid) |&gt;\n  arrange(sex) |&gt;\n  gt()"
  },
  {
    "objectID": "exercises/ex-14.html#need-a-volunteer",
    "href": "exercises/ex-14.html#need-a-volunteer",
    "title": "Stats Bootcamp - class 14",
    "section": "Need a volunteer",
    "text": "Need a volunteer\nMe: Ooohh my, imagine how tedious it would be to do this for all mice…Volunteer: Wait a sec…isn’t there a way to formulate this as a matrix algebra problem.Me: You’re right - I’m so glad you asked! Let’s conjur matrix-magic to solve this problem..\n. . .\n\\(f_{avg} = \\beta_0\\) is the average \\(weight\\) of \\(female\\) mice\\(m_{avg} = \\beta_1\\) is the average \\(weight\\) of \\(male\\) mice\n. . .\n\\(\\begin{bmatrix} y_{85} \\\\ y_{71} \\\\ y_{51} \\\\y_{62} \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 1 & 0 \\\\ 0 & 1 \\\\ 0 & 1 \\end{bmatrix} \\cdot \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\end{bmatrix} + \\begin{bmatrix} e_{85} \\\\ e_{71} \\\\ e_{51} \\\\e_{62} \\end{bmatrix}\\)\n. . .\nSo basically this looks like the same equation for fitting a line we’ve been discussing, just w/a few more dimensions :)\nThis is a conceptual peak into the underbelly of how the \\(\\beta\\) cofficients and least squares is performed using matrix operations (linear algebra). If you are interested in learning more see references at the end of the slides.\nMatrices Interlude FIN"
  },
  {
    "objectID": "exercises/ex-14.html#calculate-r2",
    "href": "exercises/ex-14.html#calculate-r2",
    "title": "Stats Bootcamp - class 14",
    "section": "Calculate \\(R^2\\)\n",
    "text": "Calculate \\(R^2\\)\n\n\\(SS_{fit}\\) — sum of squared errors around the least-squares fit\n\nss_fit &lt;-\n\n\\(SS_{null}\\) — sum of squared errors around the mean of \\(y\\)\n\nss_null &lt;-\n\n\\(R^2 = 1 - \\displaystyle \\frac {SS_{fit}}{SS_{null}}\\)\n\nrsq &lt;- ??\n\n\nglance(fit_ws) |&gt; select(r.squared)\n\nWoohoo!!"
  },
  {
    "objectID": "exercises/ex-14.html#compare-to-traditional-t-test",
    "href": "exercises/ex-14.html#compare-to-traditional-t-test",
    "title": "Stats Bootcamp - class 14",
    "section": "Compare to traditional t-test",
    "text": "Compare to traditional t-test\n\nb |&gt;\n  ?? |&gt;\n  select(-c(n1,n2,df)) |&gt;\n  gt()\n\n\ntidy(fit_ws) |&gt;\n  select(term, estimate, statistic, p.value) |&gt;\n  gt()"
  },
  {
    "objectID": "exercises/ex-14.html#prep-data-for-fams",
    "href": "exercises/ex-14.html#prep-data-for-fams",
    "title": "Stats Bootcamp - class 14",
    "section": "prep data for fams",
    "text": "prep data for fams\n\n# i have pre-selected some families to compare\nmyfams &lt;- c(\"B1.5:E1.4(4) B1.5:A1.4(5)\",\n            \"F1.3:A1.2(3) F1.3:E2.2(3)\",\n            \"A1.3:D1.2(3) A1.3:H1.2(3)\",\n            \"D5.4:G2.3(4) D5.4:C4.3(4)\")\n\n# only keep the familys in myfams\nbfam &lt;- b |&gt;\n  filter(family %in% myfams) |&gt;\n  droplevels()\n\n# simplify family names and make factor\nbfam$family &lt;- gsub(pattern = \"\\\\..*\", replacement = \"\", x = bfam$family) |&gt;\n  as.factor()\n\n\n# make B1 the reference (most similar to overall mean)\nbfam$family &lt;- relevel(x = bfam$family, ref =\"B1\")"
  },
  {
    "objectID": "exercises/ex-14.html#step-1-can-family-explain-weight",
    "href": "exercises/ex-14.html#step-1-can-family-explain-weight",
    "title": "Stats Bootcamp - class 14",
    "section": "STEP 1: Can family explain weight?",
    "text": "STEP 1: Can family explain weight?\nANOVA -&gt; comparing means of 3 or more groups.\nLet’s compare the \\(weight\\) by \\(family\\), but only for a few selected families.\n\nggplot(data = ??,\n       aes(??)) +\n  geom_jitter(width = .2) +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-14.html#what-does-the-model-look-like",
    "href": "exercises/ex-14.html#what-does-the-model-look-like",
    "title": "Stats Bootcamp - class 14",
    "section": "What does the model look like?",
    "text": "What does the model look like?\nModel: \\(y_{i} = \\beta_0 \\cdot 1+ \\beta_1 \\cdot x_{i}\\)\nNull Hypothesis: \\(\\mathcal{H}_0: \\beta_1 = 0\\)\n\\(\\mathcal{H}_0:\\) mouse \\(family\\) does NOT explain \\(weight\\)\nAlternative Hypothesis: \\(\\mathcal{H}_1: \\beta_1 \\neq 0\\)\n\\(\\mathcal{H}_1:\\) mouse \\(family\\) does explain \\(weight\\)\nImportant: \\(x_{i}\\) is an indicator (0 or 1) saying which group point \\(i\\) was sampled from using the matrix encoding of 0s and 1s.\nBelow is an example depicting 6 observations with 2 from each of 3 families:\n\\(\\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ y_{3} \\\\y_{4} \\\\y_{5} \\\\y_{5} \\end{bmatrix} = \\begin{bmatrix} 1 & 0 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 0 & 0 & 1 \\\\ \\end{bmatrix} \\cdot \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\end{bmatrix} + \\begin{bmatrix} e_{1} \\\\ e_{2} \\\\ e_{3} \\\\e_{4} \\\\e_{5} \\\\e_{6} \\end{bmatrix}\\)"
  },
  {
    "objectID": "exercises/ex-14.html#step-2-fit-linear-model-and-examine-results-1",
    "href": "exercises/ex-14.html#step-2-fit-linear-model-and-examine-results-1",
    "title": "Stats Bootcamp - class 14",
    "section": "STEP 2: Fit linear model and examine results",
    "text": "STEP 2: Fit linear model and examine results\n\nfit_wf &lt;- ??\n\nFit summary:\n\nglance(fit_wf) |&gt;\n  gt() |&gt;\n  fmt_number(columns = r.squared:statistic, decimals = 3)\n\nCoefficient summary:\n\ntidy(fit_wf) |&gt;\n  gt() |&gt;\n  fmt_number(columns =estimate:statistic, decimals = 3)"
  },
  {
    "objectID": "exercises/ex-14.html#collecting-residuals-and-other-information-1",
    "href": "exercises/ex-14.html#collecting-residuals-and-other-information-1",
    "title": "Stats Bootcamp - class 14",
    "section": "Collecting residuals and other information",
    "text": "Collecting residuals and other information\nadd residuals and other information\n\n#augment\nb_wf &lt;-\n\n# mean weight per fam\nmean_B1 &lt;- fit_wf$coefficients[??]\n\nmean_A1 &lt;- mean_B1 +\n  fit_wf$coefficients[??]\n\nmean_D5 &lt;- mean_B1 +\n  fit_wf$coefficients[??]\n\nmean_F1 &lt;- mean_B1 +\n  fit_wf$coefficients[??]"
  },
  {
    "objectID": "exercises/ex-14.html#step-3-visualize-the-error-around-fit-1",
    "href": "exercises/ex-14.html#step-3-visualize-the-error-around-fit-1",
    "title": "Stats Bootcamp - class 14",
    "section": "STEP 3: Visualize the error around fit",
    "text": "STEP 3: Visualize the error around fit\n\nggplot(b_wf,\n       aes(x = family, y = weight)) +\n  geom_point(position = position_jitter(),\n             aes(color = .resid)) +\n  scale_color_gradient2(low = \"blue\",\n                        mid = \"black\",\n                        high = \"yellow\") +\ngeom_segment(aes(x=.5, xend=1.5, y=mean_B1, yend=mean_B1), color=\"red\") +\n  geom_segment(aes(x=1.5, xend=2.5, y=mean_A1, yend=mean_A1), color=\"red\") +\n  geom_segment(aes(x=2.5, xend=3.5, y=mean_D5, yend=mean_D5), color=\"red\") +\n  geom_segment(aes(x=3.5, xend=4.5, y=mean_F1, yend=mean_F1), color=\"red\") +\n  geom_segment(aes(x=.5, xend=4.5, y=mean(weight), yend=mean(weight)), color=\"black\") +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-14.html#compare-to-traditional-anova",
    "href": "exercises/ex-14.html#compare-to-traditional-anova",
    "title": "Stats Bootcamp - class 14",
    "section": "Compare to traditional ANOVA",
    "text": "Compare to traditional ANOVA\n\nbfam |&gt;\n  ?? |&gt;\n  gt()\n\n\ntidy(fit_wf) |&gt;\n  select(term, estimate, statistic, p.value) |&gt;\n  gt()"
  },
  {
    "objectID": "exercises/ex-14.html#comparing-2-groups-of-2-continuous-variables",
    "href": "exercises/ex-14.html#comparing-2-groups-of-2-continuous-variables",
    "title": "Stats Bootcamp - class 14",
    "section": "Comparing 2 groups of 2 continuous variables",
    "text": "Comparing 2 groups of 2 continuous variables\nANCOVA, Analysis of Covariance. ANOVA with more than one independent variable. What is the impact of mouse age on mouse weight for males vs females.\n\nggplot(data = b, aes(y = weight, x = age, color=sex)) +\n  geom_point(size=.5) +\n  geom_smooth(method=lm) +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-14.html#step-2-fit-linear-model-and-examine-results-2",
    "href": "exercises/ex-14.html#step-2-fit-linear-model-and-examine-results-2",
    "title": "Stats Bootcamp - class 14",
    "section": "STEP 2: Fit linear model and examine results",
    "text": "STEP 2: Fit linear model and examine results\n\nfit_wa_sex &lt;- lm(formula = weight ~ 1 + age + sex, data = b)\nb_wa_sex &lt;- augment(fit_ws, data = b)\n\nFit summary:\n\nglance(fit_wa_sex) |&gt;\n  gt() |&gt;\n  fmt_number(columns = r.squared:statistic, decimals = 3)\n\nCompare to traditional:\n\naov(formula = weight ~ 1 + age + sex, data = b) |&gt;\n  glance()"
  },
  {
    "objectID": "exercises/ex-14.html#references",
    "href": "exercises/ex-14.html#references",
    "title": "Stats Bootcamp - class 14",
    "section": "References",
    "text": "References\nLinear Models Pt.3 - Design Matrices\nA Matrix Formulation of the Multiple Regression Model\nDoing and reporting your first ANOVA and ANCOVA in R40f2ef"
  },
  {
    "objectID": "exercises/ex-12.html",
    "href": "exercises/ex-12.html",
    "title": "Stats Bootcamp - class 12",
    "section": "",
    "text": "We are going to use ggpubr rather than ggplot2 - Don’t tell Jay ;)\n\n\nIt has great visualization for the stats on the plots.\nDifferent syntax!!\n\nmust use double quotes around “variable names”\n\n\n\n\nDue to reviewer #3, we will pivot to a more “physiologically relevant” data set biochem that consists of mouse measurements.\n\n. . ."
  },
  {
    "objectID": "exercises/ex-12.html#two-changes",
    "href": "exercises/ex-12.html#two-changes",
    "title": "Stats Bootcamp - class 12",
    "section": "",
    "text": "We are going to use ggpubr rather than ggplot2 - Don’t tell Jay ;)\n\n\nIt has great visualization for the stats on the plots.\nDifferent syntax!!\n\nmust use double quotes around “variable names”\n\n\n\n\nDue to reviewer #3, we will pivot to a more “physiologically relevant” data set biochem that consists of mouse measurements.\n\n. . ."
  },
  {
    "objectID": "exercises/ex-12.html#prepare-mouse-biochem-data",
    "href": "exercises/ex-12.html#prepare-mouse-biochem-data",
    "title": "Stats Bootcamp - class 12",
    "section": "Prepare mouse biochem data",
    "text": "Prepare mouse biochem data\n\n# we are reading the data directly from the internet\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1,6,9,14,15,24:28)]\nbiochem &lt;- biochem[,keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\",\"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename gender to sex\nb &lt;- inner_join(biochem, weight, by=\"subject_name\") |&gt;\n  na.omit() |&gt;\n  rename(sex=gender)"
  },
  {
    "objectID": "exercises/ex-12.html#compare-mean-of-a-variable-to-a-known-value",
    "href": "exercises/ex-12.html#compare-mean-of-a-variable-to-a-known-value",
    "title": "Stats Bootcamp - class 12",
    "section": "Compare mean of a variable to a known value",
    "text": "Compare mean of a variable to a known value\n\\(y\\) is independent of \\(x\\)\n\\(y\\) is continuous\n\\(x\\) is constant\nParametric: One-sample t-test\nt_test(y ~ 1, mu = x)\nNonparametric: Wilcoxon signed-rank\nwilcox_test(y ~ 1, mu = x)\n\nExamine and specify the variable(s)\nDeclare null hypothesis \\(\\mathcal{H}_0\\)\n\nCalculate test-statistic, exact p-value\n\nThink did the expression of my gene change…"
  },
  {
    "objectID": "exercises/ex-12.html#examine-and-specify-the-variables",
    "href": "exercises/ex-12.html#examine-and-specify-the-variables",
    "title": "Stats Bootcamp - class 12",
    "section": "1. Examine and specify the variable(s)",
    "text": "1. Examine and specify the variable(s)\nLet’s explore mouse \\(weight\\)\n\nggdensity(\n  data = b,\n  x = \"??\",\n  add = \"mean\",\n  rug = TRUE\n  )\n\n. . .\nlet’s see some summary stats\n\nb |&gt;\n  get_summary_stats(\n    ??,\n    type = \"common\",\n    show = c(\"mean\",\"median\",\"sd\")\n    )"
  },
  {
    "objectID": "exercises/ex-12.html#is-it-normally-distributed",
    "href": "exercises/ex-12.html#is-it-normally-distributed",
    "title": "Stats Bootcamp - class 12",
    "section": "Is it normally distributed?",
    "text": "Is it normally distributed?\n\nggqqplot(\n  data = b,\n  x = \"??\"\n  )\n\nLooks reasonable\n. . .\n\nb |&gt;\n  ??_test(weight)\n\nYikes!\nNo easy answers…gotta make a call. We’ll try both."
  },
  {
    "objectID": "exercises/ex-12.html#declare-null-hypothesis-mathcalh_0",
    "href": "exercises/ex-12.html#declare-null-hypothesis-mathcalh_0",
    "title": "Stats Bootcamp - class 12",
    "section": "2. Declare null hypothesis \\(\\mathcal{H}_0\\)\n",
    "text": "2. Declare null hypothesis \\(\\mathcal{H}_0\\)\n\nSince this is a one-way test, we don’t need to worry if the groups have equal variance (only 1 group). But, we need a standard to compare against. I asked google, how much does a mouse weigh in grams?\nAnswer: 20-35 g, I’m going with \\(27.5 g\\) as our standard.\n\n\\(\\mathcal{H}_0\\) is that the mean of mouse \\(weight\\) can be explained by \\(27.5\\)\n\n\\(weight\\) is the response variable\n\\(27.5\\) is the explanatory variable"
  },
  {
    "objectID": "exercises/ex-12.html#calculate-test-statistic-exact-p-value",
    "href": "exercises/ex-12.html#calculate-test-statistic-exact-p-value",
    "title": "Stats Bootcamp - class 12",
    "section": "3. Calculate test-statistic, exact p-value",
    "text": "3. Calculate test-statistic, exact p-value\nNonparametric test:\n\nx &lt;- 27.5 # standard from google\n\nb |&gt;\n  ??_test(weight ~ 1, mu = ??) |&gt;\n  gt()\n\n. . .\nParametric test:\n\nx &lt;- 27.5 # standard from google\n\nb |&gt;\n  ??_test(weight ~ 1, mu = ??) |&gt;\n  gt()\n\n. . .\nP values are well below 0.05\n\n\\(\\mathcal{H}_0\\) is that the mean of mouse \\(weight\\) can be explained by \\(27.5\\) is NOT WELL SUPPORTED\n\nSo \\(27.5 g\\) not able to describe weight\nNot surprising since our mean mouse weight is 20.2. Don’t believe everything you read on the internet."
  },
  {
    "objectID": "exercises/ex-12.html#compare-mean-of-two-groups",
    "href": "exercises/ex-12.html#compare-mean-of-two-groups",
    "title": "Stats Bootcamp - class 12",
    "section": "Compare mean of two groups",
    "text": "Compare mean of two groups\n\\(y\\) is independent of \\(x\\)\n\\(y\\) is continuous\n\\(x\\) is categorical with 2 groups (factor w/2 levels)\nParametric: Student’s t-test\nt_test(y ~ x) more here\nneed to pay attention to: var.equal paired\nNonparametric: Wilcoxon signed-rank\nwilcox_test(y ~ x) more here\nneed to pay attention to: paired\n\nExamine and specify the variable(s)\nDeclare null hypothesis \\(\\mathcal{H}_0\\)\n\nCalculate test-statistic, exact p-value"
  },
  {
    "objectID": "exercises/ex-12.html#tangent-on-students-t-test",
    "href": "exercises/ex-12.html#tangent-on-students-t-test",
    "title": "Stats Bootcamp - class 12",
    "section": "Tangent on Student’s t-test",
    "text": "Tangent on Student’s t-test\nThe T-Distribution, also known as Student’s t-distribution, gets its name from William Sealy Gosset who first published it in English in 1908 in the scientific journal Biometrika using his pseudonym “Student” because his employer preferred staff to use pen names when publishing scientific papers instead of their real name, so he used the name “Student” to hide his identity."
  },
  {
    "objectID": "exercises/ex-12.html#guinness-brewery-in-dublin",
    "href": "exercises/ex-12.html#guinness-brewery-in-dublin",
    "title": "Stats Bootcamp - class 12",
    "section": "Guinness Brewery in Dublin",
    "text": "Guinness Brewery in Dublin"
  },
  {
    "objectID": "exercises/ex-12.html#examine-and-specify-the-variables-1",
    "href": "exercises/ex-12.html#examine-and-specify-the-variables-1",
    "title": "Stats Bootcamp - class 12",
    "section": "1. Examine and specify the variable(s)",
    "text": "1. Examine and specify the variable(s)\nWe will compare mouse \\(weight\\) by \\(sex\\).\n\\(weight\\) is the response variable\n\\(sex\\) is the explanatory variable\n\\(y\\) ~ \\(x\\)\n\\(weight\\) ~ \\(sex\\)\n\nggdensity(\n  data = b,\n  color = \"sex\",\n  x = \"weight\",\n  add = \"mean\",\n  rug = TRUE\n  )\n\n\nI want the response variable on the \\(y\\) axis and the explanatory variable on the \\(x\\) axis.\nViolin plot\n\nggviolin(\n  data = b,\n  y = \"??\",\n  x = \"??\",\n  fill = \"??\",\n  add = \"mean_sd\"\n  )\n\n. . .\n\nb |&gt;\n  group_by(??) |&gt;\n  get_summary_stats(\n    ??,\n    type = \"common\",\n    show = c(\"mean\",\"median\",\"sd\")\n    )"
  },
  {
    "objectID": "exercises/ex-12.html#is-it-normally-distributed-1",
    "href": "exercises/ex-12.html#is-it-normally-distributed-1",
    "title": "Stats Bootcamp - class 12",
    "section": "Is it normally distributed?",
    "text": "Is it normally distributed?\n\nggqqplot(\n  data = b,\n  x = \"??\",\n  color = \"??\"\n  )\n\n. . .\n\nb |&gt;\n  group_by(sex) |&gt;\n  ??_test(weight) |&gt;\n  gt()\n\nLooks reasonable"
  },
  {
    "objectID": "exercises/ex-12.html#equal-variance",
    "href": "exercises/ex-12.html#equal-variance",
    "title": "Stats Bootcamp - class 12",
    "section": "Equal variance?",
    "text": "Equal variance?\n\nb |&gt;\n  ??_test(weight~sex) |&gt;\n  gt()\n\nOK - so we can use t-test, but variance is not equal."
  },
  {
    "objectID": "exercises/ex-12.html#declare-null-hypothesis-mathcalh_0-1",
    "href": "exercises/ex-12.html#declare-null-hypothesis-mathcalh_0-1",
    "title": "Stats Bootcamp - class 12",
    "section": "2. Declare null hypothesis \\(\\mathcal{H}_0\\)\n",
    "text": "2. Declare null hypothesis \\(\\mathcal{H}_0\\)\n\n\n\\(\\mathcal{H}_0\\) is that \\(sex\\) cannot explain \\(weight\\)"
  },
  {
    "objectID": "exercises/ex-12.html#calculate-test-statistic-exact-p-value-1",
    "href": "exercises/ex-12.html#calculate-test-statistic-exact-p-value-1",
    "title": "Stats Bootcamp - class 12",
    "section": "3. Calculate test-statistic, exact p-value",
    "text": "3. Calculate test-statistic, exact p-value\nNonparametric test:\n\nb |&gt;\n  ??_test(?? ~ ??, ref.group = \"F\") |&gt;\n  gt()\n\n. . .\nParametric test:\n\nx &lt;- 27.5 # standard from google\n\nb |&gt;\n  ??_test(weight ~ sex,\n         var.equal = ??,\n         ref.group = \"F\") |&gt;\n  gt()\n\n. . .\nP values are well below 0.05\n\n\\(\\mathcal{H}_0\\) is that \\(sex\\) cannot explain \\(weight\\) is NOT WELL SUPPORTED\n\n\\(sex\\) can explain \\(weight\\)"
  },
  {
    "objectID": "exercises/ex-12.html#visualize-the-result",
    "href": "exercises/ex-12.html#visualize-the-result",
    "title": "Stats Bootcamp - class 12",
    "section": "Visualize the result",
    "text": "Visualize the result\n\n# save statistical test result\nstatres &lt;- b |&gt;\n  t_test(weight ~ sex,\n         var.equal = F,\n         ref.group = \"F\")\n\n\nggviolin(\n  data = b,\n  y = \"weight\",\n  x = \"sex\",\n  fill = \"sex\",\n  add = \"mean_sd\"\n  ) +\n  stat_pvalue_manual(\n    ??,\n    label = \"p\",\n    y.position = 34\n    ) +\n  ylim(10,35)"
  },
  {
    "objectID": "exercises/ex-12.html#compare-means-of-three-or-more-groups",
    "href": "exercises/ex-12.html#compare-means-of-three-or-more-groups",
    "title": "Stats Bootcamp - class 12",
    "section": "Compare means of three or more groups",
    "text": "Compare means of three or more groups\n\\(y\\) is independent of \\(x\\)\n\\(y\\) is continuous\n\\(x\\) is 2 or more groups of categorical data\nParametric: ANOVA\nanova_test(y ~ group) more info\nNonparametric: Kruskal-Wallis test\nkruskal_test(y ~ group) more info\n\nExamine and specify the variable(s)\nDeclare null hypothesis \\(\\mathcal{H}_0\\)\n\nCalculate test-statistic, exact p-value"
  },
  {
    "objectID": "exercises/ex-12.html#examine-and-specify-the-variables-2",
    "href": "exercises/ex-12.html#examine-and-specify-the-variables-2",
    "title": "Stats Bootcamp - class 12",
    "section": "1. Examine and specify the variable(s)",
    "text": "1. Examine and specify the variable(s)\nWe will compare mouse \\(weight\\) by \\(family\\).\n\\(weight\\) is the response variable\n\\(family\\) is the explanatory variable\n\\(y\\) ~ \\(x\\)\n\\(weight\\) ~ \\(family\\)\n\n# i have pre-selected some families to compare\nmyfams &lt;- c(\"B1.5:E1.4(4) B1.5:A1.4(5)\",\n            \"F1.3:A1.2(3) F1.3:E2.2(3)\",\n            \"A1.3:D1.2(3) A1.3:H1.2(3)\",\n            \"D5.4:G2.3(4) D5.4:C4.3(4)\")\n\n# only keep the familys in myfams\nbfam &lt;- b |&gt;\n  filter(family %in% myfams) |&gt;\n  droplevels()\n\n# simplify family names and make factor\nbfam$family &lt;- gsub(pattern = \"\\\\..*\", replacement = \"\", x = bfam$family) |&gt;\n  as.factor()\n\n\n# make B1 the reference (most similar to overall mean)\nbfam$family &lt;- relevel(x = bfam$family, ref =\"B1\")"
  },
  {
    "objectID": "exercises/ex-12.html#visualize-the-variables",
    "href": "exercises/ex-12.html#visualize-the-variables",
    "title": "Stats Bootcamp - class 12",
    "section": "Visualize the variable(s)",
    "text": "Visualize the variable(s)\nI want the response variable on the \\(y\\) axis and the explanatory variable on the \\(x\\) axis.\nBoxplot\n\nggboxplot(\n  data = bfam,\n  y = \"??\",\n  x = \"??\",\n  fill = \"??\"\n  )\n\n. . .\n\nbfam |&gt;\n  group_by(??) |&gt;\n  get_summary_stats(\n    ??,\n    type = \"common\",\n    show = c(\"mean\",\"median\",\"sd\")\n    )"
  },
  {
    "objectID": "exercises/ex-12.html#is-it-normally-distributed-2",
    "href": "exercises/ex-12.html#is-it-normally-distributed-2",
    "title": "Stats Bootcamp - class 12",
    "section": "Is it normally distributed?",
    "text": "Is it normally distributed?\n\nggqqplot(\n  data = bfam,\n  x = \"weight\",\n  color = \"??\"\n  )\n\n. . .\n\nbfam |&gt;\n  group_by(family) |&gt;\n  ??_test(weight) |&gt;\n  gt()\n\nLooks reasonable"
  },
  {
    "objectID": "exercises/ex-12.html#equal-variance-1",
    "href": "exercises/ex-12.html#equal-variance-1",
    "title": "Stats Bootcamp - class 12",
    "section": "Equal variance?",
    "text": "Equal variance?\n\nbfam |&gt;\n  ??_test(??~??) |&gt;\n  gt()\n\nOK - so we can use anova!"
  },
  {
    "objectID": "exercises/ex-12.html#declare-null-hypothesis-mathcalh_0-2",
    "href": "exercises/ex-12.html#declare-null-hypothesis-mathcalh_0-2",
    "title": "Stats Bootcamp - class 12",
    "section": "2. Declare null hypothesis \\(\\mathcal{H}_0\\)\n",
    "text": "2. Declare null hypothesis \\(\\mathcal{H}_0\\)\n\n\n\\(\\mathcal{H}_0\\) is that \\(family\\) cannot explain \\(weight\\)"
  },
  {
    "objectID": "exercises/ex-12.html#calculate-test-statistic-exact-p-value-2",
    "href": "exercises/ex-12.html#calculate-test-statistic-exact-p-value-2",
    "title": "Stats Bootcamp - class 12",
    "section": "3. Calculate test-statistic, exact p-value",
    "text": "3. Calculate test-statistic, exact p-value\nParametric test:\n\nbfam |&gt;\n  ??_test(weight ~ ??) |&gt;\n  gt()\n\n. . .\nNonparametric test:\n\nbfam |&gt;\n  ??_test(weight ~ family) |&gt;\n  gt()\n\n. . .\nP values are well below 0.05\n\n\\(\\mathcal{H}_0\\) is that \\(family\\) cannot explain \\(weight\\) is NOT WELL SUPPORTED\n\n\\(family\\) can explain \\(weight\\)"
  },
  {
    "objectID": "exercises/ex-12.html#visualize-the-result-1",
    "href": "exercises/ex-12.html#visualize-the-result-1",
    "title": "Stats Bootcamp - class 12",
    "section": "Visualize the result",
    "text": "Visualize the result\n\n# save statistical test result\nstatres &lt;- bfam |&gt;\n  anova_test(weight ~ sex)\n\n\nggboxplot(\n  data = bfam,\n  y = \"weight\",\n  x = \"family\",\n  fill = \"family\"\n  ) +\n  stat_anova_test()"
  },
  {
    "objectID": "exercises/ex-12.html#multiple-pairwise-comparisons",
    "href": "exercises/ex-12.html#multiple-pairwise-comparisons",
    "title": "Stats Bootcamp - class 12",
    "section": "Multiple pairwise comparisons",
    "text": "Multiple pairwise comparisons\nQuick aside\n\n# save statistical test result\npairwise &lt;- bfam |&gt;\n  t_test(weight ~ family, ref.group = \"??\")\n\n\nggboxplot(bfam,\n          x = \"family\",\n          y = \"weight\",\n          fill = \"weight\",\n          ) +\n  stat_pvalue_manual(\n    pairwise,\n    label = \"p.adj\",\n    y.position = c(30, 32, 34)\n    ) +\n  ylim(10,38)\n\nNotice that not all pairwise differences are significant, yet the ANOVA is significant."
  },
  {
    "objectID": "exercises/ex-12.html#appropriate-statistical-test-cheatsheet",
    "href": "exercises/ex-12.html#appropriate-statistical-test-cheatsheet",
    "title": "Stats Bootcamp - class 12",
    "section": "Appropriate statistical test cheatsheet",
    "text": "Appropriate statistical test cheatsheet"
  },
  {
    "objectID": "exercises/ex-12.html#references",
    "href": "exercises/ex-12.html#references",
    "title": "Stats Bootcamp - class 12",
    "section": "References",
    "text": "References\nLegal analogy\nStatQuest: P Values, clearly explained\nStatQuest: How to calculate p-values\nThe Curious Tale of William Sealy Gosset"
  },
  {
    "objectID": "exercises/ex-10.html",
    "href": "exercises/ex-10.html",
    "title": "Stats Bootcamp - class 10",
    "section": "",
    "text": "Flip a coin 5 times with equal prob of H or T\nAgain\n. . .\nSet a seed\n\n#\n\n\n#"
  },
  {
    "objectID": "exercises/ex-10.html#lets-flip-a-fair-coin",
    "href": "exercises/ex-10.html#lets-flip-a-fair-coin",
    "title": "Stats Bootcamp - class 10",
    "section": "",
    "text": "Flip a coin 5 times with equal prob of H or T\nAgain\n. . .\nSet a seed\n\n#\n\n\n#"
  },
  {
    "objectID": "exercises/ex-10.html#lets-flip-an-unfair-coin",
    "href": "exercises/ex-10.html#lets-flip-an-unfair-coin",
    "title": "Stats Bootcamp - class 10",
    "section": "Let’s flip an unfair coin",
    "text": "Let’s flip an unfair coin\nFlip a coin 5 times with equal prob of H or T\nAgain"
  },
  {
    "objectID": "exercises/ex-10.html#lets-summarize-the-flipping-results",
    "href": "exercises/ex-10.html#lets-summarize-the-flipping-results",
    "title": "Stats Bootcamp - class 10",
    "section": "Let’s summarize the flipping results",
    "text": "Let’s summarize the flipping results\nFlip a fair coin 10\nFlip a fair coin 10 and calculate mean\nAgain\n. . .\nUnfair coin\nUnfair coin, again"
  },
  {
    "objectID": "exercises/ex-10.html#lets-go-wild-flipping",
    "href": "exercises/ex-10.html#lets-go-wild-flipping",
    "title": "Stats Bootcamp - class 10",
    "section": "Let’s go wild flipping",
    "text": "Let’s go wild flipping\nFlip a fair coin 10 times and calculate mean. Then do 5 rounds of that experiment.\n. . .\nSame thing for an unfair coin."
  },
  {
    "objectID": "exercises/ex-10.html#tidy-and-visualize-flips",
    "href": "exercises/ex-10.html#tidy-and-visualize-flips",
    "title": "Stats Bootcamp - class 10",
    "section": "Tidy and visualize flips",
    "text": "Tidy and visualize flips\nmake a dataframe with means and accompanying info\n. . .\nplot it"
  },
  {
    "objectID": "exercises/ex-10.html#play-around-some-more",
    "href": "exercises/ex-10.html#play-around-some-more",
    "title": "Stats Bootcamp - class 10",
    "section": "Play around some more",
    "text": "Play around some more"
  },
  {
    "objectID": "exercises/ex-07.html",
    "href": "exercises/ex-07.html",
    "title": "R Bootcamp - Class 7",
    "section": "",
    "text": "String manipulation with stringr\n\nFactor operations with forcats\n\nJoin functions with dplyr\n\nAdvanced plotting with ggplot2"
  },
  {
    "objectID": "exercises/ex-07.html#class-7-outline",
    "href": "exercises/ex-07.html#class-7-outline",
    "title": "R Bootcamp - Class 7",
    "section": "",
    "text": "String manipulation with stringr\n\nFactor operations with forcats\n\nJoin functions with dplyr\n\nAdvanced plotting with ggplot2"
  },
  {
    "objectID": "exercises/ex-07.html#setup",
    "href": "exercises/ex-07.html#setup",
    "title": "R Bootcamp - Class 7",
    "section": "Setup",
    "text": "Setup"
  },
  {
    "objectID": "exercises/ex-07.html#combining-strings-with-str_c",
    "href": "exercises/ex-07.html#combining-strings-with-str_c",
    "title": "R Bootcamp - Class 7",
    "section": "Combining strings with str_c()\n",
    "text": "Combining strings with str_c()\n\n\n\nstr_c() is similar to paste and paste0 but the behavior is more consistent."
  },
  {
    "objectID": "exercises/ex-07.html#detecting-patterns-with-str_detect",
    "href": "exercises/ex-07.html#detecting-patterns-with-str_detect",
    "title": "R Bootcamp - Class 7",
    "section": "Detecting patterns with str_detect()\n",
    "text": "Detecting patterns with str_detect()"
  },
  {
    "objectID": "exercises/ex-07.html#splitting-strings-with-str_split",
    "href": "exercises/ex-07.html#splitting-strings-with-str_split",
    "title": "R Bootcamp - Class 7",
    "section": "Splitting strings with str_split()\n",
    "text": "Splitting strings with str_split()"
  },
  {
    "objectID": "exercises/ex-07.html#counting-factor-levels-with-fct_count",
    "href": "exercises/ex-07.html#counting-factor-levels-with-fct_count",
    "title": "R Bootcamp - Class 7",
    "section": "Counting factor levels with fct_count()\n",
    "text": "Counting factor levels with fct_count()"
  },
  {
    "objectID": "exercises/ex-07.html#reordering-factors-with-fct_reorder",
    "href": "exercises/ex-07.html#reordering-factors-with-fct_reorder",
    "title": "R Bootcamp - Class 7",
    "section": "Reordering factors with fct_reorder()\n",
    "text": "Reordering factors with fct_reorder()"
  },
  {
    "objectID": "exercises/ex-07.html#lumping-infrequent-levels-with-fct_lump",
    "href": "exercises/ex-07.html#lumping-infrequent-levels-with-fct_lump",
    "title": "R Bootcamp - Class 7",
    "section": "Lumping infrequent levels with fct_lump()\n",
    "text": "Lumping infrequent levels with fct_lump()\n\n\n\n\n\nDo your numbers look different? sample() is not reproducible by default."
  },
  {
    "objectID": "exercises/ex-07.html#aside-on-sample-and-reproducibility",
    "href": "exercises/ex-07.html#aside-on-sample-and-reproducibility",
    "title": "R Bootcamp - Class 7",
    "section": "Aside on sample() and reproducibility",
    "text": "Aside on sample() and reproducibility\n\n\n\nthis also applies to rnorm(), runif(), and other random number generation functions."
  },
  {
    "objectID": "exercises/ex-07.html#setup-1",
    "href": "exercises/ex-07.html#setup-1",
    "title": "R Bootcamp - Class 7",
    "section": "Setup",
    "text": "Setup\nOpen up the tidyexplain page."
  },
  {
    "objectID": "exercises/ex-07.html#understanding-joins",
    "href": "exercises/ex-07.html#understanding-joins",
    "title": "R Bootcamp - Class 7",
    "section": "Understanding joins",
    "text": "Understanding joins\nJoins combine data from two tables based on matching keys."
  },
  {
    "objectID": "exercises/ex-07.html#left_join---keep-all-rows-from-left-table",
    "href": "exercises/ex-07.html#left_join---keep-all-rows-from-left-table",
    "title": "R Bootcamp - Class 7",
    "section": "\nleft_join() - keep all rows from left table",
    "text": "left_join() - keep all rows from left table\nMost common join - keeps all observations from the “primary” table."
  },
  {
    "objectID": "exercises/ex-07.html#inner_join---keep-only-matching-rows",
    "href": "exercises/ex-07.html#inner_join---keep-only-matching-rows",
    "title": "R Bootcamp - Class 7",
    "section": "\ninner_join() - keep only matching rows",
    "text": "inner_join() - keep only matching rows\nOnly keeps rows that exist in both tables."
  },
  {
    "objectID": "exercises/ex-07.html#full_join---keep-all-rows-from-both-tables",
    "href": "exercises/ex-07.html#full_join---keep-all-rows-from-both-tables",
    "title": "R Bootcamp - Class 7",
    "section": "\nfull_join() - keep all rows from both tables",
    "text": "full_join() - keep all rows from both tables\nKeeps everything, filling missing values with NA."
  },
  {
    "objectID": "exercises/ex-07.html#setup-2",
    "href": "exercises/ex-07.html#setup-2",
    "title": "R Bootcamp - Class 7",
    "section": "Setup",
    "text": "Setup"
  },
  {
    "objectID": "exercises/ex-07.html#scale-functions-in-ggplot2",
    "href": "exercises/ex-07.html#scale-functions-in-ggplot2",
    "title": "R Bootcamp - Class 7",
    "section": "scale functions in ggplot2",
    "text": "scale functions in ggplot2\n\n\nscale_color_brewer() and scale_fill_brewer() control color and fill aesthetics.\nSee available ggplot2 brewer palettes"
  },
  {
    "objectID": "exercises/ex-07.html#combining-multiple-plots-into-a-figure",
    "href": "exercises/ex-07.html#combining-multiple-plots-into-a-figure",
    "title": "R Bootcamp - Class 7",
    "section": "Combining multiple plots into a figure?",
    "text": "Combining multiple plots into a figure?\nUse the {patchwork} package."
  },
  {
    "objectID": "exercises/ex-07.html#saving-plots",
    "href": "exercises/ex-07.html#saving-plots",
    "title": "R Bootcamp - Class 7",
    "section": "Saving plots",
    "text": "Saving plots\nSaves last plot as 5’ x 5’ file named plot_final.png in working directory.\nMatches file type to file extension (*.png, *.jpeg, *.pdf)."
  },
  {
    "objectID": "exercises/ex-07.html#using-knitrkable",
    "href": "exercises/ex-07.html#using-knitrkable",
    "title": "R Bootcamp - Class 7",
    "section": "Using knitr::kable()\n",
    "text": "Using knitr::kable()"
  },
  {
    "objectID": "exercises/ex-07.html#using-gt",
    "href": "exercises/ex-07.html#using-gt",
    "title": "R Bootcamp - Class 7",
    "section": "Using gt\n",
    "text": "Using gt"
  },
  {
    "objectID": "exercises/ex-04.html#todays-datasets",
    "href": "exercises/ex-04.html#todays-datasets",
    "title": "R Bootcamp - Day 4",
    "section": "Today’s datasets",
    "text": "Today’s datasets\nIn this class, we will use a data set from ggplot2: diamonds contains thousands of gem prices and qualities.\nThere are many interesting data sets you can install as R packages for learning to manipulate and plot data:\n\nbabynames\ngapminder\npalmerpenguins"
  },
  {
    "objectID": "exercises/ex-04.html#getting-familiar-with-the-data---exercise-1",
    "href": "exercises/ex-04.html#getting-familiar-with-the-data---exercise-1",
    "title": "R Bootcamp - Day 4",
    "section": "Getting familiar with the data - Exercise 1",
    "text": "Getting familiar with the data - Exercise 1"
  },
  {
    "objectID": "exercises/ex-04.html#the-syntax-of-ggplot",
    "href": "exercises/ex-04.html#the-syntax-of-ggplot",
    "title": "R Bootcamp - Day 4",
    "section": "The syntax of ggplot()\n",
    "text": "The syntax of ggplot()"
  },
  {
    "objectID": "exercises/ex-04.html#making-a-plot-step-by-step-exercise-2",
    "href": "exercises/ex-04.html#making-a-plot-step-by-step-exercise-2",
    "title": "R Bootcamp - Day 4",
    "section": "Making a plot step-by-step (Exercise 2)",
    "text": "Making a plot step-by-step (Exercise 2)\n\nInitialize a plot with data.\nNext, specify the coordinate system.\nAdd a geom (geom_point).\nMap aesthetics to other variables.\n\nReduce overplotting by adjusting the transparency of points."
  },
  {
    "objectID": "exercises/ex-04.html#looking-under-the-hood-of-ggplot-exercise-3",
    "href": "exercises/ex-04.html#looking-under-the-hood-of-ggplot-exercise-3",
    "title": "R Bootcamp - Day 4",
    "section": "Looking under the hood of ggplot (Exercise 3)",
    "text": "Looking under the hood of ggplot (Exercise 3)"
  },
  {
    "objectID": "exercises/ex-04.html#ggplot-is-powerfully-simple-for-making-complex-plots",
    "href": "exercises/ex-04.html#ggplot-is-powerfully-simple-for-making-complex-plots",
    "title": "R Bootcamp - Day 4",
    "section": "ggplot is powerfully simple for making complex plots",
    "text": "ggplot is powerfully simple for making complex plots\nWhy can’t I just do this?"
  },
  {
    "objectID": "exercises/ex-04.html#geom-functions",
    "href": "exercises/ex-04.html#geom-functions",
    "title": "R Bootcamp - Day 4",
    "section": "Geom functions",
    "text": "Geom functions\n\nUse a geom function to represent data points, use the geom aesthetic properties to represent variables.\nEach function returns a plot layer.\nThere are many geoms in ggplot that are specific to plots with 1, 2, or 3 variables\n\nMake a bar plot.\n\nUpdate the bar plot aesthetics.\n\nChange to a density plot.\n\nColor the density plot.\n\nPlot subsets by mapping fill to cut\n\nUse ggridges to plot staggered subsets.\nhttps://wilkelab.org/ggridges/"
  },
  {
    "objectID": "exercises/ex-04.html#geom-functions-for-two-variables",
    "href": "exercises/ex-04.html#geom-functions-for-two-variables",
    "title": "R Bootcamp - Day 4",
    "section": "Geom functions for two variables",
    "text": "Geom functions for two variables\nMake a column plot.\nSame data with a box plot.\n\nBox plot, with fill color by cut.\nViolin plot with fill color by cut."
  },
  {
    "objectID": "exercises/ex-04.html#continuous-x-continuous-y---exercise-6",
    "href": "exercises/ex-04.html#continuous-x-continuous-y---exercise-6",
    "title": "R Bootcamp - Day 4",
    "section": "continuous x, continuous y - Exercise 6",
    "text": "continuous x, continuous y - Exercise 6\nSubset diamonds to see points more clearly.\nMake a scatter plot.\nNow add a smoothing line.\nHere we can combine geoms to see points & the fit"
  },
  {
    "objectID": "exercises/ex-02.html",
    "href": "exercises/ex-02.html",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "",
    "text": "Explore table1, table2, table3, table4a, table4b, and table5, which all display the number of TB cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000.\n\nR provides many functions to examine features of a data object\n\nView() - To open the table up in an excel-like interface - not recommended for large tables\nclass() - what kind of object is it (high-level)?\ntypeof() - what is the object’s data type (low-level)?\nis_tibble() - use is.? to confirm data type\nstr() - what is the structure of the object?\nattributes() - does it have any metadata?\nLet’s explore table1\n\nSome of the useful functions for data.frames / tibbles are as follows:\n\n\nhead() - shows first 6 rows\n\ntail() - shows last 6 rows\n\ndim() - returns the dimensions of data frame (i.e. number of rows and number of columns)\n\nnrow() - number of rows\n\nncol() - number of columns\n\nnames() or colnames() - both show the names attribute for a data frame\nglimpse()"
  },
  {
    "objectID": "exercises/ex-02.html#data-sets-for-tidying---exercise-2",
    "href": "exercises/ex-02.html#data-sets-for-tidying---exercise-2",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "",
    "text": "Explore table1, table2, table3, table4a, table4b, and table5, which all display the number of TB cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000."
  },
  {
    "objectID": "exercises/ex-02.html#getting-familiar-with-the-data---exercise-3",
    "href": "exercises/ex-02.html#getting-familiar-with-the-data---exercise-3",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "",
    "text": "R provides many functions to examine features of a data object\n\nView() - To open the table up in an excel-like interface - not recommended for large tables\nclass() - what kind of object is it (high-level)?\ntypeof() - what is the object’s data type (low-level)?\nis_tibble() - use is.? to confirm data type\nstr() - what is the structure of the object?\nattributes() - does it have any metadata?\nLet’s explore table1"
  },
  {
    "objectID": "exercises/ex-02.html#getting-familiar-with-the-data---exercise-4",
    "href": "exercises/ex-02.html#getting-familiar-with-the-data---exercise-4",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "",
    "text": "Some of the useful functions for data.frames / tibbles are as follows:\n\n\nhead() - shows first 6 rows\n\ntail() - shows last 6 rows\n\ndim() - returns the dimensions of data frame (i.e. number of rows and number of columns)\n\nnrow() - number of rows\n\nncol() - number of columns\n\nnames() or colnames() - both show the names attribute for a data frame\nglimpse()"
  },
  {
    "objectID": "exercises/ex-02.html#pivot_wider---exercise-6",
    "href": "exercises/ex-02.html#pivot_wider---exercise-6",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "pivot_wider - Exercise 6",
    "text": "pivot_wider - Exercise 6\nWhat will the output look like?\nIf you want to save the output, assign it to a new variable. This new variable will appear in your Environment tab."
  },
  {
    "objectID": "exercises/ex-02.html#pivot_longer---exercise-7",
    "href": "exercises/ex-02.html#pivot_longer---exercise-7",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "pivot_longer - Exercise 7",
    "text": "pivot_longer - Exercise 7\nWhat will the output look like?"
  },
  {
    "objectID": "exercises/ex-02.html#separate_wider_delim---exercise-8",
    "href": "exercises/ex-02.html#separate_wider_delim---exercise-8",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "separate_wider_delim - Exercise 8",
    "text": "separate_wider_delim - Exercise 8\nWhat will the output look like?\nseparate_rows - Exercise 9"
  },
  {
    "objectID": "exercises/ex-02.html#unite---exercise-10",
    "href": "exercises/ex-02.html#unite---exercise-10",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "unite - Exercise 10",
    "text": "unite - Exercise 10"
  },
  {
    "objectID": "exercises/ex-02.html#missing-values",
    "href": "exercises/ex-02.html#missing-values",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "Missing values",
    "text": "Missing values"
  },
  {
    "objectID": "course-info/team.html",
    "href": "course-info/team.html",
    "title": "MOLB 7950 — Teaching Team",
    "section": "",
    "text": "TA office hours will be 1-2:30 PM on Tues and Thurs. Please coordinate with the TAs to determine whether you want to meet in person or virtually. You can also use slack to ask questions outside of office hours.\n\n\n\n\n\n\n\n\n\nInstructor\nE-mail\n\n\n\n\nNeel Mukherjee\n\n\n\nJay Hesselberth\n\n\n\nSrinivas Ramachandran\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstructor\nE-mail\n\n\n\n\nNathaly Limon de la Rosa\n\n\n\nIlin Joshi",
    "crumbs": [
      "Course information",
      "Teaching team"
    ]
  },
  {
    "objectID": "course-info/team.html#teaching-team-and-office-hours",
    "href": "course-info/team.html#teaching-team-and-office-hours",
    "title": "MOLB 7950 — Teaching Team",
    "section": "",
    "text": "TA office hours will be 1-2:30 PM on Tues and Thurs. Please coordinate with the TAs to determine whether you want to meet in person or virtually. You can also use slack to ask questions outside of office hours.\n\n\n\n\n\n\n\n\n\nInstructor\nE-mail\n\n\n\n\nNeel Mukherjee\n\n\n\nJay Hesselberth\n\n\n\nSrinivas Ramachandran\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstructor\nE-mail\n\n\n\n\nNathaly Limon de la Rosa\n\n\n\nIlin Joshi",
    "crumbs": [
      "Course information",
      "Teaching team"
    ]
  },
  {
    "objectID": "course-info/support.html",
    "href": "course-info/support.html",
    "title": "MOLB 7950 — Getting help",
    "section": "",
    "text": "Course discussion will be through the Slack MOLB7950 organization.\nGuidelines for using Slack:\n\nUse dedicated channels for discussion in #class, questions about your #problem-sets, and your #final-project\nYou can ask for help by tagging the TAs in the #class channel. If you post @ta help, someone will start a thread where you can ask a question.\nIf needed, we can talk face-to-face via the /zoom integration.\n\n\n\n\n\nOur TAs will be available Tues-Thurs afternoons from 1-2:30pm.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-info/support.html#how-to-get-help",
    "href": "course-info/support.html#how-to-get-help",
    "title": "MOLB 7950 — Getting help",
    "section": "",
    "text": "Course discussion will be through the Slack MOLB7950 organization.\nGuidelines for using Slack:\n\nUse dedicated channels for discussion in #class, questions about your #problem-sets, and your #final-project\nYou can ask for help by tagging the TAs in the #class channel. If you post @ta help, someone will start a thread where you can ask a question.\nIf needed, we can talk face-to-face via the /zoom integration.\n\n\n\n\n\nOur TAs will be available Tues-Thurs afternoons from 1-2:30pm.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-info/final-projects.html",
    "href": "course-info/final-projects.html",
    "title": "MOLB 7950 – Final Projects",
    "section": "",
    "text": "Please submit a short proposal for your final projects with the following information.\n\nthe names of people you are working with\na description of the data set you will be working worth. This can refer to a publication and/or contain a link to public data available at NCBI GEO.\na hypothesis (tentative) you will be testing\na few bullets on your planned analysis approach.\n\nPlease include this information in a quarto document in a new Posit cloud project.",
    "crumbs": [
      "Assignments",
      "Final Project Overview"
    ]
  },
  {
    "objectID": "course-info/final-projects.html#short-proposal",
    "href": "course-info/final-projects.html#short-proposal",
    "title": "MOLB 7950 – Final Projects",
    "section": "",
    "text": "Please submit a short proposal for your final projects with the following information.\n\nthe names of people you are working with\na description of the data set you will be working worth. This can refer to a publication and/or contain a link to public data available at NCBI GEO.\na hypothesis (tentative) you will be testing\na few bullets on your planned analysis approach.\n\nPlease include this information in a quarto document in a new Posit cloud project.",
    "crumbs": [
      "Assignments",
      "Final Project Overview"
    ]
  },
  {
    "objectID": "course-info/final-projects.html#overview",
    "href": "course-info/final-projects.html#overview",
    "title": "MOLB 7950 – Final Projects",
    "section": "Overview",
    "text": "Overview\n\nFinal projects can involve groups of 1-3 people.\n\nProjects are choose your own adventure:\n\nThe resource documents contain data sets in from human S. cerevisiae. For example, sub-nucleosomal fragments provide a DNA-based signal to understand chromatin transactions that lead to transcription.\nYou could find a data set on NCBI GEO of interest (e.g., relevant to your thesis work), and work it up with salmon, DEseq, and exploratory analysis. We are happy to help you work through the pseudo-alignment steps.\nYou can start with your own sequencing data (bulk/single-cell RNA seq, DNA sequencing).",
    "crumbs": [
      "Assignments",
      "Final Project Overview"
    ]
  },
  {
    "objectID": "course-info/final-projects.html#deliverables",
    "href": "course-info/final-projects.html#deliverables",
    "title": "MOLB 7950 – Final Projects",
    "section": "Deliverables",
    "text": "Deliverables\n\nA Quarto document with code, plots, interpretations, and next steps.\nIf you work in a group, list the members of the group at the top of the document, and make it clear which parts are your work by adding your initials to code chunks.\nShort presentations (5-8 minutes) by the groups the week of Nov 1. Presentations should include 1-2 slides of background, a hypothesis for the approach, code output (table or graph) that addresses the hypothesis, and one or more tests of the statistical significance of the observation.",
    "crumbs": [
      "Assignments",
      "Final Project Overview"
    ]
  },
  {
    "objectID": "course-info/final-projects.html#grading-and-rubric",
    "href": "course-info/final-projects.html#grading-and-rubric",
    "title": "MOLB 7950 – Final Projects",
    "section": "Grading and rubric",
    "text": "Grading and rubric\nThe final project will be worth 20% of your grade and we will use the grading scheme outlined in the grading rubric.\nEach individual in a group will be evaluated separately, so contributions must be clearly marked in the document, using e.g. using chunk labels:\n\n```{r}\n#| label: plotting-code-by-jay-h\n#| eval: false\n#| fig.alt: \"Description of the plot - PLEASE FILL IN\"\nggplot(mtcars, aes(hp, mpg)) +\n  geom_point()\n```",
    "crumbs": [
      "Assignments",
      "Final Project Overview"
    ]
  },
  {
    "objectID": "course-info/problem-sets.html",
    "href": "course-info/problem-sets.html",
    "title": "MOLB 7950 — Problem Sets",
    "section": "",
    "text": "We reinforce concepts with problem sets assigned at the end of each class. During the main blocks, problem sets on Mon and Wed should take ~60 minutes to complete. Problems sets assigned on Friday will be more substantial, requiring ~1-2 hours to complete. Together the problem sets constitute 60% of your grade.\n\n\n\nProblem sets are distributed as Posit Cloud assignments. You will work on problem sets in an Rmarkdown document in the assignment. When complete, complete your assignment by submitting the URL from your Posit Cloud assignment into the assignment submission on Canvas. We will grade your problem directly in the Posit Cloud assignment.\n\n\n\n\n\n\n\n\n\n\nAssigned\nDue\nGrades By\nWho grades\nTime to complete (approx)\n\n\n\n\nMon @ 12pm\nTues @ 5pm\nWed @ 5pm\nInstructors / TAs\n60 min\n\n\nTue @ 12pm\nWed @ 5pm\nThurs @ 5pm\nInstructors / TAs\n60 min\n\n\nWed @ 12pm\nThurs @ 5pm\nFri @ 5pm\nInstructors / TAs\n60 min\n\n\nThurs @ 12pm\nFri @ 5pm\nTues @ 5pm\nInstructors / TAs\n60 min\n\n\nFri @ 12pm\nMon @ 5pm\nWed @ 5pm\nInstructors / TAs\n1-2 hr\n\n\n\n\n\n\nProblem sets are worth 60% of your grade. Values in parentheses represent point values for each level from 20 points total. This rubric will be assessed at the end of the semester.\n\n\n\n\n\n\n\n\n\nCriteria\nExpert\nCompetent\nNeeds Improvement\n\n\n\n\nCoding style\nStudent has gone beyond what was expected and required, coding manual is followed, code is well commented\nCoding style lacks refinement and has some errors, but code is readable and has some comments\nMany errors in coding style, little attention paid to making the code human readable\n\n\nCoding strategy\nComplicated problem broken down into sub-problems that are individually much simpler. Code is efficient, correct, and minimal. Code uses appropriate data structure (list, data frame, vector/matrix/array). Code checks for common errors\nCode is correct, but could be edited down to leaner code. Some “hacking” instead of using suitable data structure. Some checks for errors.\nCode tackles complicated problem in one big chunk. Code is repetitive and could easily be functionalized. No anticipation of errors.\n\n\nPresentation: graphs\nGraph(s) carefully tuned for desired purpose. One graph illustrates one point\nGraph(s) well chosen, but with a few minor problems: inappropriate aspect ratios, poor labels.\nGraph(s) poorly chosen to support questions.\n\n\nPresentation: tables\nTable(s) carefully constructed to make it easy to perform important comparisons. Careful styling highlights important features.\nTable(s) generally appropriate but possibly some minor formatting deficiencies.\nTable(s) with too many, or inconsistent, decimal places. Table(s) not appropriate for questions and findings. Major display problems.\n\n\nAchievement, mastery, cleverness, creativity\nStudent has gone beyond what was expected and required, e.g., extraordinary effort, additional tools not addressed by this course, unusually sophisticated application of tools from course.\nTools and techniques from the course are applied very competently and, perhaps,somewhat creatively. Chosen task was acceptable, but fairly conservative in ambition.\nStudent does not display the expected level of mastery of the tools and techniques in this course. Chosen task was too limited in scope.\n\n\nEase of access for instructor, compliance with course conventions for submitted work\nAccess as easy as possible, code runs!\nSatisfactory\nNot an earnest effort to reduce friction and comply with conventions and/or code does not run",
    "crumbs": [
      "Assignments",
      "Problet Set Overview"
    ]
  },
  {
    "objectID": "course-info/problem-sets.html#problem-set-overview",
    "href": "course-info/problem-sets.html#problem-set-overview",
    "title": "MOLB 7950 — Problem Sets",
    "section": "",
    "text": "We reinforce concepts with problem sets assigned at the end of each class. During the main blocks, problem sets on Mon and Wed should take ~60 minutes to complete. Problems sets assigned on Friday will be more substantial, requiring ~1-2 hours to complete. Together the problem sets constitute 60% of your grade.\n\n\n\nProblem sets are distributed as Posit Cloud assignments. You will work on problem sets in an Rmarkdown document in the assignment. When complete, complete your assignment by submitting the URL from your Posit Cloud assignment into the assignment submission on Canvas. We will grade your problem directly in the Posit Cloud assignment.\n\n\n\n\n\n\n\n\n\n\nAssigned\nDue\nGrades By\nWho grades\nTime to complete (approx)\n\n\n\n\nMon @ 12pm\nTues @ 5pm\nWed @ 5pm\nInstructors / TAs\n60 min\n\n\nTue @ 12pm\nWed @ 5pm\nThurs @ 5pm\nInstructors / TAs\n60 min\n\n\nWed @ 12pm\nThurs @ 5pm\nFri @ 5pm\nInstructors / TAs\n60 min\n\n\nThurs @ 12pm\nFri @ 5pm\nTues @ 5pm\nInstructors / TAs\n60 min\n\n\nFri @ 12pm\nMon @ 5pm\nWed @ 5pm\nInstructors / TAs\n1-2 hr\n\n\n\n\n\n\nProblem sets are worth 60% of your grade. Values in parentheses represent point values for each level from 20 points total. This rubric will be assessed at the end of the semester.\n\n\n\n\n\n\n\n\n\nCriteria\nExpert\nCompetent\nNeeds Improvement\n\n\n\n\nCoding style\nStudent has gone beyond what was expected and required, coding manual is followed, code is well commented\nCoding style lacks refinement and has some errors, but code is readable and has some comments\nMany errors in coding style, little attention paid to making the code human readable\n\n\nCoding strategy\nComplicated problem broken down into sub-problems that are individually much simpler. Code is efficient, correct, and minimal. Code uses appropriate data structure (list, data frame, vector/matrix/array). Code checks for common errors\nCode is correct, but could be edited down to leaner code. Some “hacking” instead of using suitable data structure. Some checks for errors.\nCode tackles complicated problem in one big chunk. Code is repetitive and could easily be functionalized. No anticipation of errors.\n\n\nPresentation: graphs\nGraph(s) carefully tuned for desired purpose. One graph illustrates one point\nGraph(s) well chosen, but with a few minor problems: inappropriate aspect ratios, poor labels.\nGraph(s) poorly chosen to support questions.\n\n\nPresentation: tables\nTable(s) carefully constructed to make it easy to perform important comparisons. Careful styling highlights important features.\nTable(s) generally appropriate but possibly some minor formatting deficiencies.\nTable(s) with too many, or inconsistent, decimal places. Table(s) not appropriate for questions and findings. Major display problems.\n\n\nAchievement, mastery, cleverness, creativity\nStudent has gone beyond what was expected and required, e.g., extraordinary effort, additional tools not addressed by this course, unusually sophisticated application of tools from course.\nTools and techniques from the course are applied very competently and, perhaps,somewhat creatively. Chosen task was acceptable, but fairly conservative in ambition.\nStudent does not display the expected level of mastery of the tools and techniques in this course. Chosen task was too limited in scope.\n\n\nEase of access for instructor, compliance with course conventions for submitted work\nAccess as easy as possible, code runs!\nSatisfactory\nNot an earnest effort to reduce friction and comply with conventions and/or code does not run",
    "crumbs": [
      "Assignments",
      "Problet Set Overview"
    ]
  },
  {
    "objectID": "course-info/syllabus.html",
    "href": "course-info/syllabus.html",
    "title": "MOLB 7950 Syllabus",
    "section": "",
    "text": "MOLB 7950 is a hands-on tutorial of skills and theory needed to process, analyze, and visualize output from large biological data sets. We emphasize the R statistical computing environment.\n🗓️ Class will run from Aug 26 - Oct 29\n📍 Classes will be held in-person at locations found on the schedule page.\n🕘 Class time is 9:00-10:30am\nMOLB 7950 is a three credit hour course.\nThe course is divided into blocks:\n\n\nTHe Bootcamp block covers R programming and introduces important statistical concepts and approaches. We will also cover data types you will encounter during biological data analysis and approaches for their analysis.\nDuring the bootcamp block, we will meet everyday for 90 minutes to cover fundamental concepts you will need throughout the course.\n\n\n\nAfter Bootcamp, will cover experimental approaches used to analyze DNA and RNA. Each block spans ~4 weeks, with each week focused on a particular type of experiment (see below). Each block covers statistical concepts needed for rigorous analysis and analysis approaches to process raw data to results (tables and figures) using reproducible coding techniques.\nIn most weeks we will discuss and analyze data from a publication. You are responsible for reading the week’s material before class begins on Monday.\n\n\n\nThe DNA block covers genome sequencing for identifying mutations, and two approaches for analyzing chromatin state (ChIP-seq and MNase-seq).\nThe RNA block covers RNA-seq, alternative splicing, differential gene expression, and RNA:protein interactions.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#course-overview",
    "href": "course-info/syllabus.html#course-overview",
    "title": "MOLB 7950 Syllabus",
    "section": "",
    "text": "MOLB 7950 is a hands-on tutorial of skills and theory needed to process, analyze, and visualize output from large biological data sets. We emphasize the R statistical computing environment.\n🗓️ Class will run from Aug 26 - Oct 29\n📍 Classes will be held in-person at locations found on the schedule page.\n🕘 Class time is 9:00-10:30am\nMOLB 7950 is a three credit hour course.\nThe course is divided into blocks:\n\n\nTHe Bootcamp block covers R programming and introduces important statistical concepts and approaches. We will also cover data types you will encounter during biological data analysis and approaches for their analysis.\nDuring the bootcamp block, we will meet everyday for 90 minutes to cover fundamental concepts you will need throughout the course.\n\n\n\nAfter Bootcamp, will cover experimental approaches used to analyze DNA and RNA. Each block spans ~4 weeks, with each week focused on a particular type of experiment (see below). Each block covers statistical concepts needed for rigorous analysis and analysis approaches to process raw data to results (tables and figures) using reproducible coding techniques.\nIn most weeks we will discuss and analyze data from a publication. You are responsible for reading the week’s material before class begins on Monday.\n\n\n\nThe DNA block covers genome sequencing for identifying mutations, and two approaches for analyzing chromatin state (ChIP-seq and MNase-seq).\nThe RNA block covers RNA-seq, alternative splicing, differential gene expression, and RNA:protein interactions.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#schedule",
    "href": "course-info/syllabus.html#schedule",
    "title": "MOLB 7950 Syllabus",
    "section": "Schedule",
    "text": "Schedule\nClasses begin on August 26 and end on October 29. Dates are from the Fall 2025 Academic Calendar.\nDuring the Bootcamp block, classes will be held every day, Mon-Fri from 9:00-10:30am.\nDuring the DNA & RNA blocks, we will have in-class exercises and discussion on Mon-Wed-Fri 9:00-10:30am.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#location",
    "href": "course-info/syllabus.html#location",
    "title": "MOLB 7950 Syllabus",
    "section": "Location",
    "text": "Location\nClasses will be held in-person in a variety of different rooms. Please check the schedule page to see each class’s room assignment. All classes will be recorded and made available through Canvas.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#policies",
    "href": "course-info/syllabus.html#policies",
    "title": "MOLB 7950 Syllabus",
    "section": "Policies",
    "text": "Policies\n\nAttendance\nClass attendance is a firm expectation; frequent absences or tardiness are considered cause for a grade reduction.\nif you are sick, please let us know (e-mail Srinivas and Matt) and STAY HOME.\nAnticipated absences outside of sickness should be reported to the instructors of a given block as soon as possible to make plans for possible accommodation.\nWe will record all lectures on Panopto and they will be available online through Canvas.\n\n\nLate and missed work\nWe have a late work policy for homework assignments:\n\nIf a problem set set is late but within 24 hours of due date/time, the grade will be reduced by 50%\nIf a problem set is returned any later, no credit will be given.\nAll regrade requests must be discussed with the professor within one week of receiving your grade. There will be no grade changes after the final project.\n\n\n\nDiversity & Inclusiveness\nOur view is that students from all diverse backgrounds and perspectives will be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class iss a resource, strength, and benefit.\n\n\nDisability Policy\nStudents with disabilities who need accommodations are encouraged to contact the Office of Disability, Access & Inclusion as soon as possible to ensure that accommodations are implemented in a timely fashion.\n\n\nHonor code\nAcademic dishonesty will not be tolerated and is grounds for dismissal from the class with a failing grade (“F”). For other information, please consult the Graduate Student Handbook.\nChatGPT will probably be able to answer most coding questions you ask of it. While it is useful for fleshing out an initial approach from pseudocode, we do not recommend using it, as these conceptual approaches are an essential foundation for buildling expertise in bioinformatic analysis.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#problem-sets",
    "href": "course-info/syllabus.html#problem-sets",
    "title": "MOLB 7950 Syllabus",
    "section": "Problem Sets",
    "text": "Problem Sets\n\nProblem sets will be assigned at the end of each class.\nYou can use external resources but must explicitly cite where you have obtained code (both code you used directly and “paraphrased” code / code used as inspiration). Any reused code that is not explicitly cited will be treated as plagiarism.\nYou can discuss the content of assignments with others in this class. If you do so, you must acknowledge your collaborator(s) at the top of your assignment, for example: “Collaborators: Hillary and Bernie”. Failure to acknowledge collaborators will result in a grade of 0. You may not copy code and/or answers directly from another student. If you copy other work, both parties will receive a grade of 0.\nThe problem set with the lowest score for each student will be dropped.\nRather than copying someone’s work, ask for help. You are not alone in this course!",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#professionalism",
    "href": "course-info/syllabus.html#professionalism",
    "title": "MOLB 7950 Syllabus",
    "section": "Professionalism",
    "text": "Professionalism\n\nPlease refrain from texting or using your computer for anything other than coursework during class.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#assignments-and-grading",
    "href": "course-info/syllabus.html#assignments-and-grading",
    "title": "MOLB 7950 Syllabus",
    "section": "Assignments and Grading",
    "text": "Assignments and Grading\nThe course measures learning through daily problem sets, a final project, and your participation.\n\n\n\nType\n% of grade\n\n\n\n\nProblem Sets\n60\n\n\nFinal Project\n20\n\n\nParticipation\n20\n\n\n\nGrades will be assigned as follows:\n\n\n\nPercent total points\nGrade\n\n\n\n\n&gt;= 95\nA\n\n\n&gt;= 90\nA-\n\n\n&gt;= 85\nB+\n\n\n&gt;= 80\nB\n\n\n\n\nProblem sets\nWe reinforce concepts with problem sets assigned at the end of class that should take ~60 minutes to complete.\nProblems sets assigned on Friday will be more substantial, requiring ~1-2 hours to complete.\nTogether the problem sets constitute 60% of your grade.\n\n\n\n\n\n\n\n\n\n\nAssigned\nDue\nGrades By\nWho grades\nTime to complete (approx)\n\n\n\n\nMon @ 12pm\nTues @ 5pm\nWed @ 5pm\nInstructors / TAs\n60 min\n\n\nTue @ 12pm\nWed @ 5pm\nThurs @ 5pm\nInstructors / TAs\n60 min\n\n\nWed @ 12pm\nThurs @ 5pm\nFri @ 5pm\nInstructors / TAs\n60 min\n\n\nThurs @ 12pm\nFri @ 5pm\nTues @ 5pm\nInstructors / TAs\n60 min\n\n\nFri @ 12pm\nMon @ 5pm\nWed @ 5pm\nInstructors / TAs\n1-2 hr\n\n\n\n\n\nFinal projects\nFinal projects can be completed in groups of 1-3 people. Projects will involve analysis of existing public data sets and end with a short presentation the last week of class. The final project constitutes 20% of your grade.\n\n\nGrading Rubrics\n\nProblem Set Rubric\nProblem sets are worth 60% of your grade. Values in parentheses represent point values for each level from 20 points total. This rubric will be assessed at the end of the semester.\n\n\n\n\n\n\n\n\n\nCriteria\nExpert\nCompetent\nNeeds Improvement\n\n\n\n\nCoding style\nStudent has gone beyond what was expected and required, coding manual is followed, code is well commented\nCoding style lacks refinement and has some errors, but code is readable and has some comments\nMany errors in coding style, little attention paid to making the code human readable\n\n\nCoding strategy\nComplicated problem broken down into sub-problems that are individually much simpler. Code is efficient, correct, and minimal. Code uses appropriate data structure (list, data frame, vector/matrix/array). Code checks for common errors\nCode is correct, but could be edited down to leaner code. Some “hacking” instead of using suitable data structure. Some checks for errors.\nCode tackles complicated problem in one big chunk. Code is repetitive and could easily be functionalized. No anticipation of errors.\n\n\nPresentation: graphs\nGraph(s) carefully tuned for desired purpose. One graph illustrates one point\nGraph(s) well chosen, but with a few minor problems: inappropriate aspect ratios, poor labels.\nGraph(s) poorly chosen to support questions.\n\n\nPresentation: tables\nTable(s) carefully constructed to make it easy to perform important comparisons. Careful styling highlights important features.\nTable(s) generally appropriate but possibly some minor formatting deficiencies.\nTable(s) with too many, or inconsistent, decimal places. Table(s) not appropriate for questions and findings. Major display problems.\n\n\nAchievement, mastery, cleverness, creativity\nStudent has gone beyond what was expected and required, e.g., extraordinary effort, additional tools not addressed by this course, unusually sophisticated application of tools from course.\nTools and techniques from the course are applied very competently and, perhaps,somewhat creatively. Chosen task was acceptable, but fairly conservative in ambition.\nStudent does not display the expected level of mastery of the tools and techniques in this course. Chosen task was too limited in scope.\n\n\nEase of access for instructor, compliance with course conventions for submitted work\nAccess as easy as possible, code runs!\nSatisfactory\nNot an earnest effort to reduce friction and comply with conventions and/or code does not run\n\n\n\n\n\nParticipation rubric\nAttendance & participation is worth 20% of your grade. Values in parentheses represent point values for each level from 20 points total. This rubric will be assessed at the end of the semester.\n\n\n\n\n\n\n\n\n\nCriteria\nExpert\nCompetent\nNeeds improvement\n\n\n\n\nAttendance (physically present for class, or coordinating with instructor when absent)\nAttends class regularly (5)\nAttends most classes (4)\nAttends some classes (0-3)\n\n\nPreparation (activities required for in-class participation, like surveys and software installation)\nCompletes requested activities prior to class (5)\nCompletes most requested activities prior to class, sometimes needs to finish during class (4)\nRarely completes requested activities prior to class, often takes class time to complete (0-3)\n\n\nEngagement (in-class activities like coding exercises and discussion)\nActively engages in class activities (10)\nSometimes engages in class activities (8)\nDoesn’t engage in class activities (0-7)",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#related-coursework",
    "href": "course-info/syllabus.html#related-coursework",
    "title": "MOLB 7950 Syllabus",
    "section": "Related coursework",
    "text": "Related coursework\nIn previous iterations of this course, we taught command-line (bash, grep, awk, etc) and Python programming. These skills are useful, but for consistency we opted to focus on R programming and RStudio as an analysis environment.\nAMC also offers shorter workshops on specific analysis strategies that you might find helpful.\n\nMOLB 7900: Practical Computational Biology for Biologists — Python (Taliaferro and Ramachandran)\nMOLB 7910: Practical Computational Biology for Biologists — R/R Studio (Jagannathan and Mukherjee)",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#acknowldgements-attribution",
    "href": "course-info/syllabus.html#acknowldgements-attribution",
    "title": "MOLB 7950 Syllabus",
    "section": "Acknowldgements & Attribution",
    "text": "Acknowldgements & Attribution\n\nInstructor contributions\nSeveral people have contributed to course development over the past several years.\n\nSujatha Jagannathan contributed the original R bootcamp material.\nSrinivas Ramachandran contributed material for the DNA block, including lecture material and examples for yeast chromatin accessibility and factor mapping.\nMatt Taliaferro contributed material for the RNA block, including lecture material and examples for RNA expression and splicing analysis.\nKent Riemondy and Kristen Wells contributed material for single-cell RNA sequencing.\nJay Hesselberth and Neel Mukherjee revamped much of this material in Fall 2023.\n\n\n\nExternal resources\nWe have borrowed from several (open licensed) resources for course content, including:\n\nStats 545 at UBC, particularly their grading rubrics\nCourses from Mine Çetinkaya-Rundel, particularly inspiration for quarto websites",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#land-acknowledgement",
    "href": "course-info/syllabus.html#land-acknowledgement",
    "title": "MOLB 7950 Syllabus",
    "section": "Land acknowledgement",
    "text": "Land acknowledgement\nThe University of Colorado honors and recognizes the many contributions of Indigenous peoples in our state. The University of Colorado acknowledges that it is located on the traditional territories and ancestral homelands of the Cheyenne, Arapaho, Ute and many other Native American nations. Their forced removal from these territories has caused devastating and lasting impacts. While the University of Colorado can never undo or rectify the devastation wrought on Indigenous peoples, we commit to improving and enhancing engagement with Indigenous peoples and issues locally and globally.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "exercises/ex-01.html",
    "href": "exercises/ex-01.html",
    "title": "R Bootcamp - Day 1",
    "section": "",
    "text": "We are using RStudio through Posit Cloud for the class.\nLook at RStudio panels one at a time.\nEnvironment, History, Console, Files, Plots, Packages, Help, etc.\n\nSee menu:\nHelp &gt; Cheat Sheets &gt; RStudio IDE Cheat Sheet"
  },
  {
    "objectID": "exercises/ex-01.html#rstudio---exercise-1",
    "href": "exercises/ex-01.html#rstudio---exercise-1",
    "title": "R Bootcamp - Day 1",
    "section": "",
    "text": "We are using RStudio through Posit Cloud for the class.\nLook at RStudio panels one at a time.\nEnvironment, History, Console, Files, Plots, Packages, Help, etc.\n\nSee menu:\nHelp &gt; Cheat Sheets &gt; RStudio IDE Cheat Sheet"
  },
  {
    "objectID": "exercises/ex-01.html#r-as-a-calculator---exercise-2",
    "href": "exercises/ex-01.html#r-as-a-calculator---exercise-2",
    "title": "R Bootcamp - Day 1",
    "section": "R as a calculator - Exercise 2",
    "text": "R as a calculator - Exercise 2\n\nR can function like an advanced calculator\n\n\nTry simple math.\nAssign a numeric value to an object.\n\n\n&lt;- and = are assignment operators.\nBy convention, R programmers use &lt;-.\n\nx &lt;- 1 reads “set the value of x to 1”.\n\n. . .\n= and == are two different operators.\n\na = is used for assignment (e.g., x = 1)\na == tests for equivalence (e.g. x == 1 says “does x equal 1?”)"
  },
  {
    "objectID": "exercises/ex-01.html#functions-and-arguments---exercise-3",
    "href": "exercises/ex-01.html#functions-and-arguments---exercise-3",
    "title": "R Bootcamp - Day 1",
    "section": "Functions and arguments - Exercise 3",
    "text": "Functions and arguments - Exercise 3"
  },
  {
    "objectID": "exercises/ex-01.html#writing-a-simple-function---exercise-4",
    "href": "exercises/ex-01.html#writing-a-simple-function---exercise-4",
    "title": "R Bootcamp - Day 1",
    "section": "Writing a simple function - Exercise 4",
    "text": "Writing a simple function - Exercise 4"
  },
  {
    "objectID": "exercises/ex-01.html#data-types---exercise-5",
    "href": "exercises/ex-01.html#data-types---exercise-5",
    "title": "R Bootcamp - Day 1",
    "section": "Data types - Exercise 5",
    "text": "Data types - Exercise 5\n\nThere are many data types in R.\nWe’ll mainly use numeric, character, and logical."
  },
  {
    "objectID": "exercises/ex-01.html#vectors---exercise-6",
    "href": "exercises/ex-01.html#vectors---exercise-6",
    "title": "R Bootcamp - Day 1",
    "section": "Vectors - Exercise 6",
    "text": "Vectors - Exercise 6\nLet’s create some vectors.\n\nThe c function combines values together (e.g., c(1,2,3))\n\n. . ."
  },
  {
    "objectID": "exercises/ex-01.html#data-frames",
    "href": "exercises/ex-01.html#data-frames",
    "title": "R Bootcamp - Day 1",
    "section": "Data frames",
    "text": "Data frames\n\nA data.frame is a rectangle, where each column is a vector, and each row is a slice across vectors.\ndata.frame columns are vectors, and can have different types (numeric, character, factor, etc.).\nA data.frame is constructed with data.frame()."
  },
  {
    "objectID": "exercises/ex-01.html#data-frames-tibbles---exercise-7",
    "href": "exercises/ex-01.html#data-frames-tibbles---exercise-7",
    "title": "R Bootcamp - Day 1",
    "section": "Data frames & tibbles - Exercise 7",
    "text": "Data frames & tibbles - Exercise 7\nCreate a data.frame and tibble.\nNow echo the contents of df and tbl to the console and inspect"
  },
  {
    "objectID": "exercises/ex-01.html#r-packages---exercise-8",
    "href": "exercises/ex-01.html#r-packages---exercise-8",
    "title": "R Bootcamp - Day 1",
    "section": "R packages - Exercise 8",
    "text": "R packages - Exercise 8\nLet’s do the following to explore R packages:\n\nLook at the “Environment” panel in Rstudio\nExplore Global Environment\nExplore the contents of a package"
  },
  {
    "objectID": "exercises/ex-01.html#quarto-exercise---exercise-9",
    "href": "exercises/ex-01.html#quarto-exercise---exercise-9",
    "title": "R Bootcamp - Day 1",
    "section": "Quarto Exercise - Exercise 9",
    "text": "Quarto Exercise - Exercise 9\nLet’s do the following to explore Quarto documents:\n\nCreate a new Quarto document\nRender the document to see the output"
  },
  {
    "objectID": "exercises/ex-01.html#problem-sets-and-submission",
    "href": "exercises/ex-01.html#problem-sets-and-submission",
    "title": "R Bootcamp - Day 1",
    "section": "Problem sets and submission",
    "text": "Problem sets and submission\nYour first problem set is in problem-sets/ps-01.qmd"
  },
  {
    "objectID": "exercises/ex-03.html",
    "href": "exercises/ex-03.html",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "",
    "text": "Explore these data sets:\n\ndplyr::starwars\n\ndplyr::band_members, dplyr::band_instruments, dplyr::band_instruments2"
  },
  {
    "objectID": "exercises/ex-03.html#todays-datasets---exercise-1",
    "href": "exercises/ex-03.html#todays-datasets---exercise-1",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "",
    "text": "Explore these data sets:\n\ndplyr::starwars\n\ndplyr::band_members, dplyr::band_instruments, dplyr::band_instruments2"
  },
  {
    "objectID": "exercises/ex-03.html#arrange---exercise-2",
    "href": "exercises/ex-03.html#arrange---exercise-2",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "arrange - Exercise 2",
    "text": "arrange - Exercise 2"
  },
  {
    "objectID": "exercises/ex-03.html#filter---exercise-3",
    "href": "exercises/ex-03.html#filter---exercise-3",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "filter - Exercise 3",
    "text": "filter - Exercise 3\nfilter by membership\n\n# filter based on skin color\n\nConditions can be combined using & (and), | (or).\n\n# filter on skin and eye color\n\nselect - Exercise 4\nmutate (& pipe |&gt;)- Exercise 5\n\n# create a new column to display height in meters\n\n# using the pipe to feed data into multiple functions sequentially\n\n# mutate allows you to refer to columns that you’ve just created\n\n# output needs to be saved into a new dataframe since dplyr does not \"change\" the original dataframe\n\n# using if_else clauses with mutate"
  },
  {
    "objectID": "exercises/ex-03.html#case_when---exercise-6",
    "href": "exercises/ex-03.html#case_when---exercise-6",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "case_when - Exercise 6",
    "text": "case_when - Exercise 6\n\n# create categories based on height\n\n\n# multiple conditions with case_when\n\nsummarise - Exercise 7\ngroup_by + summarize - Exercise 8\n\n# multiple grouping variables"
  },
  {
    "objectID": "exercises/ex-03.html#across---exercise-9",
    "href": "exercises/ex-03.html#across---exercise-9",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "across - Exercise 9",
    "text": "across - Exercise 9\n\n# apply mean to multiple columns\n\n\n# apply multiple functions with list()\n\n\n# combine across() with group_by()"
  },
  {
    "objectID": "exercises/ex-05.html",
    "href": "exercises/ex-05.html",
    "title": "R Bootcamp - Day 5",
    "section": "",
    "text": "Introduce ggplot2 & today’s data sets (Exercise 1)\nUnderstand the basics of ggplot2 (Exercise 2, 3)\nGeom functions (Exercise 4-8)\nGeom_point properties (Exercise 9)\nPosition adjustments (Exercise 10)\nCoordinate and Scale Functions (Exercise 11)\nZooming into a plot (Exercise 12)\n\n\n\nFaceting (Exercise 13)\nThemes (Exercise 14)\nLabels & Legends (Exercise 15)\nAdding lines to plots (Exercise 16)\nMaking multi-panel figures (Exercise 17)\nSaving a plot (Exercise 18)"
  },
  {
    "objectID": "exercises/ex-05.html#class-4-5-outline",
    "href": "exercises/ex-05.html#class-4-5-outline",
    "title": "R Bootcamp - Day 5",
    "section": "",
    "text": "Introduce ggplot2 & today’s data sets (Exercise 1)\nUnderstand the basics of ggplot2 (Exercise 2, 3)\nGeom functions (Exercise 4-8)\nGeom_point properties (Exercise 9)\nPosition adjustments (Exercise 10)\nCoordinate and Scale Functions (Exercise 11)\nZooming into a plot (Exercise 12)\n\n\n\nFaceting (Exercise 13)\nThemes (Exercise 14)\nLabels & Legends (Exercise 15)\nAdding lines to plots (Exercise 16)\nMaking multi-panel figures (Exercise 17)\nSaving a plot (Exercise 18)"
  },
  {
    "objectID": "exercises/ex-05.html#shape-size-fill-color-and-transparency---exercise-9",
    "href": "exercises/ex-05.html#shape-size-fill-color-and-transparency---exercise-9",
    "title": "R Bootcamp - Day 5",
    "section": "shape, size, fill, color, and transparency - Exercise 9",
    "text": "shape, size, fill, color, and transparency - Exercise 9\nGet a diamonds subset.\nNote that aesthetics can also be defined within a geom.\nThis is useful if you use two different geoms that share an aesthetic."
  },
  {
    "objectID": "exercises/ex-05.html#position-adjustments---exercise-10",
    "href": "exercises/ex-05.html#position-adjustments---exercise-10",
    "title": "R Bootcamp - Day 5",
    "section": "Position adjustments - Exercise 10",
    "text": "Position adjustments - Exercise 10\nA stacked bar chart.\nDodged bars are easier to read (proportions are clearer)"
  },
  {
    "objectID": "exercises/ex-05.html#coordinate-and-scale-functions---exercise-11",
    "href": "exercises/ex-05.html#coordinate-and-scale-functions---exercise-11",
    "title": "R Bootcamp - Day 5",
    "section": "Coordinate and Scale Functions - Exercise 11",
    "text": "Coordinate and Scale Functions - Exercise 11\nLogarithmic axes - 1\nNote the difference between axis labels in these two examples.\n\nLogarithmic axes - 2\n\nFlipping coordinate system (swapping x and y)\n\nNow flip the axis.\nBrief aside: ggplot can handle on-the-fly data transformations.\nHere we log-transform carat and convert USD to CAD."
  },
  {
    "objectID": "exercises/ex-05.html#zooming-into-a-plot---exercise-12",
    "href": "exercises/ex-05.html#zooming-into-a-plot---exercise-12",
    "title": "R Bootcamp - Day 5",
    "section": "Zooming into a plot - Exercise 12",
    "text": "Zooming into a plot - Exercise 12\nWe might want to change the limits of x or y axes to zoom in."
  },
  {
    "objectID": "exercises/ex-05.html#faceting-to-plot-subsets-of-data-into-separate-panels---exercise-13",
    "href": "exercises/ex-05.html#faceting-to-plot-subsets-of-data-into-separate-panels---exercise-13",
    "title": "R Bootcamp - Day 5",
    "section": "Faceting to plot subsets of data into separate panels - Exercise 13",
    "text": "Faceting to plot subsets of data into separate panels - Exercise 13\nA density plot we’ve seen before.\nWhich variables can we use to subdivide the data?\n\nFaceted by cut\nLet’s also use facet_grid() to facet by two variables.\nFaceted by clarity and cut.\n\nScatter plot with facets."
  },
  {
    "objectID": "exercises/ex-05.html#themes---exercise-14",
    "href": "exercises/ex-05.html#themes---exercise-14",
    "title": "R Bootcamp - Day 5",
    "section": "Themes - Exercise 14",
    "text": "Themes - Exercise 14\nScatter plot with default theme.\nChange the theme with theme_bw().\nMy go-to is cowplot::theme_cowplot().\nIt implements much of the advice in the “Dataviz” book, i.e.. YOUR LABELS ARE TOO SMALL.\nWe’re not going to cover it, but you can also customize pre-existing themes."
  },
  {
    "objectID": "exercises/ex-05.html#labels-legends---exercise-15",
    "href": "exercises/ex-05.html#labels-legends---exercise-15",
    "title": "R Bootcamp - Day 5",
    "section": "Labels & Legends - Exercise 15",
    "text": "Labels & Legends - Exercise 15\nUse labs() to add / change plot labels."
  },
  {
    "objectID": "exercises/ex-05.html#how-to-add-a-line-to-a-plot-exercise-16",
    "href": "exercises/ex-05.html#how-to-add-a-line-to-a-plot-exercise-16",
    "title": "R Bootcamp - Day 5",
    "section": "How to add a line to a plot? (Exercise 16)",
    "text": "How to add a line to a plot? (Exercise 16)\n\nAlso try:"
  },
  {
    "objectID": "exercises/ex-05.html#how-to-combine-multiple-plots-into-a-figure-exercise-17",
    "href": "exercises/ex-05.html#how-to-combine-multiple-plots-into-a-figure-exercise-17",
    "title": "R Bootcamp - Day 5",
    "section": "How to combine multiple plots into a figure? (Exercise 17)",
    "text": "How to combine multiple plots into a figure? (Exercise 17)\nWe have 4 legends - can they be condensed?\nYes, but it is not exactly straightforward.\nneed to scroll below"
  },
  {
    "objectID": "exercises/ex-05.html#saving-plots-exercise-18",
    "href": "exercises/ex-05.html#saving-plots-exercise-18",
    "title": "R Bootcamp - Day 5",
    "section": "Saving plots (Exercise 18)",
    "text": "Saving plots (Exercise 18)\nSaves last plot as 5’ x 5’ file named “plot_final.png” in working directory.\nMatches file type to file extension."
  },
  {
    "objectID": "exercises/ex-08.html",
    "href": "exercises/ex-08.html",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "",
    "text": "In this problem set, you’ll work with the Brauer gene expression dataset to practice comprehensive tidyverse skills including data tidying, transformation, joins, pivoting, string manipulation, and statistical modeling using broom. The dataset contains gene expression measurements for yeast genes under different nutrient limitations and growth rates.\n\nBefore we start tidying and analyzing the data, take a moment to predict what you might find.\n\nQuestion: What patterns do you expect to see in gene expression across different nutrients and growth rates?\nHypothesis: Genes involved in nutrient uptake and metabolism will show higher expression under their respective limiting conditions."
  },
  {
    "objectID": "exercises/ex-08.html#predictions",
    "href": "exercises/ex-08.html#predictions",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "",
    "text": "Before we start tidying and analyzing the data, take a moment to predict what you might find.\n\nQuestion: What patterns do you expect to see in gene expression across different nutrients and growth rates?\nHypothesis: Genes involved in nutrient uptake and metabolism will show higher expression under their respective limiting conditions."
  },
  {
    "objectID": "exercises/ex-08.html#load-required-libraries",
    "href": "exercises/ex-08.html#load-required-libraries",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n2.1 Load Required Libraries",
    "text": "2.1 Load Required Libraries\n\nCode# Load required libraries"
  },
  {
    "objectID": "exercises/ex-08.html#load-the-data",
    "href": "exercises/ex-08.html#load-the-data",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n2.2 Load the Data",
    "text": "2.2 Load the Data\nTask 1: Load the raw Brauer gene expression data and examine its structure. What makes this data “messy” or untidy?\nBreadcrumbs: Use read_tsv() to load the data from the URL. Examine column names and the first few rows. Think about tidy data principles - what issues do you see with the current format?\n\nCode# Load the Brauer gene expression data\n# URL: \"https://github.com/rnabioco/molb-7950/raw/refs/heads/main/data/bootcamp/brauer_gene_exp_raw.tsv.gz\"\n\n\n\nCode# Examine the structure of the data"
  },
  {
    "objectID": "exercises/ex-08.html#separate-the-name-column",
    "href": "exercises/ex-08.html#separate-the-name-column",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n3.1 Separate the NAME Column",
    "text": "3.1 Separate the NAME Column\nTask 2: The NAME column contains multiple pieces of information separated by “||”. Split this into meaningful columns.\nBreadcrumbs: Use separate_wider_delim() to split the NAME column. You’ll want columns for gene name, biological process, molecular function, systematic name, and number. Don’t forget to clean up whitespace and handle empty strings.\n\nCode# Separate the NAME column into meaningful components"
  },
  {
    "objectID": "exercises/ex-08.html#create-a-tidy-dataset",
    "href": "exercises/ex-08.html#create-a-tidy-dataset",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n3.2 Create a Tidy Dataset",
    "text": "3.2 Create a Tidy Dataset\nTask 3: Transform the wide-format expression data into a long format suitable for analysis.\nBreadcrumbs: First select the relevant columns (systematic_name and the expression columns). Then use pivot_longer() to convert expression columns to rows. The column names contain both nutrient type and growth rate information.\n\nCode# Transform to long format"
  },
  {
    "objectID": "exercises/ex-08.html#parse-nutrient-and-rate-information",
    "href": "exercises/ex-08.html#parse-nutrient-and-rate-information",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n3.3 Parse Nutrient and Rate Information",
    "text": "3.3 Parse Nutrient and Rate Information\nTask 4: Extract nutrient type and growth rate from the column names in your long dataset.\nBreadcrumbs: The column names follow a pattern like “G0.05” where the first character is the nutrient abbreviation and the rest is the growth rate. Use separate_wider_position() to split these. Create a lookup table for nutrient abbreviations.\n\nCode# Extract nutrient and growth rate information\n\n\n\nCode# Create nutrient lookup table"
  },
  {
    "objectID": "exercises/ex-08.html#filter-and-clean",
    "href": "exercises/ex-08.html#filter-and-clean",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n4.1 Filter and Clean",
    "text": "4.1 Filter and Clean\nTask 5: Remove any rows with missing systematic names and add meaningful nutrient names.\nBreadcrumbs: Use filter() to remove empty systematic names. Create a nutrient lookup table and use left_join() to add full nutrient names. Convert appropriate columns to factors.\n\nCode# Filter and clean the data"
  },
  {
    "objectID": "exercises/ex-08.html#explore-expression-patterns",
    "href": "exercises/ex-08.html#explore-expression-patterns",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n4.2 Explore Expression Patterns",
    "text": "4.2 Explore Expression Patterns\nTask 6: Calculate summary statistics for gene expression by nutrient type.\nBreadcrumbs: Use group_by() and summarize() to calculate mean, median, and standard deviation of expression values for each nutrient. Which nutrients show the highest variability in expression?\n\nCode# Calculate summary statistics by nutrient"
  },
  {
    "objectID": "exercises/ex-08.html#identify-high-and-low-expression",
    "href": "exercises/ex-08.html#identify-high-and-low-expression",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n4.3 Identify High and Low Expression",
    "text": "4.3 Identify High and Low Expression\nTask 7: Find genes with extreme expression values under different conditions.\nBreadcrumbs: For each nutrient-rate combination, identify the top 5 highest and lowest expressing genes. Use slice_max() and slice_min() or ranking functions. What patterns do you notice?\n\nCode# Find genes with extreme expression values"
  },
  {
    "objectID": "exercises/ex-11.html",
    "href": "exercises/ex-11.html",
    "title": "Stats Bootcamp - class 11",
    "section": "",
    "text": "Learn types of variables\nCalculate and visualize summary statistics\nProperties of data distributions\nCentral limit theorem"
  },
  {
    "objectID": "exercises/ex-11.html#learning-objectives",
    "href": "exercises/ex-11.html#learning-objectives",
    "title": "Stats Bootcamp - class 11",
    "section": "",
    "text": "Learn types of variables\nCalculate and visualize summary statistics\nProperties of data distributions\nCentral limit theorem"
  },
  {
    "objectID": "exercises/ex-11.html#quantitative-variables",
    "href": "exercises/ex-11.html#quantitative-variables",
    "title": "Stats Bootcamp - class 11",
    "section": "Quantitative Variables",
    "text": "Quantitative Variables\nDiscrete variable: numeric variables that have a countable number of values between any two values - integer in R (e.g., number of mice, read counts).\nContinuous variable: numeric variables that have an infinite number of values between any two values - numeric in R (e.g., normalized expression values, fluorescent intensity)."
  },
  {
    "objectID": "exercises/ex-11.html#categorical-variables",
    "href": "exercises/ex-11.html#categorical-variables",
    "title": "Stats Bootcamp - class 11",
    "section": "Categorical Variables",
    "text": "Categorical Variables\nNominal variable: (unordered) random variables have categories where order doesn’t matter - factor in R (e.g., country, type of gene, genotype).\nOrdinal variable: (ordered) random variables have ordered categories - order of levels in R ( e.g. grade of tumor)."
  },
  {
    "objectID": "exercises/ex-11.html#distributions-and-probabilities",
    "href": "exercises/ex-11.html#distributions-and-probabilities",
    "title": "Stats Bootcamp - class 11",
    "section": "Distributions and probabilities",
    "text": "Distributions and probabilities\nA distribution in statistics is a function that shows the possible values for a variable and how often they occur.\nWe can visualize this with a histogram or density plots as we did earlier.\nWe are going to start with simulated data and then use Palmer Penguins later."
  },
  {
    "objectID": "exercises/ex-11.html#create-a-normal-distribution",
    "href": "exercises/ex-11.html#create-a-normal-distribution",
    "title": "Stats Bootcamp - class 11",
    "section": "Create a normal distribution",
    "text": "Create a normal distribution\nAssume that the test scores of a college entrance exam fits a normal distribution. Furthermore, the mean test score is 76, and the standard deviation is 13.8.\n\nd &lt;- tibble(n1=rnorm(n = ??, mean = ??, sd = ??))\n\nhead(d)"
  },
  {
    "objectID": "exercises/ex-11.html#visualize-a-normal-distribution",
    "href": "exercises/ex-11.html#visualize-a-normal-distribution",
    "title": "Stats Bootcamp - class 11",
    "section": "Visualize a normal distribution",
    "text": "Visualize a normal distribution\nfirst we will look at a histogram n1\n\nggplot(data = ??,\n       aes(x=??)\n       ) +\n  geom_??() +\n  theme_cowplot()\n\n\nnext a density plot\n\nggplot(data = d,\n       aes(x=n1)\n       ) +\n  geom_??() +\n  geom_vline(xintercept = ??) + # draw mean\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#determine-the-probability-of-a-given-value",
    "href": "exercises/ex-11.html#determine-the-probability-of-a-given-value",
    "title": "Stats Bootcamp - class 11",
    "section": "Determine the probability of a given value",
    "text": "Determine the probability of a given value\nProbability is used to estimate how probable a sample is based on a given distribution.\nProbability refers to the area under curve (AUC) on the distribution curve. The higher the value, the more probable that the data come from this distribution.\nWhat is the probability of students scoring 85 or more in the exam?\n\ns &lt;- 85\npnorm(??, mean=76, sd=13.8, lower.tail = F)\n\n. . .\nWhat is the probability of students scoring 85 or less in the exam?\n\npnorm(s, mean=76, sd=13.8, lower.tail = T)\n\n\nProb of 85 or more is equivalent to the area under the curve to the right of 85.\n\nggplot(data = d,\n       aes(x=n1)\n       ) +\n  geom_density() +\n  geom_vline(xintercept = s) +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#determine-the-likelihood-of-a-given-value",
    "href": "exercises/ex-11.html#determine-the-likelihood-of-a-given-value",
    "title": "Stats Bootcamp - class 11",
    "section": "Determine the likelihood of a given value",
    "text": "Determine the likelihood of a given value\nLikelihood is used to estimate how good a model fits the data. Likelihood refers to a specific point on the distribution curve. The lower the likelihood, the worse the model fits the data.\nWhat is the likelihood of students scoring 85 on the exam?\n\nl &lt;- dnorm(s, mean=76, sd=13.8)\nl\n\n\nThe likelihood is the y-axis value on the curve when th x-axis = 85.\n\nggplot(data = d,\n       aes(x=n1)\n       ) +\n  geom_density() +\n  geom_vline(xintercept = s) +\n  geom_hline(yintercept = l) +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#now-to-real-messy-data",
    "href": "exercises/ex-11.html#now-to-real-messy-data",
    "title": "Stats Bootcamp - class 11",
    "section": "Now to real (messy!) data",
    "text": "Now to real (messy!) data\nWe will use the Palmer Penguins dataset\n\npenguins_raw\n\n# A tibble: 344 × 17\n   studyName `Sample Number` Species         Region Island Stage `Individual ID`\n   &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n 1 PAL0708                 1 Adelie Penguin… Anvers Torge… Adul… N1A1           \n 2 PAL0708                 2 Adelie Penguin… Anvers Torge… Adul… N1A2           \n 3 PAL0708                 3 Adelie Penguin… Anvers Torge… Adul… N2A1           \n 4 PAL0708                 4 Adelie Penguin… Anvers Torge… Adul… N2A2           \n 5 PAL0708                 5 Adelie Penguin… Anvers Torge… Adul… N3A1           \n 6 PAL0708                 6 Adelie Penguin… Anvers Torge… Adul… N3A2           \n 7 PAL0708                 7 Adelie Penguin… Anvers Torge… Adul… N4A1           \n 8 PAL0708                 8 Adelie Penguin… Anvers Torge… Adul… N4A2           \n 9 PAL0708                 9 Adelie Penguin… Anvers Torge… Adul… N5A1           \n10 PAL0708                10 Adelie Penguin… Anvers Torge… Adul… N5A2           \n# ℹ 334 more rows\n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n\n. . .\nYikes! Some of these column names have horrible formatting e.g. spaces, slashes, parenthesis. These characters can be misinterpreted by R. Also, long/wonky names makes coding annoying."
  },
  {
    "objectID": "exercises/ex-11.html#lets-tidy-the-names",
    "href": "exercises/ex-11.html#lets-tidy-the-names",
    "title": "Stats Bootcamp - class 11",
    "section": "Let’s tidy the names",
    "text": "Let’s tidy the names\n\npenguins_raw |&gt; colnames()\n\n [1] \"studyName\"           \"Sample Number\"       \"Species\"            \n [4] \"Region\"              \"Island\"              \"Stage\"              \n [7] \"Individual ID\"       \"Clutch Completion\"   \"Date Egg\"           \n[10] \"Culmen Length (mm)\"  \"Culmen Depth (mm)\"   \"Flipper Length (mm)\"\n[13] \"Body Mass (g)\"       \"Sex\"                 \"Delta 15 N (o/oo)\"  \n[16] \"Delta 13 C (o/oo)\"   \"Comments\"           \n\n\n. . .\njanitor package to the rescue.\n. . .\n. . .\nCreate a new object pen that has nice clean variable names. And get rid of any variable that is the same for all observations (not useful).\n\npen &lt;- penguins_raw |&gt;\n  clean_names() |&gt;\n  janitor::remove_constant()"
  },
  {
    "objectID": "exercises/ex-11.html#lets-inspect-the-data",
    "href": "exercises/ex-11.html#lets-inspect-the-data",
    "title": "Stats Bootcamp - class 11",
    "section": "Let’s inspect the data",
    "text": "Let’s inspect the data\n\npen |&gt;\n  str()\n\ntibble [344 × 15] (S3: tbl_df/tbl/data.frame)\n $ study_name       : chr [1:344] \"PAL0708\" \"PAL0708\" \"PAL0708\" \"PAL0708\" ...\n $ sample_number    : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...\n $ species          : chr [1:344] \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" ...\n $ island           : chr [1:344] \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" ...\n $ individual_id    : chr [1:344] \"N1A1\" \"N1A2\" \"N2A1\" \"N2A2\" ...\n $ clutch_completion: chr [1:344] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ date_egg         : Date[1:344], format: \"2007-11-11\" \"2007-11-11\" ...\n $ culmen_length_mm : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ culmen_depth_mm  : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: num [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : num [1:344] 3750 3800 3250 NA 3450 ...\n $ sex              : chr [1:344] \"MALE\" \"FEMALE\" \"FEMALE\" NA ...\n $ delta_15_n_o_oo  : num [1:344] NA 8.95 8.37 NA 8.77 ...\n $ delta_13_c_o_oo  : num [1:344] NA -24.7 -25.3 NA -25.3 ...\n $ comments         : chr [1:344] \"Not enough blood for isotopes.\" NA NA \"Adult not sampled.\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   studyName = col_character(),\n  ..   `Sample Number` = col_double(),\n  ..   Species = col_character(),\n  ..   Region = col_character(),\n  ..   Island = col_character(),\n  ..   Stage = col_character(),\n  ..   `Individual ID` = col_character(),\n  ..   `Clutch Completion` = col_character(),\n  ..   `Date Egg` = col_date(format = \"\"),\n  ..   `Culmen Length (mm)` = col_double(),\n  ..   `Culmen Depth (mm)` = col_double(),\n  ..   `Flipper Length (mm)` = col_double(),\n  ..   `Body Mass (g)` = col_double(),\n  ..   Sex = col_character(),\n  ..   `Delta 15 N (o/oo)` = col_double(),\n  ..   `Delta 13 C (o/oo)` = col_double(),\n  ..   Comments = col_character()\n  .. )\n\n\n\nLet’s select a few of these columns to keep and get rid of NAs\n\np &lt;- pen |&gt;\n  select(species, island, culmen_length_mm, flipper_length_mm, body_mass_g, sex) |&gt;\n  drop_na()\n\n. . .\nclean species names\n\nunique(p$species)\n\n[1] \"Adelie Penguin (Pygoscelis adeliae)\"      \n[2] \"Gentoo penguin (Pygoscelis papua)\"        \n[3] \"Chinstrap penguin (Pygoscelis antarctica)\"\n\np &lt;- p |&gt;\n  mutate(species = str_remove(species, pattern = \" [P|p]en.*\")\n         )"
  },
  {
    "objectID": "exercises/ex-11.html#visualizing-quantitative-variables",
    "href": "exercises/ex-11.html#visualizing-quantitative-variables",
    "title": "Stats Bootcamp - class 11",
    "section": "Visualizing quantitative variables",
    "text": "Visualizing quantitative variables\nhistogram of body mass\n\nggplot(data = ??,\n       aes(x=??)\n       ) +\n  geom_histogram() +\n  theme_cowplot()\n\n\ndensity plot of body mass\n\nggplot(data = p,\n       aes(x=body_mass_g)\n       ) +\n  geom_??() +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#visualizing-categorical-variables",
    "href": "exercises/ex-11.html#visualizing-categorical-variables",
    "title": "Stats Bootcamp - class 11",
    "section": "Visualizing categorical variables",
    "text": "Visualizing categorical variables\nbarplot - 1 category\n\nggplot(data = p, aes(x = island, fill = island)) +\n    geom_bar() +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#barplot---categories-island-vs-sex",
    "href": "exercises/ex-11.html#barplot---categories-island-vs-sex",
    "title": "Stats Bootcamp - class 11",
    "section": "barplot - categories (island vs sex)",
    "text": "barplot - categories (island vs sex)\nstacked:\n\nggplot(data = p, aes(x = island, fill = sex)) +\n  geom_bar() +\n  theme_cowplot()\n\n\n\n\n\n\n\n\nproportion\n\nggplot(data = p, aes(x = island, fill = sex)) +\n  geom_bar(position = \"fill\") +\n  theme_cowplot()\n\n\n\n\n\n\n\n\nper category\n\nggplot(data = p, aes(x = island, fill = sex)) +\n  geom_bar(position = \"dodge\") +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#descriptive-statistics-for-continuous-data",
    "href": "exercises/ex-11.html#descriptive-statistics-for-continuous-data",
    "title": "Stats Bootcamp - class 11",
    "section": "Descriptive statistics for continuous data",
    "text": "Descriptive statistics for continuous data\n\nn: # observations/individuals or sample size\nmean (\\(\\mu\\)): sum of all observations divided by # of observations, \\(\\mu = \\displaystyle \\frac {\\sum x_i} {n}\\)\n\nmedian: the “middle” value of a data set. Not as sensitive to outliers as the mean."
  },
  {
    "objectID": "exercises/ex-11.html#descriptive-statistics-for-body-weight",
    "href": "exercises/ex-11.html#descriptive-statistics-for-body-weight",
    "title": "Stats Bootcamp - class 11",
    "section": "Descriptive statistics for body weight",
    "text": "Descriptive statistics for body weight\nLet’s look at the distribution again\n\nggplot(data = p,\n       aes(x=body_mass_g)\n       ) +\n  geom_density() +\n  theme_cowplot()\n\n\n\n\n\n\n\n. . .\nn\n\nlength(p$body_mass_g)\n\n[1] 333\n\n\n. . .\nmean\n\nmean(p$body_mass_g)\n\n[1] 4207.057\n\n\n. . .\nmedian\n\nmedian(p$body_mass_g)\n\n[1] 4050\n\n\n\nviz mean + median\n\nggplot(data = p,\n       aes(x=body_mass_g)\n       ) +\n  geom_density() +\n#  geom_vline() +\n#  geom_vline() +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#other-descriptive-statistics",
    "href": "exercises/ex-11.html#other-descriptive-statistics",
    "title": "Stats Bootcamp - class 11",
    "section": "Other descriptive statistics",
    "text": "Other descriptive statistics\nMin: minimum value.\nMax: maximum value.\nq1, q3: the first and the third quartile, respectively.\nIQR: interquartile range measures the spread of the middle half of your data (q3-q1).\nQuick way to get all these stats:\n\np |&gt;\n  get_summary_stats(body_mass_g, type = \"common\")\n\n# A tibble: 1 × 10\n  variable        n   min   max median   iqr  mean    sd    se    ci\n  &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 body_mass_g   333  2700  6300   4050  1225 4207.  805.  44.1  86.8\n\n\n. . . get mean, median\n\np |&gt;\n  get_summary_stats(body_mass_g,\n                    show = c(\"??\",\"??\")\n                    )"
  },
  {
    "objectID": "exercises/ex-11.html#statistics-describing-spread-of-values",
    "href": "exercises/ex-11.html#statistics-describing-spread-of-values",
    "title": "Stats Bootcamp - class 11",
    "section": "Statistics describing spread of values",
    "text": "Statistics describing spread of values\nVariance: the average of the squared differences from the mean\n\\(\\sigma^2 = \\displaystyle \\frac {\\sum (x_{i} - \\mu)^2}{n}\\)\nStandard Deviation: square root of the variance\n\\(\\sigma = \\sqrt {\\displaystyle \\frac {\\sum (x_{i} - \\mu)^2}{n}}\\)\n\nThe variance measures the mathematical dispersion of the data relative to the mean. However, it is more difficult to apply in a real-world sense because the values used to calculate it were squared.\n\nThe standard deviation, as the square root of the variance, is in the same units as the original values, which makes it much easier to work with and interpret w/respect to the mean."
  },
  {
    "objectID": "exercises/ex-11.html#other-stats-describing-spread-of-data",
    "href": "exercises/ex-11.html#other-stats-describing-spread-of-data",
    "title": "Stats Bootcamp - class 11",
    "section": "Other stats describing spread of data",
    "text": "Other stats describing spread of data\nConfidence Interval (ci): a range of values that you can be 95% (or x%) certain contains the true population mean. Gets into inferential statistics."
  },
  {
    "objectID": "exercises/ex-11.html#get-more-descriptive-stats-easily",
    "href": "exercises/ex-11.html#get-more-descriptive-stats-easily",
    "title": "Stats Bootcamp - class 11",
    "section": "Get more descriptive stats easily",
    "text": "Get more descriptive stats easily\n\np |&gt;\n  get_summary_stats(body_mass_g, show = c(\"mean\",\"median\",\"sd\"))\n\n# A tibble: 1 × 5\n  variable        n  mean median    sd\n  &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 body_mass_g   333 4207.   4050  805.\n\n\n. . .\nby species\n\np |&gt;\n  group_by(species) |&gt;\n  get_summary_stats(body_mass_g, show = c(\"mean\",\"median\",\"sd\"))\n\n# A tibble: 3 × 6\n  species   variable        n  mean median    sd\n  &lt;chr&gt;     &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie    body_mass_g   146 3706.   3700  459.\n2 Chinstrap body_mass_g    68 3733.   3700  384.\n3 Gentoo    body_mass_g   119 5092.   5050  501.\n\n\n\nby species and island\n\np |&gt;\n  group_by(species,island) |&gt;\n  get_summary_stats(body_mass_g, show = c(\"mean\",\"median\",\"sd\"))\n\n# A tibble: 5 × 7\n  species   island    variable        n  mean median    sd\n  &lt;chr&gt;     &lt;chr&gt;     &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie    Biscoe    body_mass_g    44 3710.   3750  488.\n2 Adelie    Dream     body_mass_g    55 3701.   3600  449.\n3 Adelie    Torgersen body_mass_g    47 3709.   3700  452.\n4 Chinstrap Dream     body_mass_g    68 3733.   3700  384.\n5 Gentoo    Biscoe    body_mass_g   119 5092.   5050  501."
  },
  {
    "objectID": "exercises/ex-11.html#normal-distribution",
    "href": "exercises/ex-11.html#normal-distribution",
    "title": "Stats Bootcamp - class 11",
    "section": "Normal distribution",
    "text": "Normal distribution\nThe mean, mode, and median are all equal.\nThe distribution is symmetric about the mean—half the values fall below the mean and half above the mean.\nThe distribution can be described by two values: the mean and the standard deviation."
  },
  {
    "objectID": "exercises/ex-11.html#bell-curve-or-standard-normal",
    "href": "exercises/ex-11.html#bell-curve-or-standard-normal",
    "title": "Stats Bootcamp - class 11",
    "section": "Bell curve or standard normal:",
    "text": "Bell curve or standard normal:\nIs a special normal distribution where the mean is 0 and the standard deviation is 1."
  },
  {
    "objectID": "exercises/ex-11.html#normal-distribution-metrics",
    "href": "exercises/ex-11.html#normal-distribution-metrics",
    "title": "Stats Bootcamp - class 11",
    "section": "Normal distribution metrics",
    "text": "Normal distribution metrics\nSkewness is a measure of the asymmetry around the mean. 0 for bell curve."
  },
  {
    "objectID": "exercises/ex-11.html#normal-distribution-metrics-1",
    "href": "exercises/ex-11.html#normal-distribution-metrics-1",
    "title": "Stats Bootcamp - class 11",
    "section": "Normal distribution metrics",
    "text": "Normal distribution metrics\nKurtosis is a measure of the “flatness” of the distribution."
  },
  {
    "objectID": "exercises/ex-11.html#is-my-data-normally-distributed",
    "href": "exercises/ex-11.html#is-my-data-normally-distributed",
    "title": "Stats Bootcamp - class 11",
    "section": "Is my data normal(ly distributed)?",
    "text": "Is my data normal(ly distributed)?\nLet’s look at the test score distribution again\n\nggplot(data = d,\n       aes(x = n1)) +\n  geom_density() +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#qq-plot",
    "href": "exercises/ex-11.html#qq-plot",
    "title": "Stats Bootcamp - class 11",
    "section": "QQ-plot",
    "text": "QQ-plot\nquantile-quantile plot to compare an empirical distribution to a theoretical distribution.\nQuantile is the fraction (or percent) of points below the given value. For example, the 0.2 (or 20%) quantile is the point at which 20% percent of the data fall below and 80% fall above that value.\n\nggplot(data = d,\n       aes(sample = n1)) +\n  geom_qq() +\n  geom_qq_line() +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#shapiro-wilk-normality-test",
    "href": "exercises/ex-11.html#shapiro-wilk-normality-test",
    "title": "Stats Bootcamp - class 11",
    "section": "Shapiro-Wilk Normality Test",
    "text": "Shapiro-Wilk Normality Test\nShapiro-Wilk test is a hypothesis test that evaluates whether a data set is normally distributed. /\nIt evaluates data from a sample with the null hypothesis that the data set is normally distributed. /\nA large p-value indicates the data set is normally distributed, a low p-value indicates that it isn’t normally distributed.\n\nd |&gt;\n  shapiro_test(n1)"
  },
  {
    "objectID": "exercises/ex-11.html#back-to-penguin-body-mass",
    "href": "exercises/ex-11.html#back-to-penguin-body-mass",
    "title": "Stats Bootcamp - class 11",
    "section": "Back to penguin body mass",
    "text": "Back to penguin body mass\nDistribution\n\nggplot(data = p,\n       aes(x = body_mass_g)) +\n  geom_density() +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#qq-plot-body-mass",
    "href": "exercises/ex-11.html#qq-plot-body-mass",
    "title": "Stats Bootcamp - class 11",
    "section": "QQ-plot body mass",
    "text": "QQ-plot body mass\n\nggplot(data = p,\n       aes(sample = body_mass_g)) +\n  geom_qq() +\n  geom_qq_line() +\n  theme_cowplot()\n\n\n\n\n\n\n\nHmmm…"
  },
  {
    "objectID": "exercises/ex-11.html#shapiro-wilk-body-mass",
    "href": "exercises/ex-11.html#shapiro-wilk-body-mass",
    "title": "Stats Bootcamp - class 11",
    "section": "Shapiro-Wilk body mass",
    "text": "Shapiro-Wilk body mass\n\np |&gt;\n  shapiro_test(??)\n\nThat does not look normal!"
  },
  {
    "objectID": "exercises/ex-11.html#penguin-body-mass-by-species",
    "href": "exercises/ex-11.html#penguin-body-mass-by-species",
    "title": "Stats Bootcamp - class 11",
    "section": "Penguin body mass by species?",
    "text": "Penguin body mass by species?\nDistribution\n\nggplot(data = p,\n       aes(x = body_mass_g, color = species)) +\n  geom_density() +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#qq-plot-body-weight",
    "href": "exercises/ex-11.html#qq-plot-body-weight",
    "title": "Stats Bootcamp - class 11",
    "section": "QQ-plot body weight",
    "text": "QQ-plot body weight\n\nggplot(data = p,\n       aes(sample = body_mass_g, color = species)) +\n  geom_qq() +\n  geom_qq_line() +\n  theme_cowplot()\n\n\n\n\n\n\n\nThat looks better…"
  },
  {
    "objectID": "exercises/ex-11.html#shapiro-wilk-body-weight-by-species",
    "href": "exercises/ex-11.html#shapiro-wilk-body-weight-by-species",
    "title": "Stats Bootcamp - class 11",
    "section": "Shapiro-Wilk body weight by species",
    "text": "Shapiro-Wilk body weight by species\n\np |&gt;\n  group_by(??) |&gt;\n  shapiro_test(??)\n\nOk so Chinstrap and Gentoo look normal. Not sure about Adelie. We may want to consider using non-parametric test to compare mean body weights between Adelie vs Chinstrap or Gentoo."
  },
  {
    "objectID": "exercises/ex-11.html#central-limit-theorem",
    "href": "exercises/ex-11.html#central-limit-theorem",
    "title": "Stats Bootcamp - class 11",
    "section": "Central limit theorem",
    "text": "Central limit theorem\nThe central limit theorem states that if you take sufficiently large samples from a population, the samples’ means will be normally distributed, even if the population isn’t normally distributed.\nBack to coin flips!! 50 flips, one round.\n\nn &lt;- 50\n\n# make a hundred fair and unfair flips\nf &lt;- tibble(fair=rbinom(n = n, size = 1, prob = .5),\n       unfair=rbinom(n = n, size = 1, prob = .2)) |&gt;\n    pivot_longer(cols = c(\"fair\",\"unfair\"), names_to = \"cheating\", values_to = \"flips\")"
  },
  {
    "objectID": "exercises/ex-11.html#flip-distributions",
    "href": "exercises/ex-11.html#flip-distributions",
    "title": "Stats Bootcamp - class 11",
    "section": "flip distributions",
    "text": "flip distributions\nLook at the distribution of fair flips\n\nggplot(data = f |&gt; filter(cheating==\"fair\"),\n       aes(x=flips)\n       ) +\n  geom_histogram() +\n  theme_cowplot()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nLook at the distribution of unfair flips\n\nggplot(data = f |&gt; filter(cheating==\"unfair\"),\n       aes(x=flips)\n       ) +\n  geom_histogram() +\n  theme_cowplot()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "exercises/ex-11.html#now-lets-sample-means",
    "href": "exercises/ex-11.html#now-lets-sample-means",
    "title": "Stats Bootcamp - class 11",
    "section": "Now lets sample means",
    "text": "Now lets sample means\nlet’s do 100 round of 50 flips and take the average of each round.\nremember the size that i told you to ignore last class!\n\nr &lt;- 100\n\nrbinom(n = n, size = r, prob = .5)/r\n\n [1] 0.47 0.44 0.45 0.56 0.63 0.43 0.45 0.42 0.44 0.48 0.42 0.50 0.56 0.51 0.49\n[16] 0.44 0.52 0.46 0.56 0.53 0.43 0.49 0.48 0.49 0.47 0.57 0.47 0.51 0.42 0.51\n[31] 0.53 0.57 0.44 0.45 0.49 0.49 0.53 0.48 0.54 0.55 0.55 0.43 0.54 0.49 0.56\n[46] 0.47 0.48 0.51 0.49 0.47\n\n\n\nfmean &lt;- tibble(\n  fair=rbinom(n = n, size = r, prob = .5)/r,\n  unfair=rbinom(n = n, size = r, prob = .2)/r) |&gt;\n  pivot_longer(cols = c(\"fair\",\"unfair\"),\n               names_to = \"cheating\",\n               values_to = \"flips\"\n               )"
  },
  {
    "objectID": "exercises/ex-11.html#sampled-flip-mean-distributions",
    "href": "exercises/ex-11.html#sampled-flip-mean-distributions",
    "title": "Stats Bootcamp - class 11",
    "section": "sampled flip mean distributions",
    "text": "sampled flip mean distributions\nLook at the distribution of fair flips\n\nggplot(data = fmean |&gt; filter(cheating==\"fair\"),\n       aes(x=flips)\n       ) +\n  geom_density() +\n  geom_vline(xintercept = .5) +\n  xlim(0,1) +\n  theme_cowplot()\n\n\n\n\n\n\n\nLook at the distribution of unfair flips\n\nggplot(data = fmean |&gt; filter(cheating==\"unfair\"),\n       aes(x=flips)\n       ) +\n  geom_density() +\n  geom_vline(xintercept = .2) +\n  xlim(0,1) +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#but-is-it-normal",
    "href": "exercises/ex-11.html#but-is-it-normal",
    "title": "Stats Bootcamp - class 11",
    "section": "but is it normal?",
    "text": "but is it normal?\n\nfmean |&gt;\n  group_by(cheating) |&gt;\n  shapiro_test(flips)\n\n# A tibble: 2 × 4\n  cheating variable statistic     p\n  &lt;chr&gt;    &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n1 fair     flips        0.978 0.490\n2 unfair   flips        0.984 0.715\n\n\nyup!"
  },
  {
    "objectID": "exercises/ex-11.html#what-about-the-mean-sd-with-different-parameters",
    "href": "exercises/ex-11.html#what-about-the-mean-sd-with-different-parameters",
    "title": "Stats Bootcamp - class 11",
    "section": "What about the mean + sd with different parameters?",
    "text": "What about the mean + sd with different parameters?\n10 fair and unfair flips\n20 and 80 times\n\nfair10 &lt;- tibble(\n  r20=rbinom(n = 10, size = 20, prob = .5)/20,\n  r80=rbinom(n = 10, size = 80, prob = .5)/80,\n  type=rep(\"fair10\")\n  )\n\n\nunfair10 &lt;- tibble(\n  r20=rbinom(n = 10, size = 20, prob = .2)/20,\n  r80=rbinom(n = 10, size = 80, prob = .2)/80,\n  type=rep(\"unfair10\")\n  )\n\n\nput it all together\n\nall &lt;- bind_rows(fair10, unfair10) |&gt;\n  pivot_longer(cols = c(\"r20\",\"r80\"),\n             names_to = \"r\",\n             values_to = \"f\"\n             )"
  },
  {
    "objectID": "exercises/ex-11.html#visualize",
    "href": "exercises/ex-11.html#visualize",
    "title": "Stats Bootcamp - class 11",
    "section": "Visualize",
    "text": "Visualize\n\nggplot(all , aes(x=r, y=f, color=r)) +\n  geom_jitter() +\n  stat_summary(fun.y=mean, geom=\"point\", shape=18,\n                 size=3, color=\"black\") +\n  ylim(-0.05,1.05) +\n   facet_grid(~type) +\n  geom_hline(yintercept = .5, linetype = \"dashed\") +\n  geom_hline(yintercept = .2, linetype = \"dashed\") +\n  theme_cowplot()\n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\n\n\n\n\n\n\n. . .\n\nall |&gt;\n  group_by(type,r) |&gt;\n  get_summary_stats(show = c(\"mean\",\"sd\"))\n\n# A tibble: 4 × 6\n  type     r     variable     n  mean    sd\n  &lt;chr&gt;    &lt;chr&gt; &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 fair10   r20   f           10 0.48  0.116\n2 fair10   r80   f           10 0.509 0.082\n3 unfair10 r20   f           10 0.155 0.05 \n4 unfair10 r80   f           10 0.206 0.034"
  },
  {
    "objectID": "exercises/ex-11.html#references",
    "href": "exercises/ex-11.html#references",
    "title": "Stats Bootcamp - class 11",
    "section": "References",
    "text": "References\n\nThe Normal Distribution, Confidence Intervals, and Their Deceptive Simplicity\nCentral limit theorem\nHistograms, Clearly Explained\nThe Main Ideas behind Probability Distributions\nThe Normal Distribution, Clearly Explained!!!\nProbability vs Likelihood"
  },
  {
    "objectID": "exercises/ex-13.html",
    "href": "exercises/ex-13.html",
    "title": "Stats Bootcamp - class 13",
    "section": "",
    "text": "# we are reading the data directly from the internet\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1,6,9,14,15,24:28)]\nbiochem &lt;- biochem[,keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\",\"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename gender to sex\nb &lt;- inner_join(biochem, weight, by=\"subject_name\") |&gt;\n  na.omit() |&gt;\n  rename(sex=gender)"
  },
  {
    "objectID": "exercises/ex-13.html#prepare-mouse-biochem-data",
    "href": "exercises/ex-13.html#prepare-mouse-biochem-data",
    "title": "Stats Bootcamp - class 13",
    "section": "",
    "text": "# we are reading the data directly from the internet\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1,6,9,14,15,24:28)]\nbiochem &lt;- biochem[,keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\",\"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename gender to sex\nb &lt;- inner_join(biochem, weight, by=\"subject_name\") |&gt;\n  na.omit() |&gt;\n  rename(sex=gender)"
  },
  {
    "objectID": "exercises/ex-13.html#association-between-mouse-weight-and-tot_cholesterol",
    "href": "exercises/ex-13.html#association-between-mouse-weight-and-tot_cholesterol",
    "title": "Stats Bootcamp - class 13",
    "section": "Association between mouse \\(weight\\) and \\(tot\\_cholesterol\\)\n",
    "text": "Association between mouse \\(weight\\) and \\(tot\\_cholesterol\\)\n\n\nggscatter()\n\nwe previously established these are normal enough &gt; \\(\\mathcal{H}_0\\) is no (linear) relationship between \\(tot\\_cholesterol\\) and \\(weight\\)\n\n\nb |&gt;\n  cor_test(??, ??,\n           method = \"??\"\n           )\n\nP value well below 0.05\n\n\\(\\mathcal{H}_0\\) is no relationship between \\(tot\\_cholesterol\\) and \\(weight\\) NOT WELL SUPPORTED\n\nSo there is a (linear) relationship between \\(tot\\_cholesterol\\) and \\(weight\\)"
  },
  {
    "objectID": "exercises/ex-13.html#visualize-pearson-correlation",
    "href": "exercises/ex-13.html#visualize-pearson-correlation",
    "title": "Stats Bootcamp - class 13",
    "section": "Visualize Pearson correlation",
    "text": "Visualize Pearson correlation\n\nggscatter(data = b,\n          y = \"weight\",\n          x = \"tot_cholesterol\"\n          ) +\n  stat_cor(method = \"pearson\",\n           label.x = 1,\n           label.y = 30)"
  },
  {
    "objectID": "exercises/ex-13.html#manual-calculation-of-pearson-correlation",
    "href": "exercises/ex-13.html#manual-calculation-of-pearson-correlation",
    "title": "Stats Bootcamp - class 13",
    "section": "Manual calculation of Pearson correlation",
    "text": "Manual calculation of Pearson correlation\n\\(Corr(x,y) = \\displaystyle \\frac {\\sum_{i=1}^{n} (x_{i} - \\overline{x})(y_{i} - \\overline{y})}{\\sum_{i=1}^{n} \\sqrt(x_{i} - \\overline{x})^2 \\sqrt(y_{i} - \\overline{y})^2}\\)\n\n# mean total cholesterol\nm_chol &lt;-\n\n# average weight\nm_weight &lt;-\n\n# difference from mean total cholesterol\ndiff_chol &lt;-\n\n# difference from mean total weight\ndiff_weight &lt;-\n\n# follow formula above\nmanual_pearson &lt;-\n\nmanual_pearson"
  },
  {
    "objectID": "exercises/ex-13.html#spearman-correlation-nonparametric",
    "href": "exercises/ex-13.html#spearman-correlation-nonparametric",
    "title": "Stats Bootcamp - class 13",
    "section": "Spearman Correlation (nonparametric)",
    "text": "Spearman Correlation (nonparametric)\nSpearman’s rank correlation coefficientor Spearman’s ρ, named after Charles Spearman is a nonparametric measure of rank correlation (statistical dependence between the rankings of two variables). It assesses how well the relationship between two variables can be described using a monotonic function.\nMore info here.\n\nb |&gt;\n  cor_test(weight, tot_cholesterol,\n           method = \"??\"\n           )\n\nP value well below 0.05\n\n\\(\\mathcal{H}_0\\) is no relationship between \\(tot\\_cholesterol\\) and \\(weight\\) NOT WELL SUPPORTED"
  },
  {
    "objectID": "exercises/ex-13.html#visualize-spearman-correlation",
    "href": "exercises/ex-13.html#visualize-spearman-correlation",
    "title": "Stats Bootcamp - class 13",
    "section": "Visualize Spearman correlation",
    "text": "Visualize Spearman correlation\n\nggscatter(data = b,\n          y = \"weight\",\n          x = \"tot_cholesterol\"\n          ) +\n  stat_cor(method = \"spearman\",\n           label.x = 1,\n           label.y = 30)"
  },
  {
    "objectID": "exercises/ex-13.html#lets-create-a-hypothetical-example",
    "href": "exercises/ex-13.html#lets-create-a-hypothetical-example",
    "title": "Stats Bootcamp - class 13",
    "section": "Let’s create a hypothetical example",
    "text": "Let’s create a hypothetical example\ncreate tibble \\(d\\) with variables \\(x\\) and \\(y\\)\n\\(x\\), 1:50\n\\(y\\), which is \\(x^{10}\\)\n\nd &lt;- tibble(\n  x=??,\n  y=??)\n\n. . .\nscatter plot\n\nggscatter(data = d,\n          x = \"x\",\n          y = \"y\")\n\n\nPearson\n\nd |&gt;\n  cor_test(x, y,\n           method = \"pearson\"\n           ) |&gt;\n  select(cor)\n\n. . .\nSpearman\n\nd |&gt;\n  cor_test(x, y,\n           method = \"spearman\"\n           ) |&gt;\n  select(cor)"
  },
  {
    "objectID": "exercises/ex-13.html#additional-examples-with-correlation",
    "href": "exercises/ex-13.html#additional-examples-with-correlation",
    "title": "Stats Bootcamp - class 13",
    "section": "Additional examples with correlation",
    "text": "Additional examples with correlation\ncompare 1 variable to all other quantitative variables\n\\(weight\\)\n\nb |&gt;\n  cor_test(??) |&gt;\n  gt()\n\nrelationship between \\(weight\\) and \\(tot\\_cholesterol\\) by \\(sex\\)\n\nb |&gt;\n\n  gt()"
  },
  {
    "objectID": "exercises/ex-13.html#appropriate-statistical-test-cheatsheet",
    "href": "exercises/ex-13.html#appropriate-statistical-test-cheatsheet",
    "title": "Stats Bootcamp - class 13",
    "section": "Appropriate statistical test cheatsheet",
    "text": "Appropriate statistical test cheatsheet"
  },
  {
    "objectID": "exercises/ex-13.html#regression",
    "href": "exercises/ex-13.html#regression",
    "title": "Stats Bootcamp - class 13",
    "section": "Regression",
    "text": "Regression\nWe are going to change our frame work to learn about regression. The nice thing is that everything we learn for regression is applicable to all the tests we just learned."
  },
  {
    "objectID": "exercises/ex-13.html#the-simplicity-underlying-common-tests",
    "href": "exercises/ex-13.html#the-simplicity-underlying-common-tests",
    "title": "Stats Bootcamp - class 13",
    "section": "The simplicity underlying common tests",
    "text": "The simplicity underlying common tests\nMost of the common statistical models (t-test, correlation, ANOVA; etc.) are special cases of linear models or a very close approximation. This simplicity means that there is less to learn. It all comes down to:\n\n\\(y = a \\cdot x + b\\)\n\nThis needless complexity multiplies when students try to rote learn the parametric assumptions underlying each test separately rather than deducing them from the linear model."
  },
  {
    "objectID": "exercises/ex-13.html#equation-for-a-line",
    "href": "exercises/ex-13.html#equation-for-a-line",
    "title": "Stats Bootcamp - class 13",
    "section": "Equation for a line",
    "text": "Equation for a line\nRemember:\\(y = a \\cdot x + b\\)\nOR\\(y = b + a \\cdot x\\)\n\\(a\\) is the SLOPE (2) \\(b\\) is the y-intercept (1)\n\nd &lt;- tibble(x=c(-1,3),\n            y=c(-1,6)\n             )\n\nggplot(data=d, aes(x=x,y=y)) +\n  geom_blank() +\n  geom_abline(intercept = 1,\n              slope = 2,\n              col = \"red\") +\n  theme_linedraw()"
  },
  {
    "objectID": "exercises/ex-13.html#stats-equation-for-a-line",
    "href": "exercises/ex-13.html#stats-equation-for-a-line",
    "title": "Stats Bootcamp - class 13",
    "section": "Stats equation for a line",
    "text": "Stats equation for a line\nModel:\n\\(y\\) equals the intercept (\\(\\beta_0\\)) pluss a slope (\\(\\beta_1\\)) times \\(x\\).\n\\(y = \\beta_0 + \\beta_1 x \\qquad \\qquad \\mathcal{H}_0: \\beta_1 = 0\\)\n… which is the same as \\(y = b + a \\cdot x\\).\nThe short hand for this in R: y ~ 1 + x\nR interprets this as:\ny = 1*number + x*othernumber\nThe task of t-tests, lm, etc., is simply to find the numbers that best predict \\(y\\)."
  },
  {
    "objectID": "exercises/ex-13.html#stats-equation-for-a-line-1",
    "href": "exercises/ex-13.html#stats-equation-for-a-line-1",
    "title": "Stats Bootcamp - class 13",
    "section": "Stats equation for a line",
    "text": "Stats equation for a line\nAll you need is an intercept (\\(\\beta_0\\)) and a slope (\\(\\beta_1\\)) to get a line:\n\nggplot(data=d, aes(x=x,y=y)) +\n  geom_blank() +\n  geom_abline(intercept = 1,\n              slope = 2,\n              col = \"red\") +\n  theme_linedraw()\n\n\n\n\n\n\n\n\\(\\beta_0\\) = 1 (the y-intercept), \\(\\beta_1\\) = 2 (the slope)\n\\(y = \\beta_0 \\cdot 1 + \\beta_1 \\cdot x\\)\n\\(y = 1 \\cdot 1 + 2 \\cdot x\\)\n\\(y = 1 + 2x\\)\n\nOur mission: FIND THE BEST \\(\\beta\\) coefficients"
  },
  {
    "objectID": "exercises/ex-13.html#linear-regression",
    "href": "exercises/ex-13.html#linear-regression",
    "title": "Stats Bootcamp - class 13",
    "section": "Linear Regression",
    "text": "Linear Regression\n\nSTEP 1: Make a scatter plot visualize the linear relationship between x and y.\nSTEP 2: Perform the regression\nSTEP 3: Look at the \\(R^2\\), \\(F\\)-value and \\(p\\)-value\nSTEP 4: Visualize fit and errors\nSTEP 5: Calculate \\(R^2\\), \\(F\\)-value and \\(p\\)-value ourselves"
  },
  {
    "objectID": "exercises/ex-13.html#step-1-can-mouse-cholesterol-levels-explain-mouse-weight",
    "href": "exercises/ex-13.html#step-1-can-mouse-cholesterol-levels-explain-mouse-weight",
    "title": "Stats Bootcamp - class 13",
    "section": "STEP 1: Can mouse cholesterol levels explain mouse weight?",
    "text": "STEP 1: Can mouse cholesterol levels explain mouse weight?\nPlot \\(weight\\) (y, response variable) and \\(tot_cholesterol\\) (x, explanatory variable)\n\nggplot(data = ??,\n       aes(y = ??,\n           x = ??)) +\n  geom_point(size=.5) +\n  scale_color_manual() +\n  theme_linedraw()"
  },
  {
    "objectID": "exercises/ex-13.html#step-2-do-the-regression",
    "href": "exercises/ex-13.html#step-2-do-the-regression",
    "title": "Stats Bootcamp - class 13",
    "section": "STEP 2: Do the regression",
    "text": "STEP 2: Do the regression\nKeep calm and fit a line! Remember: \\(y = \\beta_0 \\cdot 1+ \\beta_1 \\cdot x\\)\nlinear model equation: \\(weight = \\beta_0 \\cdot 1 + \\beta_1 \\cdot tot\\_cholesterol\\)\n\n\\(\\mathcal{H}_0:\\) \\(tot\\_cholesterol\\) does NOT explain \\(weight\\) Null Hypothesis: \\(\\mathcal{H}_0: \\beta_1 = 0\\)\n\n\\(weight = \\beta_0 \\cdot 1 + 0 \\cdot tot\\_cholesterol\\) \\(weight = \\beta_0 \\cdot 1\\)\n\n\\(\\mathcal{H}_1:\\) Mouse \\(tot\\_cholesterol\\) does explain \\(weight\\)\n\n\\(weight = \\beta_0 \\cdot 1 + \\beta_1 \\cdot tot\\_cholesterol\\)\nThe cool thing here is that we can assess and compare our null and alternative hypothesis by learning and examining the model coefficients (namely the slope). Ultimately, we are comparing a complex model (with cholesterol) to a simple model (without cholesterol).\nhttps://statisticsbyjim.com/regression/interpret-constant-y-intercept-regression/"
  },
  {
    "objectID": "exercises/ex-13.html#step-4-look-at-the-r2-f-value-and-p-value",
    "href": "exercises/ex-13.html#step-4-look-at-the-r2-f-value-and-p-value",
    "title": "Stats Bootcamp - class 13",
    "section": "STEP 4: Look at the \\(R^2\\), \\(F\\)-value and \\(p\\)-value",
    "text": "STEP 4: Look at the \\(R^2\\), \\(F\\)-value and \\(p\\)-value\n\n# fitting a line\nfit_WvC &lt;- lm(\n  data = ??,\n  formula = ??)\n\n\n# base R summary of fit\nsummary(fit_WvC)\n\nThat’s a lot of info, but how would I access it? Time to meet your new best friend:\nBroom"
  },
  {
    "objectID": "exercises/ex-13.html#tidying-output",
    "href": "exercises/ex-13.html#tidying-output",
    "title": "Stats Bootcamp - class 13",
    "section": "Tidying output",
    "text": "Tidying output\ninformation about the model fit\n\n??(fit_WvC) |&gt;\n  gt() |&gt;\n  fmt_number(columns = r.squared:statistic, decimals = 3)\n\ninformation about the intercept and coefficients\n\n??(fit_WvC)|&gt;\n  gt() |&gt;\n  fmt_number(columns =estimate:statistic, decimals = 3)\n\nsave the intercept and slope into variable to use later\n\nchol_intercept &lt;-\n\nchol_slope &lt;-\n\n\n\nfor every 1 unit increase in cholesterol there is a 1.85 unit increase weight\n\n\nggplot(data = b,\n       aes(y = weight,\n           x = tot_cholesterol)) +\n  geom_smooth(method = \"lm\") +\n  geom_point(size=.5) +\n  scale_color_manual() +\n  theme_linedraw()\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "exercises/ex-13.html#collecting-residuals-and-other-information",
    "href": "exercises/ex-13.html#collecting-residuals-and-other-information",
    "title": "Stats Bootcamp - class 13",
    "section": "Collecting residuals and other information",
    "text": "Collecting residuals and other information\nadd residuals and other information\n\nb_WvC &lt;- ??(fit_WvC, data = b)\n\nb_WvC"
  },
  {
    "objectID": "exercises/ex-13.html#what-are-residuals",
    "href": "exercises/ex-13.html#what-are-residuals",
    "title": "Stats Bootcamp - class 13",
    "section": "What are Residuals\n",
    "text": "What are Residuals\n\nResiduals, \\(e\\) — the difference between the observed value of the response variable \\(y\\) and the explanatory value \\(\\widehat{y}\\) is called the residual. Each data point has one residual. Specifically, it is the distance on the y-axis between the observed \\(y_{i}\\) and the fit line.\n\\(e = y_{i} - \\widehat{y}\\)\nResiduals with large absolute values indicate the data point is NOT well explained by the model."
  },
  {
    "objectID": "exercises/ex-13.html#step-5-visualize-fit-and-errors",
    "href": "exercises/ex-13.html#step-5-visualize-fit-and-errors",
    "title": "Stats Bootcamp - class 13",
    "section": "STEP 5: Visualize fit and errors",
    "text": "STEP 5: Visualize fit and errors\nVisualize the residuals OR the error around the fit\n\nggplot(data = b_WvC,\n       aes(x = tot_cholesterol, y = weight)) +\n  geom_point(size=1, aes(color = .resid)) +\n  geom_abline(intercept = pull(chol_intercept),\n              slope = pull(chol_slope),\n              col = \"red\") +\n  scale_color_gradient2(low = \"blue\",\n                        mid = \"black\",\n                        high = \"yellow\") +\n  geom_segment(aes(xend = tot_cholesterol,\n                   yend = .fitted),\n               alpha = .1) + # plot line representing residuals\n  theme_linedraw()\n\n\nVisualize the total error OR the error around the null. So no cholesterol fit, just the mean of y.\n\navg_weight &lt;- mean(b_WvC$weight)"
  },
  {
    "objectID": "exercises/ex-13.html#step-6-calculate-r2-f-value-p-value-ourselves",
    "href": "exercises/ex-13.html#step-6-calculate-r2-f-value-p-value-ourselves",
    "title": "Stats Bootcamp - class 13",
    "section": "STEP 6: Calculate \\(R^2\\), \\(F\\)-value, \\(p\\)-value ourselves",
    "text": "STEP 6: Calculate \\(R^2\\), \\(F\\)-value, \\(p\\)-value ourselves"
  },
  {
    "objectID": "exercises/ex-13.html#what-is-r2",
    "href": "exercises/ex-13.html#what-is-r2",
    "title": "Stats Bootcamp - class 13",
    "section": "What is \\(R^2\\)\n",
    "text": "What is \\(R^2\\)\n\n\\(R^2\\) — the coefficient of determination, which is the proportion of the variance in the response variable that is predictable from the explanatory variable(s).\n\\(R^2 = 1 - \\displaystyle \\frac {SS_{fit}}{SS_{null}}\\)\n\\(SS_{fit}\\) — sum of squared errors around the least-squares fit\n\\(SS_{fit} = \\sum_{i=1}^{n} (data - line)^2 = \\sum_{i=1}^{n} (y_{i} - (\\beta_0 \\cdot 1+ \\beta_1 \\cdot x)^2\\)\n\\(SS_{null}\\) — sum of squared errors around the mean of \\(y\\)\n\\(SS_{null} = \\sum_{i=1}^{n} (data - mean)^2 = \\sum_{i=1}^{n} (y_{i} - \\overline{y})^2\\)"
  },
  {
    "objectID": "exercises/ex-13.html#calculate-r2",
    "href": "exercises/ex-13.html#calculate-r2",
    "title": "Stats Bootcamp - class 13",
    "section": "Calculate \\(R^2\\)\n",
    "text": "Calculate \\(R^2\\)\n\n\\(SS_{fit}\\) — sum of squared errors around the least-squares fit\n\nss_fit &lt;- ??\nss_fit\n\n\\(SS_{null}\\) — sum of squared errors around the mean of \\(y\\)\n\nss_null &lt;- ??\nss_null\n\n\\(R^2 = 1 - \\displaystyle \\frac {SS_{fit}}{SS_{null}}\\)\n\nrsq &lt;- 1- ??\n\nglance(fit_WvC) |&gt; select(r.squared)\n\n. . .\nBTW this is the same \\(R\\) as from the Pearson correlation, just squared:\n\nb |&gt;\n  cor_test(weight,tot_cholesterol,\n           method = \"pearson\") |&gt;\n  mutate(r2 = cor^2) |&gt;\n  pull(r2) |&gt;\n  round(2)"
  },
  {
    "objectID": "exercises/ex-13.html#interpret-r2",
    "href": "exercises/ex-13.html#interpret-r2",
    "title": "Stats Bootcamp - class 13",
    "section": "Interpret \\(R^2\\)\n",
    "text": "Interpret \\(R^2\\)\n\nThere is a 13 % reduction in the variance when we take mouse \\(cholesterol\\) into account\nOR\\(cholesterol\\) explains 13% of variation in mouse \\(weight\\)"
  },
  {
    "objectID": "exercises/ex-13.html#what-is-the-f-statistic",
    "href": "exercises/ex-13.html#what-is-the-f-statistic",
    "title": "Stats Bootcamp - class 13",
    "section": "What is the F-statistic\n",
    "text": "What is the F-statistic\n\nF-statistic — based on the ratio of two variances: the explained variance (due to the model) and the unexplained variance (residuals).\n\\(F = \\displaystyle \\frac{SS_{fit}/(p_{fit}-p_{null})} {SS_{null}/(n-p_{fit})}\\)\n\\(p_{fit}\\) — number of parameters (coefficients) in the fit line\n\\(p_{null}\\) — number of parameters (coefficients) in the mean line\n\\(n\\) — number of data points"
  },
  {
    "objectID": "exercises/ex-13.html#calculate-the-f-statistic",
    "href": "exercises/ex-13.html#calculate-the-f-statistic",
    "title": "Stats Bootcamp - class 13",
    "section": "Calculate the F-statistic\n",
    "text": "Calculate the F-statistic\n\n\\(F = \\displaystyle \\frac{SS_{null} - SS_{fit}/(p_{fit}-p_{null})} {SS_{fit}/(n-p_{fit})}\\)\n\npfit &lt;- ??\npnull &lt;- ??\nn &lt;- ??\n\nf &lt;- ??\n\n\nf\n\nglance(fit_WvC) |&gt; select(statistic)"
  },
  {
    "objectID": "exercises/ex-13.html#p-values",
    "href": "exercises/ex-13.html#p-values",
    "title": "Stats Bootcamp - class 13",
    "section": "P-values",
    "text": "P-values\nYou don’t really need to know what the \\(F-statistic\\) is unless you want to calculate the p-value. In this case we need to generate a null distribution of \\(F-statistic\\) values to compare to our observed \\(F-statistic\\).\nTherefore, we will randomize the \\(tot_cholesterol\\) and \\(weight\\) and then calculate the \\(F-statistic\\).\n\n\nWe will do this many many times to generate a null distribution of \\(F-statistic\\)s.\n\nThe p-value will be the probability of obtaining an \\(F-statistic\\) in the null distribution at least as extreme as our observed \\(F-statistic\\)."
  },
  {
    "objectID": "exercises/ex-13.html#lets-get-started",
    "href": "exercises/ex-13.html#lets-get-started",
    "title": "Stats Bootcamp - class 13",
    "section": "Let’s get started",
    "text": "Let’s get started\n\n# set up an empty tibble to hold our null distribution\nfake_biochem &lt;- tribble()\n\n# we will perform 100 permutations\nmyPerms &lt;- 100\n\nfor (i in 1:myPerms) {\n  tmp &lt;- bind_cols(\n    b_WvC[sample(nrow(b_WvC)), \"weight\"],\n    b_WvC[sample(nrow(b_WvC)),\"tot_cholesterol\"],\n    \"perm\"=factor(rep(i,nrow(b_WvC)))\n    )\n\n  fake_biochem &lt;- bind_rows(fake_biochem,tmp)\n  rm(tmp)\n\n}\n\n\n# let's look at permutations 1 and 2\nggplot(fake_biochem |&gt; filter(perm %in% c(1:2)), aes(x=weight, y=tot_cholesterol, color=perm)) +\n  geom_point(size=.1) +\n  theme_minimal()"
  },
  {
    "objectID": "exercises/ex-13.html#run-100-linear-models",
    "href": "exercises/ex-13.html#run-100-linear-models",
    "title": "Stats Bootcamp - class 13",
    "section": "Run 100 linear models!",
    "text": "Run 100 linear models!\nNow we will calculate and extract linear model results for each permutation individually using nest, mutate, and map functions\n\nfake_biochem_lms &lt;- fake_biochem |&gt;\n  nest(data = -perm) |&gt;\n  mutate(\n    fit = map(data, ~ lm(weight ~ tot_cholesterol, data = .x)),\n    glanced = map(fit, glance)\n  ) |&gt;\n  unnest(glanced)"
  },
  {
    "objectID": "exercises/ex-13.html#visualize-the-null",
    "href": "exercises/ex-13.html#visualize-the-null",
    "title": "Stats Bootcamp - class 13",
    "section": "Visualize the null",
    "text": "Visualize the null\nLet’s take a look at the null distribution of F-statistics from the randomized values\n\nggplot(fake_biochem_lms,\n       aes(x = statistic)) +\ngeom_density(color=\"red\") +\ntheme_minimal()\n\n\nremember that the \\(F-statistic\\) we observed was 255!\n\nggplot(fake_biochem_lms, aes(x = statistic)) +\nxlim(0,f*1.1) +\ngeom_density(color=\"red\") +\ngeom_vline(xintercept = f, color = \"blue\") +\n#  scale_x_log10() +\ntheme_minimal()\n\nIn our 100 randoized simulations, we never see an F-statistic as extreme as the one we observed in the actual data. Therefore:\n\nP &lt; 0.01 or 1/100\n\nReminder, our calculate P value was:"
  },
  {
    "objectID": "exercises/ex-13.html#how-to-find-the-best-least-squares-fit",
    "href": "exercises/ex-13.html#how-to-find-the-best-least-squares-fit",
    "title": "Stats Bootcamp - class 13",
    "section": "How to find the best (least squares) fit?",
    "text": "How to find the best (least squares) fit?\n\nRotate the line of fit\n\nFind the fit that minimizes the Sum of Squared Residuals or \\(SS_{fit}\\)\n\nThis is the derivative (slope of tangent at best point = 0) of the function describing the \\(SS_{fit}\\) and the next rotation is 0."
  },
  {
    "objectID": "exercises/ex-13.html#references",
    "href": "exercises/ex-13.html#references",
    "title": "Stats Bootcamp - class 13",
    "section": "References",
    "text": "References\nDifferences between correlation and regression\nalso more differences between correlation and regression.\nCommon statistical tests are linear models from Jonas Lindeløv\nStatquest\nStats gobbledygook\nLinear Regression Assumptions and Diagnostics in R: Essentials\nPRINCIPLES OF STATISTICS from GraphPad/SAS.\nStatquest: how to go from F-statistic to p-value\nStatQuest: Fitting a line to data, aka least squares, aka linear regression.\nStatQuest: Gradient Descent, Step-by-Step"
  },
  {
    "objectID": "exercises/ex-15.html",
    "href": "exercises/ex-15.html",
    "title": "Stats Bootcamp - class 15",
    "section": "",
    "text": "Types of error and multiple test corrections\nExploratory data analysis\nClustering and overlaps"
  },
  {
    "objectID": "exercises/ex-15.html#learning-objectives",
    "href": "exercises/ex-15.html#learning-objectives",
    "title": "Stats Bootcamp - class 15",
    "section": "",
    "text": "Types of error and multiple test corrections\nExploratory data analysis\nClustering and overlaps"
  },
  {
    "objectID": "exercises/ex-15.html#types-i-and-ii-error",
    "href": "exercises/ex-15.html#types-i-and-ii-error",
    "title": "Stats Bootcamp - class 15",
    "section": "Types I and II error",
    "text": "Types I and II error\nFalse positives and False negatives\n\n\\(\\alpha\\) - significance level OR evidentiary standard\n\\(\\beta\\) - type II error rate, 1 - \\(\\beta\\) is power"
  },
  {
    "objectID": "exercises/ex-15.html#different-visualization",
    "href": "exercises/ex-15.html#different-visualization",
    "title": "Stats Bootcamp - class 15",
    "section": "Different visualization",
    "text": "Different visualization\nPower vs Significance"
  },
  {
    "objectID": "exercises/ex-15.html#genomics---lots-of-data---lots-of-hypothesis-tests",
    "href": "exercises/ex-15.html#genomics---lots-of-data---lots-of-hypothesis-tests",
    "title": "Stats Bootcamp - class 15",
    "section": "Genomics -> Lots of Data -> Lots of Hypothesis Tests",
    "text": "Genomics -&gt; Lots of Data -&gt; Lots of Hypothesis Tests\nIn a typical RNA-seq experiment, we test ~10K different hypotheses. For example, you have 10K genes and for each gene you test whether the mean expression changed in condition A vs condition B. Using a standard p-value cut-off of 0.05, we’d expect 500 genes to be deemed “significant” by chance. Thus, we are very concerned about False Positives or Type I Errors."
  },
  {
    "objectID": "exercises/ex-15.html#multiple-test-corrections",
    "href": "exercises/ex-15.html#multiple-test-corrections",
    "title": "Stats Bootcamp - class 15",
    "section": "Multiple test corrections",
    "text": "Multiple test corrections\n\nControl overall α (also known as family-wise error rate or FWER), which will affect the α* for each test. That is, we are controlling the overall probability of making at least one false discovery. Bonferroni and Sidak corrections all control FWER.\nControl false discovery rate (FDR). These procedures allow for type 1 errors (false positives) but control the proportion of these false positives in relation to true positives. This is done by adjusting the decision made for the p-value associated with each individual test to decide rejection or not. Because this will result in a higher type 1 error rate, it has higher power. This affords a higher probability of true discoveries. The step procedures control for FDR."
  },
  {
    "objectID": "exercises/ex-15.html#bonferroni-correction",
    "href": "exercises/ex-15.html#bonferroni-correction",
    "title": "Stats Bootcamp - class 15",
    "section": "Bonferroni Correction",
    "text": "Bonferroni Correction\nThe most conservative of corrections, the Bonferroni correction is also perhaps the most straightforward in its approach. Simply divide α by the number of tests (m).\n\nα = α/m\n\nHowever, with many tests, α will become very small. This reduces power, which means that we are very unlikely to make any true discoveries.\nSidak Correction\n\nα = 1-(1-α)^(1/m)"
  },
  {
    "objectID": "exercises/ex-15.html#holms-step-down-procedure",
    "href": "exercises/ex-15.html#holms-step-down-procedure",
    "title": "Stats Bootcamp - class 15",
    "section": "Holm’s Step-Down Procedure",
    "text": "Holm’s Step-Down Procedure\nThe Holm-Bonferroni method is also fairly simple to calculate, but it is more powerful than the single-step Bonferroni.\n\\(HB = \\displaystyle \\frac {target \\alpha}{n - rank + 1}\\)\nH1: 0.005\nH2: 0.01\nH3: 0.03\nH4: = 0.04\nStep 1: Order the p-values from smallest to greatest (already done)\nStep 2: Calc HB for the first rank HB = .05 / 4 – 1 + 1 = .05 / 4 = .0125 H1: 0.005 &lt; .0125, so we reject the null\nStep 4: Repeat the HB formula for the second rank and keep going until we find \\(H{_N}\\) &gt; \\(HB{_N}\\). All subsequent hypotheses are non-significant (i.e. not rejected)."
  },
  {
    "objectID": "exercises/ex-15.html#hochbergs-step-up-procedure",
    "href": "exercises/ex-15.html#hochbergs-step-up-procedure",
    "title": "Stats Bootcamp - class 15",
    "section": "Hochberg’s Step-Up Procedure",
    "text": "Hochberg’s Step-Up Procedure\nMore powerful than Holm’s step-down procedure, Hochberg’s step-up procedure also seeks to control the FDR and follows a similar process, only p-values are ranked from largest to smallest.\nFor each ranked p-value, it is compared to the α calculated for its respective rank (same formula as Holm’s procedure). Testing continues until you reach the first non-rejected hypothesis. You would then fail to reject all following hypotheses."
  },
  {
    "objectID": "exercises/ex-15.html#example",
    "href": "exercises/ex-15.html#example",
    "title": "Stats Bootcamp - class 15",
    "section": "Example",
    "text": "Example\n\nrna &lt;- read_csv(here(\"data/data_rna_protein.csv.gz\")) |&gt;select(iDUX4_pval)\n\n\nrna$fdr &lt;- p.adjust(p = ??, method = \"fdr\", n = nrow(rna))\n\nrna$BH &lt;- p.adjust(p = rna$iDUX4_pval, method = \"BH\", n = nrow(rna))\n\nrna$bon &lt;- p.adjust(p = rna$iDUX4_pval, method = \"bonferroni\", n = nrow(rna))\n\n\nrna_long &lt;- rna |&gt;pivot_longer(cols = iDUX4_pval:bon, names_to = \"type\")\n\n\n\nggplot(data = rna_long, aes(x=value, fill = type)) +\n  geom_histogram(bins = 50) +\n  facet_wrap(~type) +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-15.html#exploratory-data-analysis-eda",
    "href": "exercises/ex-15.html#exploratory-data-analysis-eda",
    "title": "Stats Bootcamp - class 15",
    "section": "Exploratory data analysis (EDA)",
    "text": "Exploratory data analysis (EDA)\nOur goal here is to get an top-down big picture of the similarity/differences between variables in a dataset. For example, let’s say you do RNA-seq in triplicate on 4 treatment/developmental times.\nPCA\nWe will perform PCA on all of the samples and visualize the relationship between samples.\nCorrelation matrix\nWe will perform hierarchical clustering on a matrix representing the pairwise correlation between all these samples."
  },
  {
    "objectID": "exercises/ex-15.html#explore-data",
    "href": "exercises/ex-15.html#explore-data",
    "title": "Stats Bootcamp - class 15",
    "section": "Explore data",
    "text": "Explore data\nIs it normal-ish?\n\n# get dux targets\ndux_targets &lt;- read_csv(file = here(\"data\",\"target_genes.csv.gz\"))\n\n# get expression data\nd &lt;- read_tsv(here(\"data\",\"data_genelevel.tsv.gz\")) |&gt;\n  mutate(target = case_when(\n    gene_symbol %in% dux_targets$hgnc_symbol ~ \"target\",\n    TRUE ~ \"not_target\")\n         ) |&gt;\n  filter(gene_symbol!=\"ISCA1\") |&gt;\n  drop_na()\n\n\nd |&gt;\n  pivot_longer(cols = hour00_rep1:hour14_rep3) |&gt;\n  ggplot(aes(x=value, color=name)) +\n  ??() +\n  theme_cowplot()\n\n. . .\nDefinitely not normal"
  },
  {
    "objectID": "exercises/ex-15.html#data-transformations",
    "href": "exercises/ex-15.html#data-transformations",
    "title": "Stats Bootcamp - class 15",
    "section": "Data transformations",
    "text": "Data transformations\nWe often transform data to make it closer to being normally-distributed. This allows us to use more powerful statistical tests on the same data. One approach is to log-transform the data.\n\nd |&gt;\n  pivot_longer(cols = hour00_rep1:hour14_rep3) |&gt;\n  ggplot(aes(x=??(value), color=name)) +\n  geom_density() +\n  theme_cowplot()\n\n. . .\nWhat is this?\n\nWarning message: Removed 1251 rows containing non-finite values (stat_density())."
  },
  {
    "objectID": "exercises/ex-15.html#pseudocounts",
    "href": "exercises/ex-15.html#pseudocounts",
    "title": "Stats Bootcamp - class 15",
    "section": "Pseudocounts",
    "text": "Pseudocounts\n\\(log_{x}(0)\\) is a common problem. One solution is to add a pseudocount. Since this is read count data, the smallest unit is 1 and so we will add 1 to all the observations before perforing the log transformation. \\(1\\) represents the pseudocount in this case.\n\nd |&gt;\n  pivot_longer(cols = hour00_rep1:hour14_rep3) |&gt;\n  ggplot(aes(x=??(value), color=name)) +\n  geom_density() +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-15.html#correlation-analysis",
    "href": "exercises/ex-15.html#correlation-analysis",
    "title": "Stats Bootcamp - class 15",
    "section": "correlation analysis",
    "text": "correlation analysis\nprepare the data for analysis\n\n# pull counts\nx &lt;-  d |&gt;\n  select_if(is.numeric) |&gt;# keep only the numeric columns\n  mutate_all(funs(log2(1 + .))) |&gt;# log2 transform\n  as.matrix() # matrix\n\nrownames(x) &lt;- d$gene_symbol\n\nx &lt;- t(scale(t(x))) # scale\n\n# pairwise pearson correlation\np &lt;- ???\n\n# heatmap\npheatmap(\n  mat = p,\n  clustering_distance_rows = \"??\",\n  clustering_distance_cols = \"??\",\n  clustering_method = \"??\"\n)"
  },
  {
    "objectID": "exercises/ex-15.html#pca-1",
    "href": "exercises/ex-15.html#pca-1",
    "title": "Stats Bootcamp - class 15",
    "section": "PCA",
    "text": "PCA\nPCA is a common dimensionality reduction method that is used to visualize the similarity and differences in your data.\nLet’s watch this fantastic 5 minute video explaining PCA\n\nFor more detailed explanations go here and here."
  },
  {
    "objectID": "exercises/ex-15.html#pca-2",
    "href": "exercises/ex-15.html#pca-2",
    "title": "Stats Bootcamp - class 15",
    "section": "PCA",
    "text": "PCA\n\n# pairwise pearson correlation\npc &lt;-\n\nsummary(pc) # summarize the PCs by variance"
  },
  {
    "objectID": "exercises/ex-15.html#pca---prepare-visualization",
    "href": "exercises/ex-15.html#pca---prepare-visualization",
    "title": "Stats Bootcamp - class 15",
    "section": "PCA - prepare visualization",
    "text": "PCA - prepare visualization\n\n# create a dataframe with the importance/explanation of variation for each PC\npca_data_info &lt;- summary(pc)$importance |&gt; as.data.frame()\n\npca_data_info &lt;- round(x = pca_data_info, digits = 3)\n\n# we make a dataframe out of the rotations and will use this to plot\npca_plot_data &lt;- pc$rotation |&gt;\n  as.data.frame() |&gt;\n  rownames_to_column(var = \"ID\") |&gt;\n  separate(\n    ID,\n    into = c(\"time\",\"rep\"),\n    sep = \"_\"\n  )\n\n# recode \"rep\"\npca_plot_data$rep &lt;- recode(\n  pca_plot_data$rep,\n  rep1 = \"A\",\n  rep2 = \"B\",\n  rep3 = \"C\"\n)\n\n# gsub hour\npca_plot_data$time &lt;- gsub(\n  pattern = \"hour\",\n  replacement = \"\",\n  x = pca_plot_data$time\n)\n\nggplot(\n  pca_plot_data,\n  aes(x=PC1, y = PC2, color=time)\n  ) +\n  geom_point() +\n  xlab(paste(\"PC1, %\",100 * pca_data_info[\"Proportion of Variance\",\"PC1\"])) +\n  ylab(paste(\"PC2, %\",100 * pca_data_info[\"Proportion of Variance\",\"PC2\"])) +\n  ggtitle(\"PCA for DUX4 timecourse\") +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-15.html#famous-pca-example",
    "href": "exercises/ex-15.html#famous-pca-example",
    "title": "Stats Bootcamp - class 15",
    "section": "Famous PCA example",
    "text": "Famous PCA example\nUsing gene expression as your measurement, do you think the mouse liver is more similar to a mouse heart or a human liver?\nThe Mouse ENCODE Consortium reported that comparative gene expression data from human and mouse tend to cluster more by species rather than by tissue.\n\nA comparative encyclopedia of DNA elements in the mouse genome\nComparison of the transcriptional landscapes between human and mouse tissues"
  },
  {
    "objectID": "exercises/ex-15.html#some-found-this-hard-to-believe",
    "href": "exercises/ex-15.html#some-found-this-hard-to-believe",
    "title": "Stats Bootcamp - class 15",
    "section": "Some found this hard to believe",
    "text": "Some found this hard to believe\nYoav Gilad’s lab recapitulated the initial result:\n\nThis observation was surprising, as it contradicted much of the comparative gene regulatory data collected previously, as well as the common notion that major developmental pathways are highly conserved across a wide range of species, in particular across mammals."
  },
  {
    "objectID": "exercises/ex-15.html#careful-with-batch-effects",
    "href": "exercises/ex-15.html#careful-with-batch-effects",
    "title": "Stats Bootcamp - class 15",
    "section": "Careful with batch effects",
    "text": "Careful with batch effects\nBut noticed something funny about which samples were sequenced on the same lanes."
  },
  {
    "objectID": "exercises/ex-15.html#accounting-for-batch-effects",
    "href": "exercises/ex-15.html#accounting-for-batch-effects",
    "title": "Stats Bootcamp - class 15",
    "section": "Accounting for batch effects",
    "text": "Accounting for batch effects\n\nHere we show that the Mouse ENCODE gene expression data were collected using a flawed study design, which confounded sequencing batch (namely, the assignment of samples to sequencing flowcells and lanes) with species. When we account for the batch effect, the corrected comparative gene expression data from human and mouse tend to cluster by tissue, not by species."
  },
  {
    "objectID": "exercises/ex-15.html#k-means-clustering-to-look-for-patterns",
    "href": "exercises/ex-15.html#k-means-clustering-to-look-for-patterns",
    "title": "Stats Bootcamp - class 15",
    "section": "K-means clustering to look for patterns",
    "text": "K-means clustering to look for patterns\nGoal: to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster. –Wiki\nK-means"
  },
  {
    "objectID": "exercises/ex-15.html#k-means-data-preparation",
    "href": "exercises/ex-15.html#k-means-data-preparation",
    "title": "Stats Bootcamp - class 15",
    "section": "K-Means data preparation",
    "text": "K-Means data preparation\n\nRows are observations (individuals) and columns are variables\nAny missing value in the data must be removed or estimated.\nThe data must be standardized (i.e., scaled) to make variables comparable."
  },
  {
    "objectID": "exercises/ex-15.html#scaling-or-z-score",
    "href": "exercises/ex-15.html#scaling-or-z-score",
    "title": "Stats Bootcamp - class 15",
    "section": "Scaling or z-score",
    "text": "Scaling or z-score\n{%20}\n\\(x\\) = observation\\(\\mu\\) = population mean\\(\\sigma\\) = population sd\nWe will be using this function on each row. This will allow comparison of relative changes across a row, for all rows."
  },
  {
    "objectID": "exercises/ex-15.html#k-means-clustering",
    "href": "exercises/ex-15.html#k-means-clustering",
    "title": "Stats Bootcamp - class 15",
    "section": "K-Means clustering",
    "text": "K-Means clustering\n\nComputing k-means clustering in R (pheatmap)\nDetermine appropriate cluster number\nAdd new column with cluster number to initial data"
  },
  {
    "objectID": "exercises/ex-15.html#how-do-we-figure-out-the-optimal-clusters",
    "href": "exercises/ex-15.html#how-do-we-figure-out-the-optimal-clusters",
    "title": "Stats Bootcamp - class 15",
    "section": "How do we figure out the optimal # clusters?",
    "text": "How do we figure out the optimal # clusters?\nThere are many methods, but we will stick with the “elbow” method.\nK-means is minimizing the total within cluster sum of squares (wss).\nWe pick the cluster where that drop in total reaches diminishing returns -&gt; the elbow."
  },
  {
    "objectID": "exercises/ex-15.html#lets-cluster-once-to-see",
    "href": "exercises/ex-15.html#lets-cluster-once-to-see",
    "title": "Stats Bootcamp - class 15",
    "section": "Let’s cluster once to see",
    "text": "Let’s cluster once to see\n\nset.seed(33)\ntmp &lt;- pheatmap(\n  mat = x,\n  clustering_distance_rows = \"euclidean\",\n  clustering_method = \"ward.D2\",\n  kmeans_k = ??,\n  cluster_cols = FALSE,\n  scale = \"none\"\n)\n\n\ntmp$kmeans$tot.withinss"
  },
  {
    "objectID": "exercises/ex-15.html#functions-in-r",
    "href": "exercises/ex-15.html#functions-in-r",
    "title": "Stats Bootcamp - class 15",
    "section": "Functions in R",
    "text": "Functions in R"
  },
  {
    "objectID": "exercises/ex-15.html#create-function-to-calculate-wss",
    "href": "exercises/ex-15.html#create-function-to-calculate-wss",
    "title": "Stats Bootcamp - class 15",
    "section": "Create function to calculate wss",
    "text": "Create function to calculate wss\n\nwss &lt;- function(knum) {\n  ph &lt;- pheatmap(\n    mat = x,\n    kmeans_k = ??,\n    scale = \"none\",\n    cluster_cols = FALSE,\n    clustering_distance_rows = \"euclidean\",\n    clustering_method = \"ward.D2\",\n    silent = TRUE\n  )\n  return(ph$kmeans$tot.withinss)\n}\n\nwss(6)"
  },
  {
    "objectID": "exercises/ex-15.html#find-the-elbow",
    "href": "exercises/ex-15.html#find-the-elbow",
    "title": "Stats Bootcamp - class 15",
    "section": "find the elbow",
    "text": "find the elbow\n\ntibble(wss=map_vec(2:15,wss),\n       k=2:15) |&gt;\n  ggplot(., aes(x=k, y=wss)) +\n  geom_point() +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-15.html#final-clustering",
    "href": "exercises/ex-15.html#final-clustering",
    "title": "Stats Bootcamp - class 15",
    "section": "Final clustering",
    "text": "Final clustering\n\nset.seed(33)\nc &lt;- pheatmap(\n  mat = x,\n  clustering_distance_rows = \"euclidean\",\n  clustering_method = \"ward.D2\",\n  kmeans_k = 7,\n  cluster_cols = F,\n  scale = \"none\"\n)\n\ncg &lt;- tibble(\n  Cluster=c$kmeans$cluster,\n  gene_symbol=names(c$kmeans$cluster)\n)\n\ncd &lt;- left_join(d, cg, by=\"gene_symbol\")"
  },
  {
    "objectID": "exercises/ex-15.html#which-clusters-contains-dux4-targets",
    "href": "exercises/ex-15.html#which-clusters-contains-dux4-targets",
    "title": "Stats Bootcamp - class 15",
    "section": "Which cluster(s) contains DUX4 targets?",
    "text": "Which cluster(s) contains DUX4 targets?\nFisher’s Exact Test and the Hypergeometric Distribution\n\n# list of genes by dux4 targeting\nduxList &lt;- split(cd$gene_symbol, cd$??)\n\n# list of genes by clustering\nclustList &lt;- split(cd$gene_symbol, as.factor(cd$??))\n\n# calculate all overlaps between lists\ngom.duxclust &lt;- newGOM(??List,\n                       ??List,\n                       genome.size = ??)\n\n\ngetMatrix(gom.duxclust, \"pval\") |&gt;\n  t() |&gt;\n  as.data.frame() |&gt;\n  rownames_to_column(var = \"clust\") |&gt;\n  as.tibble() |&gt;\n  arrange(target)"
  },
  {
    "objectID": "exercises/ex-15.html#lets-calculate-the-empirical-p-value-of-the-cluster-most-enriched-for-dux4-targets-by-sampling",
    "href": "exercises/ex-15.html#lets-calculate-the-empirical-p-value-of-the-cluster-most-enriched-for-dux4-targets-by-sampling",
    "title": "Stats Bootcamp - class 15",
    "section": "Let’s calculate the empirical p-value of the cluster most enriched for DUX4 targets by sampling",
    "text": "Let’s calculate the empirical p-value of the cluster most enriched for DUX4 targets by sampling\nIn order to do this, you will need to:\n\nIdentify which cluster is the most enriched for DUX4 targets.\n\nDetermine how many genes are in the cluster. You will need to know this to figure out how many genes to sample from the whole data set.\nDetermine how many of the genes in the cluster are DUX4 targets. This is the metric that you are interested in comparing between the null distribution and your observation.\n\n\nGenerate 1000 random sample of the proper size from all genes and find out how many of them are DUX4 targets.\nVisualize the distribution of DUX4 targets in these 1000 random (your null distribution) and overlay the number of DUX4 targets you observed in the cluster that was most enriched for DUX4 targets."
  },
  {
    "objectID": "prepare/prepare-01.html",
    "href": "prepare/prepare-01.html",
    "title": "R Bootcamp",
    "section": "",
    "text": "Important\n\n\n\nBefore class begins, login with your CU credentials at Posit Cloud: https://sso.posit.cloud/cu-anschutz"
  },
  {
    "objectID": "prepare/prepare-01.html#prepare",
    "href": "prepare/prepare-01.html#prepare",
    "title": "R Bootcamp",
    "section": "Prepare",
    "text": "Prepare\n📖 Read the syllabus\n📖 Read the support resources\n📖 Look over the RStudio cheatsheet"
  },
  {
    "objectID": "prepare/prepare-03.html",
    "href": "prepare/prepare-03.html",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look over the dplyr cheatsheet.\nWe’ll be using the filter(), select(), mutate(), arrange(), group_by(), and summarise() functions. Pay special attention to the comparison operators and logical operators sections, as well as case_when() for conditional logic."
  },
  {
    "objectID": "prepare/prepare-03.html#prepare",
    "href": "prepare/prepare-03.html#prepare",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look over the dplyr cheatsheet.\nWe’ll be using the filter(), select(), mutate(), arrange(), group_by(), and summarise() functions. Pay special attention to the comparison operators and logical operators sections, as well as case_when() for conditional logic."
  },
  {
    "objectID": "prepare/prepare-07.html",
    "href": "prepare/prepare-07.html",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look at the *_join() functions in the dplyr cheatsheet. These animations are helpful visualizations of the join transformations.\nLook over the cheatsheets for stringr and forcats.\nLook over the scale_*() functions (second page) in the ggplot2 cheatsheet."
  },
  {
    "objectID": "prepare/prepare-07.html#prepare",
    "href": "prepare/prepare-07.html#prepare",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look at the *_join() functions in the dplyr cheatsheet. These animations are helpful visualizations of the join transformations.\nLook over the cheatsheets for stringr and forcats.\nLook over the scale_*() functions (second page) in the ggplot2 cheatsheet."
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html",
    "href": "problem-set-keys/ps-key-01.html",
    "title": "Problem Set 1 Key",
    "section": "",
    "text": "Each problem below is worth 8 points.\nThe problem set is due 12pm on Aug 30.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#problem-set",
    "href": "problem-set-keys/ps-key-01.html#problem-set",
    "title": "Problem Set 1 Key",
    "section": "",
    "text": "Each problem below is worth 8 points.\nThe problem set is due 12pm on Aug 30.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#setup",
    "href": "problem-set-keys/ps-key-01.html#setup",
    "title": "Problem Set 1 Key",
    "section": "Setup",
    "text": "Setup\nStart by loading libraries you need analysis below. When in doubt, start by loading the tidyverse package.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#question-1",
    "href": "problem-set-keys/ps-key-01.html#question-1",
    "title": "Problem Set 1 Key",
    "section": "Question 1",
    "text": "Question 1\nCreate 3 different vectors called x, y, and z:\n\n\nx should be character vector of length 5 (hint: use LETTERS or letters)\n\ny should be a numeric vector of length 5 (hint: try 1:5 or c(1, 2, 3, 4, 5))\n\nz should be a logical vector of length 5 (hint: use TRUE and FALSE values)\n\nUse length() to calculate the length of each vector.\n\nx &lt;- LETTERS[1:5]\ny &lt;- 1:5\nz &lt;- c(TRUE, TRUE, FALSE, FALSE, FALSE)\n\nx\n\n[1] \"A\" \"B\" \"C\" \"D\" \"E\"\n\ny\n\n[1] 1 2 3 4 5\n\nz\n\n[1]  TRUE  TRUE FALSE FALSE FALSE\n\n# Traditional way\nlength(x)\n\n[1] 5\n\nlength(y)\n\n[1] 5\n\nlength(z)\n\n[1] 5"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#question-2",
    "href": "problem-set-keys/ps-key-01.html#question-2",
    "title": "Problem Set 1 Key",
    "section": "Question 2",
    "text": "Question 2\nUsing the vectors you created above, create a new tibble with column names x, y, and z. Use the tibble() function to combine your vectors into a data frame.\nUse nrow() and ncol() to calculate the number of rows and columns, both with and without the pipe operator.\nUse glimpse() to get a quick overview of your tibble - this shows data types and first few values.\nWhat do you notice about the length of the vectors and the number of rows?\n\ntbl &lt;- tibble(x = x, y = y, z = z)\n\n# Traditional way\nnrow(tbl)\n\n[1] 5\n\nncol(tbl)\n\n[1] 3\n\n# Get a quick overview\nglimpse(tbl)\n\nRows: 5\nColumns: 3\n$ x &lt;chr&gt; \"A\", \"B\", \"C\", \"D\", \"E\"\n$ y &lt;int&gt; 1, 2, 3, 4, 5\n$ z &lt;lgl&gt; TRUE, TRUE, FALSE, FALSE, FALSE\n\n\nAnswer\nThe length of the vectors and the number of rows are the same, because tibble columns are simply the vectors we started with."
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#question-3",
    "href": "problem-set-keys/ps-key-01.html#question-3",
    "title": "Problem Set 1 Key",
    "section": "Question 3",
    "text": "Question 3\nLet’s explore the penguins dataset that we loaded.\n\nLook at the number of rows with nrow() - this tells us how many penguins are in the dataset\nLook at the number of columns with ncol() - this tells us how many variables we measured\nLook at the column names with names() - this shows us what variables we have\nGet a glimpse of the data with glimpse() - this shows data types and sample values\n\n\n# Explore the penguins dataset\nnrow(penguins)\n\n[1] 344\n\nncol(penguins)\n\n[1] 8\n\nnames(penguins)\n\n[1] \"species\"     \"island\"      \"bill_len\"    \"bill_dep\"    \"flipper_len\"\n[6] \"body_mass\"   \"sex\"         \"year\"       \n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species     &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Ad…\n$ island      &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgersen, Tor…\n$ bill_len    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, 42.0, …\n$ bill_dep    &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, 20.2, …\n$ flipper_len &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186, 180,…\n$ body_mass   &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, 4250, …\n$ sex         &lt;fct&gt; male, female, female, NA, female, male, female, male, NA, …\n$ year        &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#question-4",
    "href": "problem-set-keys/ps-key-01.html#question-4",
    "title": "Problem Set 1 Key",
    "section": "Question 4",
    "text": "Question 4\nNext we will think about data tidying. Let’s start by analyzing the penguins dataset.\nPart A: Is the penguins dataset tidy? To determine this, we need to think about the three principles of tidy data:\n\nEach variable forms a column\nEach observation forms a row\nEach type of observational unit forms a table\n\nLook at the penguins dataset and answer:\n\nWhat are the variables in the dataset? (Hint: use names(penguins) to see them)\nDoes each column represent a single variable?\nDoes each row represent a single penguin observation?\n\n\n# Look at the structure of penguins\npenguins |&gt; glimpse()\n\nRows: 344\nColumns: 8\n$ species     &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Ad…\n$ island      &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgersen, Tor…\n$ bill_len    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, 42.0, …\n$ bill_dep    &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, 20.2, …\n$ flipper_len &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186, 180,…\n$ body_mass   &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, 4250, …\n$ sex         &lt;fct&gt; male, female, female, NA, female, male, female, male, NA, …\n$ year        &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n# What are the variables?\nnames(penguins)\n\n[1] \"species\"     \"island\"      \"bill_len\"    \"bill_dep\"    \"flipper_len\"\n[6] \"body_mass\"   \"sex\"         \"year\"       \n\n# Look at a few rows\npenguins |&gt; head()\n\n  species    island bill_len bill_dep flipper_len body_mass    sex year\n1  Adelie Torgersen     39.1     18.7         181      3750   male 2007\n2  Adelie Torgersen     39.5     17.4         186      3800 female 2007\n3  Adelie Torgersen     40.3     18.0         195      3250 female 2007\n4  Adelie Torgersen       NA       NA          NA        NA   &lt;NA&gt; 2007\n5  Adelie Torgersen     36.7     19.3         193      3450 female 2007\n6  Adelie Torgersen     39.3     20.6         190      3650   male 2007\n\n\nAnswer: Yes, the penguins dataset is tidy because:\n\nEach column represents one variable (species, island, bill_length_mm, etc.)\nEach row represents one penguin observation\nAll observations are of the same type (penguin measurements)\n\nPart B: Now let’s examine some datasets that are NOT tidy. Use data() to see available datasets, then look at these two examples:\nExample 1: anscombe - This is a classic statistics dataset:\n\n# Look at the anscombe dataset\nanscombe\n\n   x1 x2 x3 x4    y1   y2    y3    y4\n1  10 10 10  8  8.04 9.14  7.46  6.58\n2   8  8  8  8  6.95 8.14  6.77  5.76\n3  13 13 13  8  7.58 8.74 12.74  7.71\n4   9  9  9  8  8.81 8.77  7.11  8.84\n5  11 11 11  8  8.33 9.26  7.81  8.47\n6  14 14 14  8  9.96 8.10  8.84  7.04\n7   6  6  6  8  7.24 6.13  6.08  5.25\n8   4  4  4 19  4.26 3.10  5.39 12.50\n9  12 12 12  8 10.84 9.13  8.15  5.56\n10  7  7  7  8  4.82 7.26  6.42  7.91\n11  5  5  5  8  5.68 4.74  5.73  6.89\n\nglimpse(anscombe)\n\nRows: 11\nColumns: 8\n$ x1 &lt;dbl&gt; 10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5\n$ x2 &lt;dbl&gt; 10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5\n$ x3 &lt;dbl&gt; 10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5\n$ x4 &lt;dbl&gt; 8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8\n$ y1 &lt;dbl&gt; 8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68\n$ y2 &lt;dbl&gt; 9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74\n$ y3 &lt;dbl&gt; 7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73\n$ y4 &lt;dbl&gt; 6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89\n\n\nIs anscombe tidy? Think about: - What are the actual variables? (Hint: x and y coordinates for different datasets) - How many different datasets are encoded in the column names? - What would a tidy version look like?\nExample 2: Choose another dataset - Pick one more dataset from data() and analyze whether it’s tidy:\n\n# Look at available datasets\ndata()\n\n# Choose one and examine it (examples: WorldPhones, UCBAdmissions, HairEyeColor)\n# Let's try WorldPhones as an example\nWorldPhones\n\n     N.Amer Europe Asia S.Amer Oceania Africa Mid.Amer\n1951  45939  21574 2876   1815    1646     89      555\n1956  60423  29990 4708   2568    2366   1411      733\n1957  64721  32510 5230   2695    2526   1546      773\n1958  68484  35218 6662   2845    2691   1663      836\n1959  71799  37598 6856   3000    2868   1769      911\n1960  76036  40341 8220   3145    3054   1905     1008\n1961  79831  43173 9053   3338    3224   2005     1076\n\n\n`\nPart C: Write a brief explanation (2-3 sentences) for each dataset about: 1. Whether it’s tidy or not 2. What makes it tidy/untidy 3. What the variables actually represent\nYour Analysis:\npenguins: The penguins dataset is tidy because each column represents a single variable (species, island, bill measurements, etc.), each row represents one penguin observation, and all data is the same type of observational unit (individual penguin measurements). The variables are clearly defined and there’s no mixing of different types of information in single columns.\nanscombe: The anscombe dataset is NOT tidy because it violates multiple tidy data principles. The actual variables are x-coordinates, y-coordinates, and dataset identifier, but the dataset identifier is encoded in the column names (x1, y1, x2, y2, etc.). Four different datasets are stored in one table, with each dataset’s x and y values spread across separate columns rather than being in rows with a dataset identifier column.\nWorldPhones: The WorldPhones dataset is NOT tidy because it has years as row names instead of a proper column, and regions are spread across columns rather than being values in a “region” variable. The actual variables should be year, region, and number of phones, but currently the year and region information is stored in the structure of the table rather than as data values. A tidy version would have one row per year-region combination."
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#submit",
    "href": "problem-set-keys/ps-key-01.html#submit",
    "title": "Problem Set 1 Key",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of the Posit Cloud project (NOT the HTML link) into the problem set on Canvas."
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html",
    "href": "problem-set-keys/ps-key-03.html",
    "title": "R Bootcamp Problem Set 3",
    "section": "",
    "text": "Start by loading libraries you need analysis in the code chunk below. When in doubt, start by loading the tidyverse package.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html#setup",
    "href": "problem-set-keys/ps-key-03.html#setup",
    "title": "R Bootcamp Problem Set 3",
    "section": "",
    "text": "Start by loading libraries you need analysis in the code chunk below. When in doubt, start by loading the tidyverse package.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html#problem-set",
    "href": "problem-set-keys/ps-key-03.html#problem-set",
    "title": "R Bootcamp Problem Set 3",
    "section": "Problem Set",
    "text": "Problem Set\nEach problem below is worth 5 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Aug 31.\nGrading rubric\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points ## Question 1\n\nLoad the palmerpenguins package (already done above). Inspect the penguins tibble with summary() to see the distribution of variables and any missing values.\nUse drop_na() to remove rows with NA values in the penguins tibble. Calculate how many rows were removed by subtracting the new count from the original count using nrow().\nThen, use count() to explore the data and see how many penguins of each species we have. This is a simple but powerful way to understand your data!\n\nsummary(penguins)\n\n      species          island       bill_len        bill_dep    \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n  flipper_len      body_mass        sex           year     \n Min.   :172.0   Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0   1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0   Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9   Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0   3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0   Max.   :6300                Max.   :2009  \n NA's   :2       NA's   :2                                 \n\n# Remove rows with any missing values\npenguins_nona &lt;- drop_na(penguins)\nnrow(penguins) - nrow(penguins_nona)\n\n[1] 11\n\n# Simple counting - this is a great way to explore data!\npenguins |&gt;\n  count(species)\n\n    species   n\n1    Adelie 152\n2 Chinstrap  68\n3    Gentoo 124\n\n# You can count by multiple variables too\npenguins |&gt;\n  count(species, island)\n\n    species    island   n\n1    Adelie    Biscoe  44\n2    Adelie     Dream  56\n3    Adelie Torgersen  52\n4 Chinstrap     Dream  68\n5    Gentoo    Biscoe 124\n\n\nThen, use replace_na() to replace NA values in bill_length_mm and bill_depth_mm with a value of 0. You’ll need to:\n\nProvide the data frame as the first argument\nProvide a named list showing which columns to replace and what values to use\n\n\nreplace_na(penguins, list(bill_length_mm = 0, bill_depth_mm = 0))\n\n      species    island bill_len bill_dep flipper_len body_mass    sex year\n1      Adelie Torgersen     39.1     18.7         181      3750   male 2007\n2      Adelie Torgersen     39.5     17.4         186      3800 female 2007\n3      Adelie Torgersen     40.3     18.0         195      3250 female 2007\n4      Adelie Torgersen       NA       NA          NA        NA   &lt;NA&gt; 2007\n5      Adelie Torgersen     36.7     19.3         193      3450 female 2007\n6      Adelie Torgersen     39.3     20.6         190      3650   male 2007\n7      Adelie Torgersen     38.9     17.8         181      3625 female 2007\n8      Adelie Torgersen     39.2     19.6         195      4675   male 2007\n9      Adelie Torgersen     34.1     18.1         193      3475   &lt;NA&gt; 2007\n10     Adelie Torgersen     42.0     20.2         190      4250   &lt;NA&gt; 2007\n11     Adelie Torgersen     37.8     17.1         186      3300   &lt;NA&gt; 2007\n12     Adelie Torgersen     37.8     17.3         180      3700   &lt;NA&gt; 2007\n13     Adelie Torgersen     41.1     17.6         182      3200 female 2007\n14     Adelie Torgersen     38.6     21.2         191      3800   male 2007\n15     Adelie Torgersen     34.6     21.1         198      4400   male 2007\n16     Adelie Torgersen     36.6     17.8         185      3700 female 2007\n17     Adelie Torgersen     38.7     19.0         195      3450 female 2007\n18     Adelie Torgersen     42.5     20.7         197      4500   male 2007\n19     Adelie Torgersen     34.4     18.4         184      3325 female 2007\n20     Adelie Torgersen     46.0     21.5         194      4200   male 2007\n21     Adelie    Biscoe     37.8     18.3         174      3400 female 2007\n22     Adelie    Biscoe     37.7     18.7         180      3600   male 2007\n23     Adelie    Biscoe     35.9     19.2         189      3800 female 2007\n24     Adelie    Biscoe     38.2     18.1         185      3950   male 2007\n25     Adelie    Biscoe     38.8     17.2         180      3800   male 2007\n26     Adelie    Biscoe     35.3     18.9         187      3800 female 2007\n27     Adelie    Biscoe     40.6     18.6         183      3550   male 2007\n28     Adelie    Biscoe     40.5     17.9         187      3200 female 2007\n29     Adelie    Biscoe     37.9     18.6         172      3150 female 2007\n30     Adelie    Biscoe     40.5     18.9         180      3950   male 2007\n31     Adelie     Dream     39.5     16.7         178      3250 female 2007\n32     Adelie     Dream     37.2     18.1         178      3900   male 2007\n33     Adelie     Dream     39.5     17.8         188      3300 female 2007\n34     Adelie     Dream     40.9     18.9         184      3900   male 2007\n35     Adelie     Dream     36.4     17.0         195      3325 female 2007\n36     Adelie     Dream     39.2     21.1         196      4150   male 2007\n37     Adelie     Dream     38.8     20.0         190      3950   male 2007\n38     Adelie     Dream     42.2     18.5         180      3550 female 2007\n39     Adelie     Dream     37.6     19.3         181      3300 female 2007\n40     Adelie     Dream     39.8     19.1         184      4650   male 2007\n41     Adelie     Dream     36.5     18.0         182      3150 female 2007\n42     Adelie     Dream     40.8     18.4         195      3900   male 2007\n43     Adelie     Dream     36.0     18.5         186      3100 female 2007\n44     Adelie     Dream     44.1     19.7         196      4400   male 2007\n45     Adelie     Dream     37.0     16.9         185      3000 female 2007\n46     Adelie     Dream     39.6     18.8         190      4600   male 2007\n47     Adelie     Dream     41.1     19.0         182      3425   male 2007\n48     Adelie     Dream     37.5     18.9         179      2975   &lt;NA&gt; 2007\n49     Adelie     Dream     36.0     17.9         190      3450 female 2007\n50     Adelie     Dream     42.3     21.2         191      4150   male 2007\n51     Adelie    Biscoe     39.6     17.7         186      3500 female 2008\n52     Adelie    Biscoe     40.1     18.9         188      4300   male 2008\n53     Adelie    Biscoe     35.0     17.9         190      3450 female 2008\n54     Adelie    Biscoe     42.0     19.5         200      4050   male 2008\n55     Adelie    Biscoe     34.5     18.1         187      2900 female 2008\n56     Adelie    Biscoe     41.4     18.6         191      3700   male 2008\n57     Adelie    Biscoe     39.0     17.5         186      3550 female 2008\n58     Adelie    Biscoe     40.6     18.8         193      3800   male 2008\n59     Adelie    Biscoe     36.5     16.6         181      2850 female 2008\n60     Adelie    Biscoe     37.6     19.1         194      3750   male 2008\n61     Adelie    Biscoe     35.7     16.9         185      3150 female 2008\n62     Adelie    Biscoe     41.3     21.1         195      4400   male 2008\n63     Adelie    Biscoe     37.6     17.0         185      3600 female 2008\n64     Adelie    Biscoe     41.1     18.2         192      4050   male 2008\n65     Adelie    Biscoe     36.4     17.1         184      2850 female 2008\n66     Adelie    Biscoe     41.6     18.0         192      3950   male 2008\n67     Adelie    Biscoe     35.5     16.2         195      3350 female 2008\n68     Adelie    Biscoe     41.1     19.1         188      4100   male 2008\n69     Adelie Torgersen     35.9     16.6         190      3050 female 2008\n70     Adelie Torgersen     41.8     19.4         198      4450   male 2008\n71     Adelie Torgersen     33.5     19.0         190      3600 female 2008\n72     Adelie Torgersen     39.7     18.4         190      3900   male 2008\n73     Adelie Torgersen     39.6     17.2         196      3550 female 2008\n74     Adelie Torgersen     45.8     18.9         197      4150   male 2008\n75     Adelie Torgersen     35.5     17.5         190      3700 female 2008\n76     Adelie Torgersen     42.8     18.5         195      4250   male 2008\n77     Adelie Torgersen     40.9     16.8         191      3700 female 2008\n78     Adelie Torgersen     37.2     19.4         184      3900   male 2008\n79     Adelie Torgersen     36.2     16.1         187      3550 female 2008\n80     Adelie Torgersen     42.1     19.1         195      4000   male 2008\n81     Adelie Torgersen     34.6     17.2         189      3200 female 2008\n82     Adelie Torgersen     42.9     17.6         196      4700   male 2008\n83     Adelie Torgersen     36.7     18.8         187      3800 female 2008\n84     Adelie Torgersen     35.1     19.4         193      4200   male 2008\n85     Adelie     Dream     37.3     17.8         191      3350 female 2008\n86     Adelie     Dream     41.3     20.3         194      3550   male 2008\n87     Adelie     Dream     36.3     19.5         190      3800   male 2008\n88     Adelie     Dream     36.9     18.6         189      3500 female 2008\n89     Adelie     Dream     38.3     19.2         189      3950   male 2008\n90     Adelie     Dream     38.9     18.8         190      3600 female 2008\n91     Adelie     Dream     35.7     18.0         202      3550 female 2008\n92     Adelie     Dream     41.1     18.1         205      4300   male 2008\n93     Adelie     Dream     34.0     17.1         185      3400 female 2008\n94     Adelie     Dream     39.6     18.1         186      4450   male 2008\n95     Adelie     Dream     36.2     17.3         187      3300 female 2008\n96     Adelie     Dream     40.8     18.9         208      4300   male 2008\n97     Adelie     Dream     38.1     18.6         190      3700 female 2008\n98     Adelie     Dream     40.3     18.5         196      4350   male 2008\n99     Adelie     Dream     33.1     16.1         178      2900 female 2008\n100    Adelie     Dream     43.2     18.5         192      4100   male 2008\n101    Adelie    Biscoe     35.0     17.9         192      3725 female 2009\n102    Adelie    Biscoe     41.0     20.0         203      4725   male 2009\n103    Adelie    Biscoe     37.7     16.0         183      3075 female 2009\n104    Adelie    Biscoe     37.8     20.0         190      4250   male 2009\n105    Adelie    Biscoe     37.9     18.6         193      2925 female 2009\n106    Adelie    Biscoe     39.7     18.9         184      3550   male 2009\n107    Adelie    Biscoe     38.6     17.2         199      3750 female 2009\n108    Adelie    Biscoe     38.2     20.0         190      3900   male 2009\n109    Adelie    Biscoe     38.1     17.0         181      3175 female 2009\n110    Adelie    Biscoe     43.2     19.0         197      4775   male 2009\n111    Adelie    Biscoe     38.1     16.5         198      3825 female 2009\n112    Adelie    Biscoe     45.6     20.3         191      4600   male 2009\n113    Adelie    Biscoe     39.7     17.7         193      3200 female 2009\n114    Adelie    Biscoe     42.2     19.5         197      4275   male 2009\n115    Adelie    Biscoe     39.6     20.7         191      3900 female 2009\n116    Adelie    Biscoe     42.7     18.3         196      4075   male 2009\n117    Adelie Torgersen     38.6     17.0         188      2900 female 2009\n118    Adelie Torgersen     37.3     20.5         199      3775   male 2009\n119    Adelie Torgersen     35.7     17.0         189      3350 female 2009\n120    Adelie Torgersen     41.1     18.6         189      3325   male 2009\n121    Adelie Torgersen     36.2     17.2         187      3150 female 2009\n122    Adelie Torgersen     37.7     19.8         198      3500   male 2009\n123    Adelie Torgersen     40.2     17.0         176      3450 female 2009\n124    Adelie Torgersen     41.4     18.5         202      3875   male 2009\n125    Adelie Torgersen     35.2     15.9         186      3050 female 2009\n126    Adelie Torgersen     40.6     19.0         199      4000   male 2009\n127    Adelie Torgersen     38.8     17.6         191      3275 female 2009\n128    Adelie Torgersen     41.5     18.3         195      4300   male 2009\n129    Adelie Torgersen     39.0     17.1         191      3050 female 2009\n130    Adelie Torgersen     44.1     18.0         210      4000   male 2009\n131    Adelie Torgersen     38.5     17.9         190      3325 female 2009\n132    Adelie Torgersen     43.1     19.2         197      3500   male 2009\n133    Adelie     Dream     36.8     18.5         193      3500 female 2009\n134    Adelie     Dream     37.5     18.5         199      4475   male 2009\n135    Adelie     Dream     38.1     17.6         187      3425 female 2009\n136    Adelie     Dream     41.1     17.5         190      3900   male 2009\n137    Adelie     Dream     35.6     17.5         191      3175 female 2009\n138    Adelie     Dream     40.2     20.1         200      3975   male 2009\n139    Adelie     Dream     37.0     16.5         185      3400 female 2009\n140    Adelie     Dream     39.7     17.9         193      4250   male 2009\n141    Adelie     Dream     40.2     17.1         193      3400 female 2009\n142    Adelie     Dream     40.6     17.2         187      3475   male 2009\n143    Adelie     Dream     32.1     15.5         188      3050 female 2009\n144    Adelie     Dream     40.7     17.0         190      3725   male 2009\n145    Adelie     Dream     37.3     16.8         192      3000 female 2009\n146    Adelie     Dream     39.0     18.7         185      3650   male 2009\n147    Adelie     Dream     39.2     18.6         190      4250   male 2009\n148    Adelie     Dream     36.6     18.4         184      3475 female 2009\n149    Adelie     Dream     36.0     17.8         195      3450 female 2009\n150    Adelie     Dream     37.8     18.1         193      3750   male 2009\n151    Adelie     Dream     36.0     17.1         187      3700 female 2009\n152    Adelie     Dream     41.5     18.5         201      4000   male 2009\n153    Gentoo    Biscoe     46.1     13.2         211      4500 female 2007\n154    Gentoo    Biscoe     50.0     16.3         230      5700   male 2007\n155    Gentoo    Biscoe     48.7     14.1         210      4450 female 2007\n156    Gentoo    Biscoe     50.0     15.2         218      5700   male 2007\n157    Gentoo    Biscoe     47.6     14.5         215      5400   male 2007\n158    Gentoo    Biscoe     46.5     13.5         210      4550 female 2007\n159    Gentoo    Biscoe     45.4     14.6         211      4800 female 2007\n160    Gentoo    Biscoe     46.7     15.3         219      5200   male 2007\n161    Gentoo    Biscoe     43.3     13.4         209      4400 female 2007\n162    Gentoo    Biscoe     46.8     15.4         215      5150   male 2007\n163    Gentoo    Biscoe     40.9     13.7         214      4650 female 2007\n164    Gentoo    Biscoe     49.0     16.1         216      5550   male 2007\n165    Gentoo    Biscoe     45.5     13.7         214      4650 female 2007\n166    Gentoo    Biscoe     48.4     14.6         213      5850   male 2007\n167    Gentoo    Biscoe     45.8     14.6         210      4200 female 2007\n168    Gentoo    Biscoe     49.3     15.7         217      5850   male 2007\n169    Gentoo    Biscoe     42.0     13.5         210      4150 female 2007\n170    Gentoo    Biscoe     49.2     15.2         221      6300   male 2007\n171    Gentoo    Biscoe     46.2     14.5         209      4800 female 2007\n172    Gentoo    Biscoe     48.7     15.1         222      5350   male 2007\n173    Gentoo    Biscoe     50.2     14.3         218      5700   male 2007\n174    Gentoo    Biscoe     45.1     14.5         215      5000 female 2007\n175    Gentoo    Biscoe     46.5     14.5         213      4400 female 2007\n176    Gentoo    Biscoe     46.3     15.8         215      5050   male 2007\n177    Gentoo    Biscoe     42.9     13.1         215      5000 female 2007\n178    Gentoo    Biscoe     46.1     15.1         215      5100   male 2007\n179    Gentoo    Biscoe     44.5     14.3         216      4100   &lt;NA&gt; 2007\n180    Gentoo    Biscoe     47.8     15.0         215      5650   male 2007\n181    Gentoo    Biscoe     48.2     14.3         210      4600 female 2007\n182    Gentoo    Biscoe     50.0     15.3         220      5550   male 2007\n183    Gentoo    Biscoe     47.3     15.3         222      5250   male 2007\n184    Gentoo    Biscoe     42.8     14.2         209      4700 female 2007\n185    Gentoo    Biscoe     45.1     14.5         207      5050 female 2007\n186    Gentoo    Biscoe     59.6     17.0         230      6050   male 2007\n187    Gentoo    Biscoe     49.1     14.8         220      5150 female 2008\n188    Gentoo    Biscoe     48.4     16.3         220      5400   male 2008\n189    Gentoo    Biscoe     42.6     13.7         213      4950 female 2008\n190    Gentoo    Biscoe     44.4     17.3         219      5250   male 2008\n191    Gentoo    Biscoe     44.0     13.6         208      4350 female 2008\n192    Gentoo    Biscoe     48.7     15.7         208      5350   male 2008\n193    Gentoo    Biscoe     42.7     13.7         208      3950 female 2008\n194    Gentoo    Biscoe     49.6     16.0         225      5700   male 2008\n195    Gentoo    Biscoe     45.3     13.7         210      4300 female 2008\n196    Gentoo    Biscoe     49.6     15.0         216      4750   male 2008\n197    Gentoo    Biscoe     50.5     15.9         222      5550   male 2008\n198    Gentoo    Biscoe     43.6     13.9         217      4900 female 2008\n199    Gentoo    Biscoe     45.5     13.9         210      4200 female 2008\n200    Gentoo    Biscoe     50.5     15.9         225      5400   male 2008\n201    Gentoo    Biscoe     44.9     13.3         213      5100 female 2008\n202    Gentoo    Biscoe     45.2     15.8         215      5300   male 2008\n203    Gentoo    Biscoe     46.6     14.2         210      4850 female 2008\n204    Gentoo    Biscoe     48.5     14.1         220      5300   male 2008\n205    Gentoo    Biscoe     45.1     14.4         210      4400 female 2008\n206    Gentoo    Biscoe     50.1     15.0         225      5000   male 2008\n207    Gentoo    Biscoe     46.5     14.4         217      4900 female 2008\n208    Gentoo    Biscoe     45.0     15.4         220      5050   male 2008\n209    Gentoo    Biscoe     43.8     13.9         208      4300 female 2008\n210    Gentoo    Biscoe     45.5     15.0         220      5000   male 2008\n211    Gentoo    Biscoe     43.2     14.5         208      4450 female 2008\n212    Gentoo    Biscoe     50.4     15.3         224      5550   male 2008\n213    Gentoo    Biscoe     45.3     13.8         208      4200 female 2008\n214    Gentoo    Biscoe     46.2     14.9         221      5300   male 2008\n215    Gentoo    Biscoe     45.7     13.9         214      4400 female 2008\n216    Gentoo    Biscoe     54.3     15.7         231      5650   male 2008\n217    Gentoo    Biscoe     45.8     14.2         219      4700 female 2008\n218    Gentoo    Biscoe     49.8     16.8         230      5700   male 2008\n219    Gentoo    Biscoe     46.2     14.4         214      4650   &lt;NA&gt; 2008\n220    Gentoo    Biscoe     49.5     16.2         229      5800   male 2008\n221    Gentoo    Biscoe     43.5     14.2         220      4700 female 2008\n222    Gentoo    Biscoe     50.7     15.0         223      5550   male 2008\n223    Gentoo    Biscoe     47.7     15.0         216      4750 female 2008\n224    Gentoo    Biscoe     46.4     15.6         221      5000   male 2008\n225    Gentoo    Biscoe     48.2     15.6         221      5100   male 2008\n226    Gentoo    Biscoe     46.5     14.8         217      5200 female 2008\n227    Gentoo    Biscoe     46.4     15.0         216      4700 female 2008\n228    Gentoo    Biscoe     48.6     16.0         230      5800   male 2008\n229    Gentoo    Biscoe     47.5     14.2         209      4600 female 2008\n230    Gentoo    Biscoe     51.1     16.3         220      6000   male 2008\n231    Gentoo    Biscoe     45.2     13.8         215      4750 female 2008\n232    Gentoo    Biscoe     45.2     16.4         223      5950   male 2008\n233    Gentoo    Biscoe     49.1     14.5         212      4625 female 2009\n234    Gentoo    Biscoe     52.5     15.6         221      5450   male 2009\n235    Gentoo    Biscoe     47.4     14.6         212      4725 female 2009\n236    Gentoo    Biscoe     50.0     15.9         224      5350   male 2009\n237    Gentoo    Biscoe     44.9     13.8         212      4750 female 2009\n238    Gentoo    Biscoe     50.8     17.3         228      5600   male 2009\n239    Gentoo    Biscoe     43.4     14.4         218      4600 female 2009\n240    Gentoo    Biscoe     51.3     14.2         218      5300   male 2009\n241    Gentoo    Biscoe     47.5     14.0         212      4875 female 2009\n242    Gentoo    Biscoe     52.1     17.0         230      5550   male 2009\n243    Gentoo    Biscoe     47.5     15.0         218      4950 female 2009\n244    Gentoo    Biscoe     52.2     17.1         228      5400   male 2009\n245    Gentoo    Biscoe     45.5     14.5         212      4750 female 2009\n246    Gentoo    Biscoe     49.5     16.1         224      5650   male 2009\n247    Gentoo    Biscoe     44.5     14.7         214      4850 female 2009\n248    Gentoo    Biscoe     50.8     15.7         226      5200   male 2009\n249    Gentoo    Biscoe     49.4     15.8         216      4925   male 2009\n250    Gentoo    Biscoe     46.9     14.6         222      4875 female 2009\n251    Gentoo    Biscoe     48.4     14.4         203      4625 female 2009\n252    Gentoo    Biscoe     51.1     16.5         225      5250   male 2009\n253    Gentoo    Biscoe     48.5     15.0         219      4850 female 2009\n254    Gentoo    Biscoe     55.9     17.0         228      5600   male 2009\n255    Gentoo    Biscoe     47.2     15.5         215      4975 female 2009\n256    Gentoo    Biscoe     49.1     15.0         228      5500   male 2009\n257    Gentoo    Biscoe     47.3     13.8         216      4725   &lt;NA&gt; 2009\n258    Gentoo    Biscoe     46.8     16.1         215      5500   male 2009\n259    Gentoo    Biscoe     41.7     14.7         210      4700 female 2009\n260    Gentoo    Biscoe     53.4     15.8         219      5500   male 2009\n261    Gentoo    Biscoe     43.3     14.0         208      4575 female 2009\n262    Gentoo    Biscoe     48.1     15.1         209      5500   male 2009\n263    Gentoo    Biscoe     50.5     15.2         216      5000 female 2009\n264    Gentoo    Biscoe     49.8     15.9         229      5950   male 2009\n265    Gentoo    Biscoe     43.5     15.2         213      4650 female 2009\n266    Gentoo    Biscoe     51.5     16.3         230      5500   male 2009\n267    Gentoo    Biscoe     46.2     14.1         217      4375 female 2009\n268    Gentoo    Biscoe     55.1     16.0         230      5850   male 2009\n269    Gentoo    Biscoe     44.5     15.7         217      4875   &lt;NA&gt; 2009\n270    Gentoo    Biscoe     48.8     16.2         222      6000   male 2009\n271    Gentoo    Biscoe     47.2     13.7         214      4925 female 2009\n272    Gentoo    Biscoe       NA       NA          NA        NA   &lt;NA&gt; 2009\n273    Gentoo    Biscoe     46.8     14.3         215      4850 female 2009\n274    Gentoo    Biscoe     50.4     15.7         222      5750   male 2009\n275    Gentoo    Biscoe     45.2     14.8         212      5200 female 2009\n276    Gentoo    Biscoe     49.9     16.1         213      5400   male 2009\n277 Chinstrap     Dream     46.5     17.9         192      3500 female 2007\n278 Chinstrap     Dream     50.0     19.5         196      3900   male 2007\n279 Chinstrap     Dream     51.3     19.2         193      3650   male 2007\n280 Chinstrap     Dream     45.4     18.7         188      3525 female 2007\n281 Chinstrap     Dream     52.7     19.8         197      3725   male 2007\n282 Chinstrap     Dream     45.2     17.8         198      3950 female 2007\n283 Chinstrap     Dream     46.1     18.2         178      3250 female 2007\n284 Chinstrap     Dream     51.3     18.2         197      3750   male 2007\n285 Chinstrap     Dream     46.0     18.9         195      4150 female 2007\n286 Chinstrap     Dream     51.3     19.9         198      3700   male 2007\n287 Chinstrap     Dream     46.6     17.8         193      3800 female 2007\n288 Chinstrap     Dream     51.7     20.3         194      3775   male 2007\n289 Chinstrap     Dream     47.0     17.3         185      3700 female 2007\n290 Chinstrap     Dream     52.0     18.1         201      4050   male 2007\n291 Chinstrap     Dream     45.9     17.1         190      3575 female 2007\n292 Chinstrap     Dream     50.5     19.6         201      4050   male 2007\n293 Chinstrap     Dream     50.3     20.0         197      3300   male 2007\n294 Chinstrap     Dream     58.0     17.8         181      3700 female 2007\n295 Chinstrap     Dream     46.4     18.6         190      3450 female 2007\n296 Chinstrap     Dream     49.2     18.2         195      4400   male 2007\n297 Chinstrap     Dream     42.4     17.3         181      3600 female 2007\n298 Chinstrap     Dream     48.5     17.5         191      3400   male 2007\n299 Chinstrap     Dream     43.2     16.6         187      2900 female 2007\n300 Chinstrap     Dream     50.6     19.4         193      3800   male 2007\n301 Chinstrap     Dream     46.7     17.9         195      3300 female 2007\n302 Chinstrap     Dream     52.0     19.0         197      4150   male 2007\n303 Chinstrap     Dream     50.5     18.4         200      3400 female 2008\n304 Chinstrap     Dream     49.5     19.0         200      3800   male 2008\n305 Chinstrap     Dream     46.4     17.8         191      3700 female 2008\n306 Chinstrap     Dream     52.8     20.0         205      4550   male 2008\n307 Chinstrap     Dream     40.9     16.6         187      3200 female 2008\n308 Chinstrap     Dream     54.2     20.8         201      4300   male 2008\n309 Chinstrap     Dream     42.5     16.7         187      3350 female 2008\n310 Chinstrap     Dream     51.0     18.8         203      4100   male 2008\n311 Chinstrap     Dream     49.7     18.6         195      3600   male 2008\n312 Chinstrap     Dream     47.5     16.8         199      3900 female 2008\n313 Chinstrap     Dream     47.6     18.3         195      3850 female 2008\n314 Chinstrap     Dream     52.0     20.7         210      4800   male 2008\n315 Chinstrap     Dream     46.9     16.6         192      2700 female 2008\n316 Chinstrap     Dream     53.5     19.9         205      4500   male 2008\n317 Chinstrap     Dream     49.0     19.5         210      3950   male 2008\n318 Chinstrap     Dream     46.2     17.5         187      3650 female 2008\n319 Chinstrap     Dream     50.9     19.1         196      3550   male 2008\n320 Chinstrap     Dream     45.5     17.0         196      3500 female 2008\n321 Chinstrap     Dream     50.9     17.9         196      3675 female 2009\n322 Chinstrap     Dream     50.8     18.5         201      4450   male 2009\n323 Chinstrap     Dream     50.1     17.9         190      3400 female 2009\n324 Chinstrap     Dream     49.0     19.6         212      4300   male 2009\n325 Chinstrap     Dream     51.5     18.7         187      3250   male 2009\n326 Chinstrap     Dream     49.8     17.3         198      3675 female 2009\n327 Chinstrap     Dream     48.1     16.4         199      3325 female 2009\n328 Chinstrap     Dream     51.4     19.0         201      3950   male 2009\n329 Chinstrap     Dream     45.7     17.3         193      3600 female 2009\n330 Chinstrap     Dream     50.7     19.7         203      4050   male 2009\n331 Chinstrap     Dream     42.5     17.3         187      3350 female 2009\n332 Chinstrap     Dream     52.2     18.8         197      3450   male 2009\n333 Chinstrap     Dream     45.2     16.6         191      3250 female 2009\n334 Chinstrap     Dream     49.3     19.9         203      4050   male 2009\n335 Chinstrap     Dream     50.2     18.8         202      3800   male 2009\n336 Chinstrap     Dream     45.6     19.4         194      3525 female 2009\n337 Chinstrap     Dream     51.9     19.5         206      3950   male 2009\n338 Chinstrap     Dream     46.8     16.5         189      3650 female 2009\n339 Chinstrap     Dream     45.7     17.0         195      3650 female 2009\n340 Chinstrap     Dream     55.8     19.8         207      4000   male 2009\n341 Chinstrap     Dream     43.5     18.1         202      3400 female 2009\n342 Chinstrap     Dream     49.6     18.2         193      3775   male 2009\n343 Chinstrap     Dream     50.8     19.0         210      4100   male 2009\n344 Chinstrap     Dream     50.2     18.7         198      3775 female 2009"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html#question-2",
    "href": "problem-set-keys/ps-key-03.html#question-2",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 2",
    "text": "Question 2\nUse arrange, filter, and select on a data frame. Let’s build this step by step to understand how pipes work:\n\nImport the data set data/data_transcript_exp_tidy.csv using read_csv() and here().\n\nStep 2a: First, just sort the tibble by expression data (count) from highest to lowest level using arrange(). Use desc() to get descending order.\n\nStep 2b: Then add filter() to keep only rows where count &gt; 100. Chain this with the pipe operator.\n\nStep 2c: Finally, add select() to choose all columns except for type. Use the - operator to exclude columns.\n\n\nexp_tbl &lt;- read_csv(here(\"data/bootcamp/data_transcript_exp_tidy.csv.gz\"))\n\nRows: 600 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ensembl_transcript_id, type, time, replicate\ndbl (1): count\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Step 2a: Just arrange first\nexp_tbl |&gt;\n  arrange(desc(count)) # desc() for descending order\n\n# A tibble: 600 × 5\n   ensembl_transcript_id      type  time  replicate count\n   &lt;chr&gt;                      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 ENST00000234590.8_121_1423 rna   0h    rep2      11144\n 2 ENST00000234590.8_121_1423 rna   0h    rep3      10619\n 3 ENST00000234590.8_121_1423 rna   0h    rep1       9802\n 4 ENST00000234590.8_121_1423 rna   14h   rep3       6012\n 5 ENST00000234590.8_121_1423 rna   14h   rep1       5292\n 6 ENST00000234590.8_121_1423 rna   14h   rep2       5090\n 7 ENST00000377482.9_300_1611 rna   14h   rep1       1396\n 8 ENST00000377482.9_300_1611 rna   0h    rep2       1377\n 9 ENST00000377482.9_300_1611 rna   0h    rep1       1311\n10 ENST00000377482.9_300_1611 rna   0h    rep3       1244\n# ℹ 590 more rows\n\n# Step 2b: Add the filter\nexp_tbl |&gt;\n  arrange(desc(count)) |&gt;\n  filter(count &gt; 100)\n\n# A tibble: 109 × 5\n   ensembl_transcript_id      type  time  replicate count\n   &lt;chr&gt;                      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 ENST00000234590.8_121_1423 rna   0h    rep2      11144\n 2 ENST00000234590.8_121_1423 rna   0h    rep3      10619\n 3 ENST00000234590.8_121_1423 rna   0h    rep1       9802\n 4 ENST00000234590.8_121_1423 rna   14h   rep3       6012\n 5 ENST00000234590.8_121_1423 rna   14h   rep1       5292\n 6 ENST00000234590.8_121_1423 rna   14h   rep2       5090\n 7 ENST00000377482.9_300_1611 rna   14h   rep1       1396\n 8 ENST00000377482.9_300_1611 rna   0h    rep2       1377\n 9 ENST00000377482.9_300_1611 rna   0h    rep1       1311\n10 ENST00000377482.9_300_1611 rna   0h    rep3       1244\n# ℹ 99 more rows\n\n# Step 2c: Add the select (use -type to exclude the type column)\nexp_tbl |&gt;\n  arrange(desc(count)) |&gt;\n  filter(count &gt; 100) |&gt;\n  select(-type)\n\n# A tibble: 109 × 4\n   ensembl_transcript_id      time  replicate count\n   &lt;chr&gt;                      &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 ENST00000234590.8_121_1423 0h    rep2      11144\n 2 ENST00000234590.8_121_1423 0h    rep3      10619\n 3 ENST00000234590.8_121_1423 0h    rep1       9802\n 4 ENST00000234590.8_121_1423 14h   rep3       6012\n 5 ENST00000234590.8_121_1423 14h   rep1       5292\n 6 ENST00000234590.8_121_1423 14h   rep2       5090\n 7 ENST00000377482.9_300_1611 14h   rep1       1396\n 8 ENST00000377482.9_300_1611 0h    rep2       1377\n 9 ENST00000377482.9_300_1611 0h    rep1       1311\n10 ENST00000377482.9_300_1611 0h    rep3       1244\n# ℹ 99 more rows"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html#question-3",
    "href": "problem-set-keys/ps-key-03.html#question-3",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 3",
    "text": "Question 3\nHow will you:\n\ncreate a new column log10count that contains log10 transformed count values using mutate() and log10() and\nrearrange the columns in the following order: ensembl_transcript_id, type, time, replicate, count, log10count using select().\n\nBefore showing the solution, remember: - mutate() adds new columns (or modifies existing ones) - it keeps all existing columns - select() chooses columns and can reorder them - list them in the order you want\n\nexp_tbl |&gt;\n  mutate(log10count = log10(count)) |&gt;\n  select(ensembl_transcript_id, type, time, replicate, count, log10count)\n\n# A tibble: 600 × 6\n   ensembl_transcript_id      type  time  replicate count log10count\n   &lt;chr&gt;                      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 ENST00000327044.6_51_2298  rna   0h    rep1        243      2.39 \n 2 ENST00000327044.6_51_2298  rna   0h    rep2        322      2.51 \n 3 ENST00000327044.6_51_2298  rna   0h    rep3        303      2.48 \n 4 ENST00000327044.6_51_2298  rna   14h   rep1        177      2.25 \n 5 ENST00000327044.6_51_2298  rna   14h   rep2        177      2.25 \n 6 ENST00000327044.6_51_2298  rna   14h   rep3        239      2.38 \n 7 ENST00000338591.7_360_2034 rna   0h    rep1         19      1.28 \n 8 ENST00000338591.7_360_2034 rna   0h    rep2         17      1.23 \n 9 ENST00000338591.7_360_2034 rna   0h    rep3         15      1.18 \n10 ENST00000338591.7_360_2034 rna   14h   rep1          9      0.954\n# ℹ 590 more rows"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html#question-4",
    "href": "problem-set-keys/ps-key-03.html#question-4",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 4",
    "text": "Question 4\nLet’s explore grouping operations step by step. We’ll build your understanding progressively, starting with simple examples and then combining concepts.\nStep 4a: First, try a simple grouping operation. Calculate the total count per transcript (ignoring time). Use:\n\n\ngroup_by() to group by transcript ID\n\nsummarize() to calculate the sum of counts\n\n.groups = \"drop\" to remove grouping afterward (good practice!)\n\n\n# Simple grouping - sum counts for each transcript across all conditions\nexp_tbl |&gt;\n  group_by(ensembl_transcript_id) |&gt;\n  summarize(\n    total_count = sum(count),\n    .groups = \"drop\" # This removes the grouping afterward - good practice!\n  )\n\n# A tibble: 100 × 2\n   ensembl_transcript_id        total_count\n   &lt;chr&gt;                              &lt;dbl&gt;\n 1 ENST00000054650.8_159_876           50.3\n 2 ENST00000054666.10_116_416         728  \n 3 ENST00000054668.5_220_418           22.5\n 4 ENST00000234590.8_121_1423       47959  \n 5 ENST00000263741.11_1328_1496       176. \n 6 ENST00000263741.11_315_1338        845  \n 7 ENST00000270708.11_75_1455         274  \n 8 ENST00000288774.7_29_1067           96.5\n 9 ENST00000291386.3_370_895          805  \n10 ENST00000307896.10_39_753           50.3\n# ℹ 90 more rows\n\n\nStep 4b: Now calculate a per-transcript sum, while keeping the time information (group by both transcript and time). This creates separate groups for each combination of transcript AND time:\n\nexp_tbl |&gt;\n  group_by(ensembl_transcript_id, time) |&gt;\n  summarize(\n    count_sum = sum(count),\n    .groups = \"drop\"\n  )\n\n# A tibble: 200 × 3\n   ensembl_transcript_id        time  count_sum\n   &lt;chr&gt;                        &lt;chr&gt;     &lt;dbl&gt;\n 1 ENST00000054650.8_159_876    0h         33.8\n 2 ENST00000054650.8_159_876    14h        16.5\n 3 ENST00000054666.10_116_416   0h        447  \n 4 ENST00000054666.10_116_416   14h       281  \n 5 ENST00000054668.5_220_418    0h          0  \n 6 ENST00000054668.5_220_418    14h        22.5\n 7 ENST00000234590.8_121_1423   0h      31565  \n 8 ENST00000234590.8_121_1423   14h     16394  \n 9 ENST00000263741.11_1328_1496 0h         97.5\n10 ENST00000263741.11_1328_1496 14h        79  \n# ℹ 190 more rows"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html#question-5",
    "href": "problem-set-keys/ps-key-03.html#question-5",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 5",
    "text": "Question 5\nCreate meaningful categories from your data using case_when(). This function lets you create new variables based on multiple conditions\nCategorize the expression levels in the count column into meaningful groups:\n\n“Low” for counts less than 50\n“Medium” for counts between 50 and 200 (inclusive of 50, exclusive of 200)\n“High” for counts between 200 and 1000 (inclusive of 200, exclusive of 1000)\n“Very High” for counts 1000 and above\n\nUse case_when() inside mutate() to create a new column called expression_level, then use count() to see how many transcripts fall into each category.\n\n# Categorize expression levels into meaningful groups\nexp_tbl |&gt;\n  mutate(\n    expression_level = case_when(\n      count &lt; 50 ~ \"Low\",\n      count &lt; 200 ~ \"Medium\",\n      count &lt; 1000 ~ \"High\",\n      count &gt;= 1000 ~ \"Very High\",\n      .default = \"undetermined\" # in case of NA values\n    )\n  ) |&gt;\n  count(expression_level, sort = TRUE)\n\n# A tibble: 4 × 2\n  expression_level     n\n  &lt;chr&gt;            &lt;int&gt;\n1 Low                413\n2 Medium             150\n3 High                25\n4 Very High           12"
  },
  {
    "objectID": "problem-sets/ps-01.html",
    "href": "problem-sets/ps-01.html",
    "title": "Problem Set 1 Key",
    "section": "",
    "text": "Each problem below is worth 5 points.\nThe problem set is due 12pm on Aug 26.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-sets/ps-01.html#problem-set",
    "href": "problem-sets/ps-01.html#problem-set",
    "title": "Problem Set 1 Key",
    "section": "",
    "text": "Each problem below is worth 5 points.\nThe problem set is due 12pm on Aug 26.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-sets/ps-01.html#setup",
    "href": "problem-sets/ps-01.html#setup",
    "title": "Problem Set 1 Key",
    "section": "Setup",
    "text": "Setup\nStart by loading libraries you need analysis below. When in doubt, start by loading the tidyverse package.\n\nlibrary(___)"
  },
  {
    "objectID": "problem-sets/ps-01.html#question-1",
    "href": "problem-sets/ps-01.html#question-1",
    "title": "Problem Set 1 Key",
    "section": "Question 1",
    "text": "Question 1\nCreate 3 different vectors called x, y, and z:\n\n\nx should be character vector of length 5 (hint: use LETTERS or letters)\n\ny should be a numeric vector of length 5 (hint: try 1:5 or c(1, 2, 3, 4, 5))\n\nz should be a logical vector of length 5 (hint: use TRUE and FALSE values)\n\nUse length() to calculate the length of each vector."
  },
  {
    "objectID": "problem-sets/ps-01.html#question-2",
    "href": "problem-sets/ps-01.html#question-2",
    "title": "Problem Set 1 Key",
    "section": "Question 2",
    "text": "Question 2\nUsing the vectors you created above, create a new tibble with column names x, y, and z. Use the tibble() function to combine your vectors into a data frame.\nUse nrow() and ncol() to calculate the number of rows and columns, both with and without the pipe operator.\nUse glimpse() to get a quick overview of your tibble - this shows data types and first few values.\nWhat do you notice about the length of the vectors and the number of rows?\n\ntbl &lt;- tibble(___)\n\nnrow(___)\nncol(___)\n\n# Get a quick overview\nglimpse(___)\n\nAnswer\nThe length of the vectors and the number of rows are the same, because tibble columns are simply the vectors we started with."
  },
  {
    "objectID": "problem-sets/ps-01.html#question-3",
    "href": "problem-sets/ps-01.html#question-3",
    "title": "Problem Set 1 Key",
    "section": "Question 3",
    "text": "Question 3\nLet’s explore the penguins dataset that we loaded.\n\nLook at the number of rows with nrow() - this tells us how many penguins are in the dataset\nLook at the number of columns with ncol() - this tells us how many variables we measured\nLook at the column names with names() - this shows us what variables we have\nGet a glimpse of the data with glimpse() - this shows data types and sample values\n\n\n# Explore the penguins dataset\nnrow(___)\nncol(___)\nnames(___)\nglimpse(___)"
  },
  {
    "objectID": "problem-sets/ps-01.html#question-4",
    "href": "problem-sets/ps-01.html#question-4",
    "title": "Problem Set 1 Key",
    "section": "Question 4",
    "text": "Question 4\nNext we will think about data tidying. Let’s start by analyzing the penguins dataset.\nPart A: Is the penguins dataset tidy? To determine this, we need to think about the three principles of tidy data:\n\nEach variable forms a column\nEach observation forms a row\nEach type of observational unit forms a table\n\nLook at the penguins dataset and answer:\n\nWhat are the variables in the dataset? (Hint: use names(penguins) to see them)\nDoes each column represent a single variable?\nDoes each row represent a single penguin observation?\n\nPart B: Now let’s examine some datasets that are NOT tidy. Use data() to see available datasets, then look at these two examples:\nExample 1: anscombe - This is a classic statistics dataset.\n\n# Look at the anscombe dataset. Start by reading the help page with `?anscombe`\n\nIs anscombe tidy? Think about:\n\nWhat are the actual variables? (Hint: x and y coordinates for different datasets)\nHow many different datasets are encoded in the column names?\nWhat would a tidy version look like?\n\nExample 2: Choose another dataset - Pick one more dataset from data() and analyze whether it’s tidy:\n\n# Look at available datasets\ndata()\n\nIs this other data set tidy? Think about:\n\nWhat are the actual variables? (Hint: x and y coordinates for different datasets)\nHow many different datasets are encoded in the column names?\nWhat would a tidy version look like?\n\nPart C: Write a brief explanation (2-3 sentences) for each dataset about:\n\nWhether it’s tidy or not\nWhat makes it tidy/untidy\nWhat the variables actually represent\n\nYour Analysis:\npenguins: [Your answer here]\nanscombe: [Your answer here]\n[Your chosen dataset]: [Your answer here]"
  },
  {
    "objectID": "problem-sets/ps-01.html#submit",
    "href": "problem-sets/ps-01.html#submit",
    "title": "Problem Set 1 Key",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of the Posit Cloud project (NOT the HTML link) into the problem set on Canvas."
  },
  {
    "objectID": "problem-sets/ps-03.html",
    "href": "problem-sets/ps-03.html",
    "title": "R Bootcamp Problem Set 3",
    "section": "",
    "text": "Start by loading libraries you need analysis in the code chunk below. When in doubt, start by loading the tidyverse package."
  },
  {
    "objectID": "problem-sets/ps-03.html#setup",
    "href": "problem-sets/ps-03.html#setup",
    "title": "R Bootcamp Problem Set 3",
    "section": "",
    "text": "Start by loading libraries you need analysis in the code chunk below. When in doubt, start by loading the tidyverse package."
  },
  {
    "objectID": "problem-sets/ps-03.html#problem-set",
    "href": "problem-sets/ps-03.html#problem-set",
    "title": "R Bootcamp Problem Set 3",
    "section": "Problem Set",
    "text": "Problem Set\nEach problem below is worth 5 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Aug 28.\nGrading rubric\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-sets/ps-03.html#question-1",
    "href": "problem-sets/ps-03.html#question-1",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 1",
    "text": "Question 1\nLoad the palmerpenguins package (already done above). Inspect the penguins tibble with summary() to see the distribution of variables and any missing values.\nUse drop_na() to remove rows with NA values in the penguins tibble. Calculate how many rows were removed by subtracting the new count from the original count using nrow().\nThen, use count() to explore the data and see how many penguins of each species we have. This is a simple but powerful way to understand your data!\nThen, use replace_na() to replace NA values in bill_length_mm and bill_depth_mm with a value of 0. You’ll need to:\n\nProvide the data frame as the first argument\nProvide a named list showing which columns to replace and what values to use"
  },
  {
    "objectID": "problem-sets/ps-03.html#question-2",
    "href": "problem-sets/ps-03.html#question-2",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 2",
    "text": "Question 2\nUse arrange, filter, and select on a data frame. Let’s build this step by step to understand how pipes work:\n\nImport the data set data/data_transcript_exp_tidy.csv using read_csv() and here().\n\nStep 2a: First, just sort the tibble by expression data (count) from highest to lowest level using arrange(). Use desc() to get descending order.\n\nStep 2b: Then add filter() to keep only rows where count &gt; 100. Chain this with the pipe operator.\n\nStep 2c: Finally, add select() to choose all columns except for type. Use the - operator to exclude columns."
  },
  {
    "objectID": "problem-sets/ps-03.html#question-3",
    "href": "problem-sets/ps-03.html#question-3",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 3",
    "text": "Question 3\nHow will you:\n\ncreate a new column log10count that contains log10 transformed count values using mutate() and log10() and\nrearrange the columns in the following order: ensembl_transcript_id, type, time, replicate, count, log10count using select().\n\nBefore showing the solution, remember: - mutate() adds new columns (or modifies existing ones) - it keeps all existing columns - select() chooses columns and can reorder them - list them in the order you want"
  },
  {
    "objectID": "problem-sets/ps-03.html#question-4",
    "href": "problem-sets/ps-03.html#question-4",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 4",
    "text": "Question 4\nLet’s explore grouping operations step by step. We’ll build your understanding progressively, starting with simple examples and then combining concepts.\nStep 4a: First, try a simple grouping operation. Calculate the total count per transcript (ignoring time). Use:\n\n\ngroup_by() to group by transcript ID\n\nsummarize() to calculate the sum of counts\n\n.groups = \"drop\" to remove grouping afterward (good practice!)\n\nStep 4b: Now calculate a per-transcript sum, while keeping the time information (group by both transcript and time). This creates separate groups for each combination of transcript AND time:"
  },
  {
    "objectID": "problem-sets/ps-03.html#question-5",
    "href": "problem-sets/ps-03.html#question-5",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 5",
    "text": "Question 5\nCreate meaningful categories from your data using case_when(). This function lets you create new variables based on multiple conditions - it’s like a more powerful version of if_else().\nCategorize the expression levels in the count column into meaningful groups: - “Low” for counts less than 50 - “Medium” for counts between 50 and 200 (inclusive of 50, exclusive of 200) - “High” for counts between 200 and 1000 (inclusive of 200, exclusive of 1000) - “Very High” for counts 1000 and above\nUse case_when() inside mutate() to create a new column called expression_level, then use count() to see how many transcripts fall into each category."
  },
  {
    "objectID": "problem-sets/ps-03.html#question-6",
    "href": "problem-sets/ps-03.html#question-6",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 6",
    "text": "Question 6\nTry to state and answer a new question! Stitch together several dplyr fuctions to answer a new question. I’m trying to wean you off the fill-in-the-blanks approach and get you to think independently using the tidyverse.\nHere are some ideas to get you started, you don’t have to use any of them:\n\nWhich transcript has the highest expression level at each time point? (Hint: use dplyr::slice_max() after grouping by time)\nWhat is the average expression level for each transcript across all time points? (Hint: use group_by() and summarize())\nWhich time point has the highest total expression level across all transcripts? (Hint: group by time and summarize total count)"
  },
  {
    "objectID": "problem-sets/ps-05.html",
    "href": "problem-sets/ps-05.html",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "",
    "text": "Your objective is to create some new extreme art using R, something either ugly or sublime. What you cannot do is be boring; your goal is to stay on the fringe.\nYour submission (a Quarto .qmd file) is due Tues Sept 2 by 5pm. If you submit an entry, you get full credit on the problem set. Entries will be anonymized and winners will selected by popular vote."
  },
  {
    "objectID": "problem-sets/ps-05.html#extreme-art-objective",
    "href": "problem-sets/ps-05.html#extreme-art-objective",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "",
    "text": "Your objective is to create some new extreme art using R, something either ugly or sublime. What you cannot do is be boring; your goal is to stay on the fringe.\nYour submission (a Quarto .qmd file) is due Tues Sept 2 by 5pm. If you submit an entry, you get full credit on the problem set. Entries will be anonymized and winners will selected by popular vote."
  },
  {
    "objectID": "problem-sets/ps-05.html#favorite-rtists",
    "href": "problem-sets/ps-05.html#favorite-rtists",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "Favorite Rtists",
    "text": "Favorite Rtists\nHere are some of my favorite generative artists who use R. Be inspired!\n\nDanielle Navarro [Art] [Github]\n\nIjeamaka Anyene [Github] and this study in particular.\nClaus Wilke [Art] [Github], a biologist at UT Austin who also wrote the book on data visualization (it’s excellent).\nThomas Lin Pederesen [Art] [Github]. I have some of his pieces in my office.\ninconvergent [Art] [Github]. It’s lisp, not R. But it’s so good.\n\nThere are several resources for color palettes, an important component of any hideous or beautiful creation.\n\nThe section in Data Viz for R on color is worth a read.\nThe colors in e.g. scale_color_brewer come from Cynthia Brewer, a cartographer who makes visually informative maps.\n\ncolor-hex has collections of complementary color palettes.\n\nThere are also several R packages that might help you build Rtistic plots.\n\n\ngganimate provides tools to bring your plots to life.\n\nggforce provides interesting geoms that build on ggplot2.\n\npatchwork provides layout functions for plots."
  },
  {
    "objectID": "problem-sets/ps-05.html#informative-but-boring.",
    "href": "problem-sets/ps-05.html#informative-but-boring.",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "Informative, but boring.",
    "text": "Informative, but boring.\nThis is an informative but relatively boring plot. NOT THE GOAL HERE.\n\nCodelibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(cowplot)\n\npenguins_clean &lt;- drop_na(penguins)\n\nggplot(\n  penguins_clean,\n  aes(\n    x = body_mass_g / 1000,\n    y = bill_length_mm\n  )\n) +\n  geom_point(\n    aes(\n      shape = sex,\n      color = species\n    )\n  ) +\n  facet_grid(~island) +\n  theme_minimal_grid() +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(\n    title = \"Analysis of geographic isolation on penguin phenotypes\",\n    x = \"Body mass (kg)\",\n    y = \"Bill length (mm)\"\n  )"
  },
  {
    "objectID": "problem-sets/ps-05.html#ugly-plots",
    "href": "problem-sets/ps-05.html#ugly-plots",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "Ugly Plots",
    "text": "Ugly Plots\nYikes. We can thank Yunus Ozekin for this abomination.\n\nCodelibrary(tidyverse)\ntitanic_tbl &lt;- as_tibble(Titanic)\n\nggplot(\n  titanic_tbl,\n  aes(\n    x = Survived,\n    y = n,\n    color = Class,\n    shape = Sex,\n    size = 6\n  )\n) +\n  geom_jitter() +\n  scale_y_sqrt() +\n  labs(\n    x = \"Not Dead?\",\n    y = \"How many? (ppl)\",\n    title = \"WhO dIEd In titaNic?\",\n    caption = \"Some lived, some died.\"\n  ) +\n  scale_x_discrete(position = \"top\") +\n  theme(\n    axis.text.x = element_text(\n      face = \"bold.italic\",\n      color = \"#993333\",\n      size = 18,\n      angle = 180\n    ),\n    axis.text.y = element_text(\n      face = \"bold\",\n      color = \"orange\",\n      size = 18,\n      angle = 135\n    ),\n    plot.background = element_rect(fill = \"darkblue\"),\n    plot.title = element_text(\n      face = \"italic\",\n      color = \"green\",\n      size = 48,\n      angle = 183\n    ),\n    plot.caption = element_text(color = \"white\", size = 22),\n    axis.title.x = element_text(size = 22, color = \"pink\", angle = 12),\n    axis.title.y = element_text(color = \"yellow\", angle = 273, size = 17),\n    legend.background = element_rect(fill = \"yellow\"),\n    legend.title = element_text(\n      angle = 71,\n      face = \"bold\",\n      color = \"purple\",\n      size = 12\n    ),\n    legend.key = element_rect(color = \"green\", fill = \"orange\"),\n    legend.text = element_text(color = \"red\", size = 14),\n    panel.background = element_rect(fill = \"yellow\"),\n    panel.grid.major.y = element_line(\n      color = \"green\",\n      linetype = \"dotdash\",\n      linewidth = 1.2\n    ),\n    panel.grid.major.x = element_line(\n      color = \"purple\",\n      linewidth = 3,\n      linetype = \"twodash\"\n    ),\n    panel.grid.minor = element_line(\n      color = \"red\",\n      linewidth = 2,\n      linetype = \"dashed\"\n    ),\n    legend.position = \"bottom\"\n  )"
  },
  {
    "objectID": "problem-sets/ps-05.html#beautiful-plots",
    "href": "problem-sets/ps-05.html#beautiful-plots",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "Beautiful Plots",
    "text": "Beautiful Plots\nThis is a piece from Ijeamaka Anyene’s ode to coord_polar() (link above). Reminds me of Miro.\n\nCodelibrary(tidyverse)\n\napply_pattern_theme &lt;- function(bg_hex, caption_hex) {\n  theme(\n    plot.background = element_rect(fill = bg_hex),\n    panel.background = element_rect(fill = bg_hex),\n    panel.grid = element_blank(),\n    plot.caption = element_text(\n      family = \"Open Sans\",\n      size = 6,\n      color = caption_hex\n    ),\n    legend.position = \"none\",\n    axis.title = element_blank(),\n    axis.text = element_blank(),\n    axis.ticks = element_blank()\n  )\n}\n\noutline &lt;- tibble(\n  x = 1,\n  xend = 7,\n  y = 15,\n  yend = 15\n)\nsegment_line &lt;- tibble(\n  x = c(1, 7),\n  xend = c(1, 7),\n  y = c(0, 2),\n  yend = 15\n)\narea &lt;- tibble(\n  x = c(3, 5, 6),\n  y = c(5, 7.5, 2),\n  type = LETTERS[1:3]\n)\npalette_values &lt;- c(\"#2a2640\", \"#a64e46\", \"#f29544\")\nggplot() +\n  geom_col(\n    data = area,\n    aes(x = x, y = y, fill = type),\n    alpha = 0.75,\n    width = 4\n  ) +\n  geom_segment(\n    data = outline,\n    aes(\n      x = x,\n      y = y,\n      xend = xend,\n      yend = yend\n    ),\n    size = 0.5\n  ) +\n  geom_segment(\n    data = segment_line,\n    aes(\n      x = x,\n      xend = xend,\n      y = y,\n      yend = yend\n    ),\n    size = 0.5\n  ) +\n  geom_point(aes(x = 5, y = 0)) +\n  scale_fill_manual(values = palette_values) +\n  scale_y_continuous(limits = c(0, 15)) +\n  scale_x_continuous(limits = c(1, 10)) +\n  coord_polar() +\n  labs(caption = \"Ijeamaka Anyene | @ijeamaka_a\") +\n  apply_pattern_theme(\n    bg_hex = \"#ded5c9\",\n    caption_hex = \"black\"\n  )\n\n\n\n\n\n\n\nHere’s another more complex geometric creation, again using coord_polar(). This will take a few seconds to render.\n\nCode# https://twitter.com/aschinchon/status/1095057262744387587\nlibrary(tidyverse)\n\nxy &lt;- seq(-2, 2, by = .005)\nexpand.grid(x = xy, y = xy) |&gt;\n  ggplot(\n    aes(\n      x = (cos(x)^2 + sin(y^2)),\n      y = (sin(y)^3 - cos(x^2))\n    )\n  ) +\n  geom_point(alpha = .01, shape = 20, size = 0) +\n  theme_void() +\n  coord_polar()"
  },
  {
    "objectID": "problem-sets/ps-11.html",
    "href": "problem-sets/ps-11.html",
    "title": "Problem Set Stats Bootcamp - class 11",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\nAttaching package: 'cowplot'\n\n\nThe following object is masked from 'package:lubridate':\n\n    stamp"
  },
  {
    "objectID": "problem-sets/ps-11.html#problem-1",
    "href": "problem-sets/ps-11.html#problem-1",
    "title": "Problem Set Stats Bootcamp - class 11",
    "section": "Problem # 1",
    "text": "Problem # 1\nAssume that the height jackalopes fit a normal distribution. Through careful field research measuring 1000 wild jackalopes, we have determined the mean height is 97 cm and the standard deviation is 10 cm. Your was camping and found a jackalope. Being a great friend and knowing your interest in jackalopes, they (harmlessly) subdued and measured the wild jackalope and found that it was 75 cm.\n\nSimulate a normal distribution of 1000 jackalope heights using the mean and sd you painstakingly measured.\n\n\nPlot the density of the jackalope height distribution. Indicate with a vertical line the height of the jackalope your friend measured.\n\n\nCalculate the probability of a jackalope being 75 cm or shorter.\n\n\nAre jackalope heights normally distributed?"
  },
  {
    "objectID": "problem-sets/ps-11.html#explore-coin-flip-distribution-characteristics",
    "href": "problem-sets/ps-11.html#explore-coin-flip-distribution-characteristics",
    "title": "Problem Set Stats Bootcamp - class 11",
    "section": "Explore coin flip distribution characteristics",
    "text": "Explore coin flip distribution characteristics\nWhen we flip a fair coin multiple times (numFlips) in a row, we expect to get heads (or tails) 50% of the time on average. This is not always the case for a single round of flipping, but if we do multiple rounds with (numRounds) that average should be 50%."
  },
  {
    "objectID": "problem-sets/ps-11.html#problem-2",
    "href": "problem-sets/ps-11.html#problem-2",
    "title": "Problem Set Stats Bootcamp - class 11",
    "section": "Problem # 2",
    "text": "Problem # 2\nIn class, we simulated coin flip experiments using two different coins that were either fair (0.5 prob of head) or unfair (0.9 prob of head). We varied the number of flips in a single round (numFlips) and the number of rounds of flipping (numRounds). For this assignment, use the same to coins and use all possible combinations of numFlips and numRounds from the table below.\n\nparameters to explore\n\nnumFlips\nnumRounds\n\n\n\n5\n10\n\n\n500\n100\n\n\n\n\nCreate a tibble has all the combinations of numFlips, numRounds, and prob of getting heads.\n\n\n# hint for 8 flips and 12 rounds of a fair coin you could do\n# rbinom(n = 8, size = 12, prob = .5)/12\n\n\nPlot your result using faceting. I recommend faceting by numFlips (like in class describing both the number and fair v unfair) . Include the observed mean as a black diamond and the true mean as a dashed line.\n\n3. Report the means and sd of each pair of numFlips and numRounds\n4. Describe in a few sentences how increasing numFlips and numRounds alters:\nThe estimation of and spread around the true mean."
  },
  {
    "objectID": "problem-sets/ps-13.html",
    "href": "problem-sets/ps-13.html",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\nAttaching package: 'janitor'\n\n\nThe following object is masked from 'package:rstatix':\n\n    make_clean_names\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nhere() starts at /home/runner/work/molb-7950/molb-7950\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1, 6, 9, 14, 15, 24:28)]\nbiochem &lt;- biochem[, keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\", \"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename gender to sex\nb &lt;- inner_join(biochem, weight, by = \"subject_name\") |&gt;\n  na.omit() |&gt;\n  rename(sex = gender)"
  },
  {
    "objectID": "problem-sets/ps-13.html#problem-1",
    "href": "problem-sets/ps-13.html#problem-1",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Problem # 1",
    "text": "Problem # 1\nIs there an association between mouse calcium and sodium levels?\n1. Make a scatterplot to inspect variable\n2. Are they normal (enough)?\nWhich test will you use and why?\n\n\n\n3. Declare null hypothesis \\(\\mathcal{H}_0\\)\n\n\\(\\mathcal{H}_0\\) is that there is no dependency/association between \\(calcium\\) and \\(sodium\\)\n4. Calculate and plot the correlation on a scatterplot"
  },
  {
    "objectID": "problem-sets/ps-13.html#problem-2",
    "href": "problem-sets/ps-13.html#problem-2",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Problem # 2",
    "text": "Problem # 2"
  },
  {
    "objectID": "problem-sets/ps-13.html#do-mouse-calcium-levels-explain-mouse-sodium-levels-if-so-to-what-extent",
    "href": "problem-sets/ps-13.html#do-mouse-calcium-levels-explain-mouse-sodium-levels-if-so-to-what-extent",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Do mouse calcium levels explain mouse sodium levels? If so, to what extent?",
    "text": "Do mouse calcium levels explain mouse sodium levels? If so, to what extent?\nUse a linear model to do the following:\n1. Specify the Response and Explanatory variables — (2 pts)\n\nThe response variable y is The explantory variable x is\n\n2. Declare the null hypothesis — (1 pts)\n\nThe null hypothesis is …\n\n3. Use the lm function to create a fit (linear model)\nalso save the slope and intercept for later\n4. Add residuals to the data and create a plot visualizing the residuals\n5. Calculate the \\(R^2\\) and compare to \\(R^2\\) from fit\n\\(R^2 = 1 - \\displaystyle \\frac {SS_{fit}}{SS_{null}}\\)\n\\(SS_{fit} = \\sum_{i=1}^{n} (data - line)^2 = \\sum_{i=1}^{n} (y_{i} - (\\beta_0 \\cdot 1+ \\beta_1 \\cdot x)^2\\)\n\\(SS_{null}\\) — sum of squared errors around the mean of \\(y\\)\n\\(SS_{null} = \\sum_{i=1}^{n} (data - mean)^2 = \\sum_{i=1}^{n} (y_{i} - \\overline{y})^2\\)\n6. Using \\(R^2\\), describe the extent to which calcium explains sodium levels\n\n\n\n7. Report (do not calculate) the \\(p-value\\) and your decision on the null\n\nThe null hypothesis is …\n\nCalcium levels to predict sodium levels."
  },
  {
    "objectID": "problem-sets/ps-13.html#problem-3",
    "href": "problem-sets/ps-13.html#problem-3",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Problem # 3",
    "text": "Problem # 3\nWhat is the association between mouse weight and age levels for different sexes?\n1. Calculate the pearson correlation coefficient between weight and age for females and males\n2. Describe your observations\n\nThe relationship between weight and age…"
  },
  {
    "objectID": "problem-sets/ps-15.html",
    "href": "problem-sets/ps-15.html",
    "title": "Problem Set Stats Bootcamp - class 15",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\nAttaching package: 'janitor'\n\n\nThe following object is masked from 'package:rstatix':\n\n    make_clean_names\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nhere() starts at /home/runner/work/molb-7950/molb-7950\nang &lt;- read_csv(here(\"data/bootcamp/edger.csv.gz\")) |&gt;\n  clean_names() |&gt;\n  filter(fdr &lt; 0.05) |&gt;\n  select(log_fc_time0_25:log_fc_time8) |&gt;\n  as.matrix()\n\ncolnames(ang) &lt;- gsub(pattern = \"log_fc_\", \"\", colnames(ang))"
  },
  {
    "objectID": "problem-sets/ps-15.html#problem-1",
    "href": "problem-sets/ps-15.html#problem-1",
    "title": "Problem Set Stats Bootcamp - class 15",
    "section": "Problem # 1",
    "text": "Problem # 1\nMake sure to run the chunk above. The data represent the avg fold change in gene expression for an angiotensin II time course (.25, .5, .75, 1, 1.5, 2, 3, 4, 6, 8, 24 hrs) compared to unstimulated."
  },
  {
    "objectID": "problem-sets/ps-15.html#correlation",
    "href": "problem-sets/ps-15.html#correlation",
    "title": "Problem Set Stats Bootcamp - class 15",
    "section": "correlation",
    "text": "correlation\nCreate hierarchical clustering heatmap of pairwise pearson correlation coefficients. And provide 1-2 observations.\n\n# scale\n\n# pairwise pearson correlation\n\n\n# make heatmap\n\nTimepoints close to each other tend to correlate strongly with each other. The 4,6, and 8 hr time points are the most different from all others."
  },
  {
    "objectID": "problem-sets/ps-15.html#pca",
    "href": "problem-sets/ps-15.html#pca",
    "title": "Problem Set Stats Bootcamp - class 15",
    "section": "PCA",
    "text": "PCA\nPerform PCA and visualize PC1 vs PC2.Provide 1-2 observations.\n\n# pca\n\n\n# gather info from summary\n\n\n\n\n# we make a dataframe out of the rotations and will use this to plot\n\n\n# plot"
  },
  {
    "objectID": "problem-sets/ps-15.html#calculate-the-empirical-p-value-of-the-cluster-most-enriched-for-dux4-targets-by-sampling",
    "href": "problem-sets/ps-15.html#calculate-the-empirical-p-value-of-the-cluster-most-enriched-for-dux4-targets-by-sampling",
    "title": "Problem Set Stats Bootcamp - class 15",
    "section": "Calculate the empirical p-value of the cluster most enriched for DUX4 targets by sampling",
    "text": "Calculate the empirical p-value of the cluster most enriched for DUX4 targets by sampling\nIn order to do this, you will need to:\n\nIdentify which cluster is the most enriched for DUX4 targets.\n\nDetermine how many genes are in the cluster. You will need to know this to figure out how many genes to sample from the whole data set.\nDetermine how many of the genes in the cluster are DUX4 targets. This is the metric that you are interested in comparing between the null distribution and your observation.\n\n\nGenerate 1000 random sample of the proper size from all genes and find out how many of them are DUX4 targets.\nVisualize the distribution of DUX4 targets in these 1000 random (your null distribution) and overlay the number of DUX4 targets you observed in the cluster that was most enriched for DUX4 targets.\n\n\n# read in data\ncd &lt;- read_tsv(here(\"data\", \"dux4_clustering_results.csv.gz\"))\n\nRows: 10566 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (2): gene_symbol, target\ndbl (13): hour00_rep1, hour00_rep2, hour00_rep3, hour04_rep1, hour04_rep2, h...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# how many genes are in cluster of interest?\n\n# how many dux targets are in cluster interest?\n\n\n\n# initialize empty vector\nsampled_targets &lt;- vector()\n\n# randomly sample # genes above from data 1000x and tally number of dux4 targets each random sampling\n\n\n\n# plot\n\nWhat is the p-value?\nWhat is your interpretation?"
  },
  {
    "objectID": "resources/block-rna-resources.html",
    "href": "resources/block-rna-resources.html",
    "title": "Resources for the RNA block",
    "section": "",
    "text": "These studies below laid the methodological groundwork for RNA-sequencing, ribosome profiling, and mapping binding sites of RNA-binding proteins using UV-crosslinking based approaches (CLIP-seq/PAR-CLIP).\n\n\nMortazavi A, Williams BA, McCue K, Schaeffer L, Wold B. Mapping and quantifying mammalian transcriptomes by RNA-Seq. Nat Methods. 2008 Jul;5(7):621-8. doi: 10.1038/nmeth.1226. Epub 2008 May 30. PMID: 18516045. [Link]\n\n\n\nIngolia NT, Ghaemmaghami S, Newman JR, Weissman JS. Genome-wide analysis in vivo of translation with nucleotide resolution using ribosome profiling. Science. 2009 Apr 10;324(5924):218-23. doi: 10.1126/science.1168978. Epub 2009 Feb 12. PMID: 19213877; PMCID: PMC2746483.[Link]\n\n\n\nUle J, Jensen KB, Ruggiu M, Mele A, Ule A, Darnell RB. CLIP identifies Nova-regulated RNA networks in the brain. Science. 2003 Nov 14;302(5648):1212-5. doi: 10.1126/science.1090095. PMID: 14615540. [Link]\nHafner M, Landthaler M, Burger L, Khorshid M, Hausser J, Berninger P, Rothballer A, Ascano M Jr, Jungkamp AC, Munschauer M, Ulrich A, Wardle GS, Dewell S, Zavolan M, Tuschl T. Transcriptome-wide identification of RNA-binding protein and microRNA target sites by PAR-CLIP. Cell. 2010 Apr 2;141(1):129-41. doi: 10.1016/j.cell.2010.03.009. PMID: 20371350; PMCID: PMC2861495. [Link]",
    "crumbs": [
      "Resources",
      "RNA Block resources"
    ]
  },
  {
    "objectID": "resources/block-rna-resources.html#foundational-work",
    "href": "resources/block-rna-resources.html#foundational-work",
    "title": "Resources for the RNA block",
    "section": "",
    "text": "These studies below laid the methodological groundwork for RNA-sequencing, ribosome profiling, and mapping binding sites of RNA-binding proteins using UV-crosslinking based approaches (CLIP-seq/PAR-CLIP).\n\n\nMortazavi A, Williams BA, McCue K, Schaeffer L, Wold B. Mapping and quantifying mammalian transcriptomes by RNA-Seq. Nat Methods. 2008 Jul;5(7):621-8. doi: 10.1038/nmeth.1226. Epub 2008 May 30. PMID: 18516045. [Link]\n\n\n\nIngolia NT, Ghaemmaghami S, Newman JR, Weissman JS. Genome-wide analysis in vivo of translation with nucleotide resolution using ribosome profiling. Science. 2009 Apr 10;324(5924):218-23. doi: 10.1126/science.1168978. Epub 2009 Feb 12. PMID: 19213877; PMCID: PMC2746483.[Link]\n\n\n\nUle J, Jensen KB, Ruggiu M, Mele A, Ule A, Darnell RB. CLIP identifies Nova-regulated RNA networks in the brain. Science. 2003 Nov 14;302(5648):1212-5. doi: 10.1126/science.1090095. PMID: 14615540. [Link]\nHafner M, Landthaler M, Burger L, Khorshid M, Hausser J, Berninger P, Rothballer A, Ascano M Jr, Jungkamp AC, Munschauer M, Ulrich A, Wardle GS, Dewell S, Zavolan M, Tuschl T. Transcriptome-wide identification of RNA-binding protein and microRNA target sites by PAR-CLIP. Cell. 2010 Apr 2;141(1):129-41. doi: 10.1016/j.cell.2010.03.009. PMID: 20371350; PMCID: PMC2861495. [Link]",
    "crumbs": [
      "Resources",
      "RNA Block resources"
    ]
  },
  {
    "objectID": "resources/block-rna-resources.html#software",
    "href": "resources/block-rna-resources.html#software",
    "title": "Resources for the RNA block",
    "section": "Software",
    "text": "Software\n\nAlignment software\nSTAR and minimap2 are popular choices for short read alignment. They are fast, free, and well-maintained.\n\n\nTranscript Quantification\nSalmon is a pseuodoalignment based approach for quantifying transcripts from RNA-seq data. See the salmon documentation and documentation for importing salmon data into R using txipmort\n\n\nPeak calling\nPARalyzer is the gold-standard in peak calling for PAR-CLIP data. It models read coverage and nucleotide conversions using a kernel density estimate classification to generate a high-resolution map of RNA-protein interaction sites.",
    "crumbs": [
      "Resources",
      "RNA Block resources"
    ]
  },
  {
    "objectID": "resources/plot-competition-2025.html",
    "href": "resources/plot-competition-2025.html",
    "title": "aRt competition entries",
    "section": "",
    "text": "Vote for your favorites at this Google Form.\nPlot 1\n\nCodelibrary(tidyverse)\nlibrary(patchwork)\nlibrary(emo)\n\n# need length.out and sequence function to have enough data points to make smooth curved lines; here I create a tbl with values for theta and a corresponding r for my coordinate plot\ntbl &lt;- tibble(\n  theta = seq(0, 2 * 3.14, length.out = 500),\n  r = (3 * sin(pi * theta))\n)\n\n# create a plot of each coordinate point and changed the aesthetics to adjust x and y to make an abstract plot. With different variations I came upon these aesthetic adjustments to create what looks like a squid\nggplot(tbl) +\n  geom_point(\n    aes(x = r * theta, y = r^2),\n    color = \"#613092\",\n    alpha = 0.75,\n    size = 0.25\n  ) +\n  coord_polar(start = 0) +\n  #added a face to my squid using annotate\n  annotate(\n    \"text\",\n    x = 0,\n    y = -4,\n    label = \"❁´◡`❁  \",\n    size = 7,\n    color = \"#452268\",\n    angle = 4\n  ) +\n\n  # added a title amd subtitle\n  labs(\n    title = \"Hugs From Miss Squid\",\n    subtitle = \"❤️  ❤️  ❤️ ❤️ ❤️ ❤️ ❤️ ❤️ ❤️ ❤️ ❤️\"\n  ) +\n  theme(\n    plot.subtitle = element_text(color = \"red\")\n  ) +\n\n  # used theme_void() to remove the coordinate plot background and axis labels so I was left with a white background behind my data points (squid body) and annotated text (face of squid)\n  theme_void()\n\n\n\nPlot 2\n\nCodelibrary(ggplot2)\nlibrary(dplyr)\nlibrary(viridis)\n\nset.seed(42)\nx &lt;- seq(-4 * pi, 4 * pi, length.out = 2000)\n\n# Mountain Layers\nmountain_data &lt;- data.frame(\n  x = rep(x, 5),\n  layer = rep(1:5, each = length(x))\n) %&gt;%\n  mutate(\n    # Base mountain shape\n    base_height = case_when(\n      layer == 1 ~ 3 * sin(x / 2) + 1.5 * sin(x / 1.3) + 0.8 * sin(x * 0.7),\n      layer == 2 ~ 2.5 * sin(x / 1.8) + 1.2 * sin(x / 1.1) + 0.6 * sin(x * 0.9),\n      layer == 3 ~ 2 * sin(x / 2.2) + sin(x / 0.9) + 0.4 * sin(x * 1.2),\n      layer == 4 ~ 1.5 * sin(x / 2.8) + 0.8 * sin(x / 1.5) + 0.3 * sin(x * 1.5),\n      layer == 5 ~ sin(x / 3.2) + 0.5 * sin(x / 2.1) + 0.2 * sin(x * 1.8)\n    ),\n    # Noise for texture\n    noise = rnorm(n(), 0, 0.1 * (6 - layer)),\n    y = pmax(base_height + noise, -layer * 0.5), # Ensure layers don't go below each other\n    # Color based on height and layer for atmospheric perspective\n    fill_color = layer + (y - min(y)) / (max(y) - min(y))\n  )\n\n# Plot each layer\np1 &lt;- ggplot() +\n  # Layer 5 (background)\n  geom_ribbon(\n    data = filter(mountain_data, layer == 5),\n    aes(x = x, ymin = -2.5, ymax = y),\n    fill = \"#440154\",\n    alpha = 0.6\n  ) +\n  # Layer 4\n  geom_ribbon(\n    data = filter(mountain_data, layer == 4),\n    aes(x = x, ymin = -2, ymax = y),\n    fill = \"#31688e\",\n    alpha = 0.7\n  ) +\n  # Layer 3\n  geom_ribbon(\n    data = filter(mountain_data, layer == 3),\n    aes(x = x, ymin = -1.5, ymax = y),\n    fill = \"#26828e\",\n    alpha = 0.75\n  ) +\n  # Layer 2\n  geom_ribbon(\n    data = filter(mountain_data, layer == 2),\n    aes(x = x, ymin = -1, ymax = y),\n    fill = \"#35b779\",\n    alpha = 0.8\n  ) +\n  # Layer 1 (foreground)\n  geom_ribbon(\n    data = filter(mountain_data, layer == 1),\n    aes(x = x, ymin = -0.5, ymax = y),\n    fill = \"#fde725\",\n    alpha = 0.85\n  ) +\n  labs(title = \"The Rocky Mountains\", x = \"\", y = \"\") +\n  theme_void() +\n  theme(\n    plot.background = element_rect(fill = \"black\", color = NA),\n    panel.background = element_rect(fill = \"black\", color = NA),\n    plot.title = element_text(color = \"white\", size = 16, hjust = 0.5),\n    plot.subtitle = element_text(color = \"white\", size = 12, hjust = 0.5),\n    legend.position = \"none\"\n  )\n\nprint(p1)\n\n\n\n\n\n\n\nPlot 3\n\nCode# aRt Title: Transcript City\n\n# Use transcriptomic data from ps-04.\n# Select for gene name & RNA_fc values only.\n# Drop NAs & remove duplicates.\n# Filter rna_fc within a positive range that is reasonable to display.\n\nlibrary(tidyverse)\nlibrary(here)\n\nart_tbl &lt;- read_csv(\n  here(\"data/bootcamp/data_rna_protein.csv.gz\")\n)\n\nart_tbl_trim &lt;- art_tbl |&gt;\n  select(gene = geneid, rna_fc = iDUX4_logFC) |&gt;\n  drop_na() |&gt;\n  distinct(gene, .keep_all = TRUE) |&gt;\n  filter(rna_fc &gt; 0 & rna_fc &lt;= 0.5) |&gt;\n  # Mutate to assign `color_class` based on arbitrary rna_fc value; will be used to vary color in plot\n  mutate(\n    color_class = case_when(\n      rna_fc &lt; 0.1 ~ \"A\",\n      rna_fc &lt; 0.2 ~ \"B\",\n      rna_fc &lt; 0.3 ~ \"C\",\n      rna_fc &lt; 0.4 ~ \"D\",\n      .default = \"E\"\n    )\n  ) |&gt;\n  # Mutate to assign `star_class` based on first letter of gene name. Use this stackoverflow post to understand partial strings: https://stackoverflow.com/questions/56993566/how-to-create-a-new-column-based-on-partial-string-of-another-column\n  mutate(\n    star_class = substr(gene, 1L, 1L)\n  )\n\ncity_palette &lt;- c(\"#eeaf61\", \"#fb9062\", \"#ee5d6c\", \"#ce4993\", \"#6a0d83\")\n\nggplot(\n  art_tbl_trim,\n  aes(\n    x = gene,\n    y = rna_fc,\n    fill = color_class\n  )\n) +\n  geom_col() +\n  geom_point(\n    shape = 8,\n    color = \"white\",\n    size = 0.2\n  ) +\n  theme(\n    # Remove legend, axis titles, grid, & make background black\n    legend.position = \"none\",\n    axis.title = element_blank(),\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    panel.grid = element_blank(),\n    panel.background = element_rect(fill = 'black')\n  ) +\n  scale_fill_manual(values = city_palette)\n\n\n\n\n\n\n\nPlot 4\n\nCodelibrary(ggplot2)\n\npride_colors &lt;- c(\n  \"maroon\",\n  \"purple\",\n  \"pink\",\n  \"lavender\",\n  \"steelblue\",\n  \"turquoise\",\n  \"springgreen\",\n  \"snow4\"\n)\n\nstripes_df &lt;- data.frame(\n  ymin = seq(0, 7),\n  #Ymin needs to match the number of colors you've picked out\n  ymax = seq(1, 8),\n  #Ymax is setting the width of each rectangle to be 1 unit later on\n  color = pride_colors\n)\n\nbase_flag &lt;- ggplot(stripes_df) +\n  geom_rect(\n    aes(xmin = 0, xmax = 15, ymin = ymin, ymax = ymax, fill = color),\n    color = NA\n  )\n\n#Create a triangle polygon df\n\ntriangle_df &lt;- data.frame(\n  x = c(0, 0, 5),\n  y = c(0, 8, 4) # bottom, top, center\n)\n\ncombined_flag &lt;- base_flag +\n  geom_polygon(\n    data = triangle_df,\n    aes(x = x, y = y),\n    fill = \"orange\",\n    alpha = 0.7\n  ) +\n  scale_fill_identity() +\n  theme_void() +\n  coord_fixed()\n\ndots_df &lt;- data.frame(\n  x = runif(400, 0, 15), # Random x across flag width\n  y = runif(400, 0, length(pride_colors)), # Random y across flag height\n  size = runif(400, 0.5, 2), # Dot sizes\n  alpha = runif(400, 0.1, 0.4), # Transparency\n  color = sample(pride_colors, 400, replace = TRUE) # Pride color for each dot\n)\n\n# Final plot\ncombined_flag +\n  geom_point(\n    data = dots_df,\n    aes(x = x, y = y, size = size, alpha = 0.7, color = color),\n    show.legend = FALSE\n  ) +\n  #scale_fill_identity() +\n  theme_void() +\n  coord_fixed()\n\n\n\n\n\n\n\nPlot 5\n\nCodelibrary(tidyverse)\ndata(\"trees\")\ntrees_tibble &lt;- as_tibble(trees)\n\nggplot_trees &lt;- ggplot(\n  data = trees_tibble,\n  mapping = aes(\n    x = Girth,\n    y = Height,\n    size = Volume\n  )\n) +\n  geom_point(\n    alpha = 1.0,\n    shape = 8,\n    color = \"#FF0000\",\n    size = 10,\n    stroke = 1\n  ) +\n  geom_smooth(\n    alpha = 0.5,\n    color = \"#0000FF\",\n    fill = \"#8A00C4\",\n    linetype = \"dashed\",\n    size = 3\n  ) +\n  theme(\n    plot.background = element_rect(fill = \"#FFFF00\"),\n    panel.background = element_rect(fill = \"#39FF14\"),\n    panel.grid.major = element_line(color = \"#FF0000\"),\n    panel.grid.minor.x = element_line(color = \"#0000FF\"),\n    panel.grid.minor.y = element_line(color = \"#FFAE42\"),\n    panel.grid.major.y = element_line(color = \"#FF13F0\")\n  ) +\n  labs(\n    x = \"how thick is it (in) ??\",\n    y = \"vertical dominance (ft)\",\n    title = \"cool facts about 31 black cherry trees\"\n  )\n\nggplot_trees\n\n\n\n\n\n\n\nPlot 6\n\nCode#generating histogram with labels and title\nugly_plant &lt;- ggplot(PlantGrowth, aes(weight, fill = group, color = group)) +\n  geom_histogram() +\n  labs(x = \"PLANT WEIGHT\", y = \"PLANT COUNT\", title = \"green plants\")\n\n#Theme changes for colors and position/angle of labels\nugly_plant +\n  theme(\n    plot.background = element_rect(fill = \"lightgreen\"),\n    panel.background = element_rect(fill = \"darkgreen\"),\n    panel.grid.major = element_line(colour = \"white\"),\n    plot.title = element_text(color = \"#29AB87\", angle = 100, hjust = 6),\n    axis.title.x = element_text(\n      color = \"blue\",\n      angle = 145,\n      hjust = 1,\n      vjust = 1\n    ),\n    axis.title.y = element_text(\n      color = \"yellow\",\n      angle = 250,\n      hjust = 1,\n      vjust = 1\n    ),\n    legend.title = element_text(\n      color = \"green\",\n      angle = 170,\n      hjust = -1,\n      vjust = -1\n    ),\n    legend.text = element_text(color = \"darkgreen\", angle = 120)\n  ) +\n  scale_fill_brewer(palette = \"Light1\")\n\n\n\n\n\n\n\nPlot 7\n\nCodelibrary(tidyverse)\nlibrary(here)\nlibrary(gganimate)\nlibrary(ragg)\n\nstorms_sin &lt;- storms |&gt; drop_na()\n\nanim &lt;- ggplot(\n  storms_sin,\n  aes(\n    x = cos(pressure),\n    y = sin(wind),\n  )\n) +\n  geom_point(alpha = 0.05, shape = 11, size = 8, color = \"#edf8b1\") +\n  theme_void() +\n  coord_flip() +\n  geom_point(\n    aes(x = cos(pressure), y = sin(lat)),\n    alpha = 0.3,\n    shape = 8,\n    size = 15,\n    color = \"#7fcdbb\"\n  ) +\n  geom_density_2d_filled(\n    aes(x = cos(pressure), y = sin(lat)),\n    alpha = 0.1,\n    linewidth = 12,\n    color = \"violet\"\n  ) +\n\n  theme(\n    legend.position = \"none\",\n    plot.background = element_rect(fill = \"#91c7d8\"),\n    panel.background = element_rect(fill = \"#9c8080\")\n  ) +\n  transition_states(\n    transition_length = 0,\n    state_length = 0.001,\n    year\n  )\n\nspacestorm_plot &lt;- animate(\n  anim,\n  device = \"ragg_png\",\n  renderer = gifski_renderer()\n)\n\nanim_save(\n  filename = \"spacestorm.gif\",\n  animation = spacestorm_plot,\n  path = here(\"img\")\n)\n\n\n\nPlot 8\n\nCodelibrary(tidyverse)\nlibrary(emo)\n# library(emojifont)\nlibrary(here)\nlibrary(gganimate)\nlibrary(ragg)\ndata(\"WorldPhones\")\n\nset.seed(42)\n\nworldphones_tidy &lt;- WorldPhones %&gt;%\n  as.data.frame() %&gt;%\n  rownames_to_column(var = \"year\") %&gt;%\n  pivot_longer(\n    cols = -year,\n    names_to = \"region\",\n    values_to = \"phones\"\n  ) %&gt;%\n  mutate(\n    emoji = case_when(\n      region == \"N.Amer\" ~ emo::ji(\"eagle\"),\n      region == \"Europe\" ~ emo::ji(\"bear\"),\n      region == \"Asia\" ~ emo::ji(\"tiger\"),\n      region == \"S.Amer\" ~ emo::ji(\"monkey\"),\n      region == \"Oceania\" ~ emo::ji(\"penguin\"),\n      region == \"Africa\" ~ emo::ji(\"giraffe\"),\n      region == \"Mid.Amer\" ~ emo::ji(\"cow\")\n    )\n  ) %&gt;%\n  select(\n    year,\n    emoji,\n    region,\n    phones\n  )\n\nggplot(\n  worldphones_tidy,\n  aes(\n    x = year,\n    y = phones,\n    color = region\n  )\n) +\n  geom_text(\n    aes(label = emoji),\n    size = 4,\n    show.legend = FALSE\n  ) +\n  labs(\n    x = \"BEST YEARS\",\n    y = \"TOO MANY PHONES\",\n    title = \"ANIMALS LOVE PHONES\",\n    caption = \"eagles are addicted to phones\"\n  ) +\n  scale_y_continuous(\n    limits = c(0, 100000),\n    breaks = seq(0, 100000, 10000),\n    labels = scales::comma\n  ) +\n  scale_x_discrete(position = \"top\") +\n  theme(\n    axis.text.x = element_text(\n      face = \"bold\",\n      color = \"#ffeda0\",\n      size = 13,\n      angle = 179\n    ),\n    axis.text.y = element_text(\n      face = \"bold\",\n      color = \"orange\",\n      size = 10,\n      angle = 180\n    ),\n    plot.background = element_rect(fill = \"pink\"),\n    plot.title = element_text(\n      face = \"bold.italic\",\n      color = \"green\",\n      size = 18,\n      angle = 183\n    ),\n    plot.caption = element_text(color = \"white\", size = 12),\n    axis.title.x = element_text(size = 22, color = \"dark blue\", angle = 12),\n    axis.title.y = element_text(color = \"orange\", angle = 181, size = 14),\n    panel.background = element_rect(fill = \"light blue\")\n  )\n\n\n\n\n\n\n\nPlot 9\n\nCodelibrary(tidyverse)\nlibrary(here)\nlibrary(emo)\nlibrary(ggplot2)\n\nexp_tbl &lt;- read_csv(here(\"data/languages.csv\"))\n\nexp_tidy &lt;-\n  exp_tbl |&gt;\n  select(state, language, percent) |&gt;\n  drop_na()\n\nggplot(\n  exp_tbl_tidy,\n  aes(x = state, y = language, size = percent, color = percent)\n) +\n  geom_point(alpha = 0.50, fill = \"tomato1\", color = \"red\")\n+labs(x = \"States\", y = \"Language\", title = \"Linguistics\")\n\n\nPlot 10\n\nCode# Official ggplot for competition, emoji's where not working\nemojimap &lt;- c(\n  \"Tiger\" = \"🐆\",\n  \"Cow\" = \"🐄\",\n  \"African elephant\" = \"🐘\",\n  \"Dog\" = \"🐕\",\n  \"Goat\" = \"🐐\",\n  \"Rabbit\" = \"🐇\",\n  \"Pig\" = \"🐖\",\n  \"Chimpanzee\" = \"🐒\"\n)\n\nsleep_long &lt;- msleep |&gt;\n  mutate(emoji = emojimap[name]) |&gt;\n  filter(!is.na(emoji)) |&gt;\n  select(emoji, name, brainwt, sleep_total, awake) |&gt;\n  drop_na() |&gt;\n  pivot_longer(\n    c(sleep_total, awake),\n    names_to = \"state\",\n    values_to = \"hours\"\n  ) |&gt;\n  mutate(\n    factor(\n      state,\n      levels = c(\"awake\", \"sleep_total\"),\n      labels = c(\"Awake\", \"Sleep\")\n    )\n  ) |&gt;\n  mutate(\n    emoji = case_when(\n      name == \"Tiger\" ~ emo::ji(\"tiger\"),\n      name == \"Cow\" ~ emo::ji(\"cow\"),\n      name == \"African elephant\" ~ emo::ji(\"elephant\"),\n      name == \"Goat\" ~ emo::ji(\"goat\"),\n      name == \"Rabbit\" ~ emo::ji(\"rabbit\"),\n      name == \"Pig\" ~ emo::ji(\"pig\"),\n      name == \"Chimpanzee\" ~ emo::ji(\"monkey\"),\n      name == \"Dog\" ~ emo::ji(\"dog\")\n    )\n  )\n\nggplot(\n  sleep_long,\n  aes(\n    x = name,\n    y = brainwt,\n    label = emoji,\n    size = hours,\n    color = state\n  )\n) +\n  geom_point(alpha = 0.7, show.legend = FALSE) +\n  geom_text(aes(label = emoji), size = 6) +\n  # scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  scale_y_log10() +\n  #facet_wrap(~name) +\n  # Here comes the gganimate specific bits\n  labs(\n    title = 'Animal activity: {closest_state}',\n    x = \"Animal species\",\n    y = \"Brain weight\",\n    size = \"Hours\",\n    color = \"State\"\n  ) +\n  transition_states(state, transition_length = 2, state_length = 1) +\n  ease_aes('linear') +\n  theme(\n    legend.position = \"none\",\n    axis.text = element_text(angle = 180),\n    plot.title = element_text(hjust = 0.5, size = 30),\n    axis.title = element_text(size = 30),\n    axis.text.x = element_text(size = 2),\n    axis.text.y = element_text(size = 2),\n    plot.background = element_rect(fill = \"#F0F8FF\"),\n    panel.background = element_rect(fill = \"#E6F2FF\"),\n    panel.grid.major = element_line(color = \"#D3D3D3\"),\n    panel.grid.minor = element_line(color = \"#96ceb4\")\n  )\n\n\n\n\n\n\n\nPlot 11\n\nCodelibrary(tidyverse)\nlibrary(viridisLite)\n\nbg &lt;- \"#0b0c10\"\npal &lt;- viridis(1000, option = \"plasma\")\n\na &lt;- 4\nb &lt;- 6\nphi &lt;- pi / 6\nt &lt;- seq(0, 3 * pi, length.out = 8000)\n\ndf &lt;- tibble(\n  t = t,\n  x = sin(a * t + phi),\n  y = sin(b * t)\n)\nNC_modify_FINAL_PLOT_NOT_PENGUINS &lt;- ggplot(df, aes(x, y, color = t)) +\n  geom_path(linewidth = 0.5, alpha = 0.9) +\n  scale_color_gradientn(colors = pal, guide = \"none\") +\n  coord_equal() +\n  theme_void() +\n  theme(\n    plot.background = element_rect(fill = bg, color = NA),\n    plot.margin = margin(40, 40, 40, 40)\n  )\nNC_modify_FINAL_PLOT_NOT_PENGUINS\n\n\n\n\n\n\n\nPlot 12\n\nCodelibrary(emo)\nlibrary(gifski)\nlibrary(ggplot2)\nlibrary(gganimate)\nlibrary(dplyr)\nlibrary(ragg)\nlibrary(here)\n\nlibrary(showtext)\n# Add the system font manually\n# font_add(\"emoji\", \"~/.local/share/fonts/NotoColorEmoji.ttf\")\n# showtext_auto()\n\n# Define x, y, and frames\n# -----------------------------\n# Define paths\nn &lt;- 200\n# Plan path (straight line)\nx &lt;- seq(0, 10, length.out = n)\nplan_y &lt;- seq(0, 0, length.out = n)\n#Reality path (curvy line)\nreality_y &lt;- sin(0.9 * x) + cos(3.8 * x)\nframe &lt;- 1:length(x)\n\n# Determine student emoji: happy if y&gt;0, sad if y&lt;=0\nstudent &lt;- ifelse(\n  reality_y &gt; 0,\n  emo::ji(\"grinning_face\"),\n  emo::ji(\"anxious_face_with_sweat\")\n)\n\ndata &lt;- data.frame(x = x, y = reality_y + 0.5, frame = frame, student = student)\ndata$student &lt;- as.character(data$student)\n# -----------------------------\n# Obstacles (plateau points on Reality line)\n# -----------------------------\nobstacles &lt;- data.frame(\n  x = c(\n    0.063,\n    0.779,\n    1.658,\n    2.520,\n    3.246,\n    4.185,\n    4.944,\n    5.759,\n    6.674,\n    7.382,\n    8.291,\n    9.115,\n    9.867\n  ),\n  y = c(\n    1.028,\n    -0.339,\n    1.997,\n    -0.222,\n    1.192,\n    -1.566,\n    0.032,\n    -1.886,\n    0.701,\n    -0.622,\n    1.920,\n    -0.057,\n    1.497\n  ),\n  label = c(\n    paste0(emo::ji(\"lab_coat\"), emo::ji(\"handshake\")),\n    emo::ji(\"books\"),\n    paste0(emo::ji(\"hundred_points\"), emo::ji(\"page_facing_up\")),\n    paste0(emo::ji(\"mouse_face\"), emo::ji(\"syringe\")),\n    paste0(emo::ji(\"skier\"), emo::ji(\"mountain\")),\n    paste0(emo::ji(\"test_tube\"), emo::ji(\"poo\")),\n    paste0(emo::ji(\"sparkles\"), emo::ji(\"brain\")),\n    emo::ji(\"exploding_head\"),\n    paste0(emo::ji(\"coffee\"), emo::ji(\"pizza\")),\n    paste0(\n      emo::ji(\"man_teacher\"),\n      emo::ji(\"woman_teacher\"),\n      emo::ji(\"angry_face\")\n    ),\n    paste0(emo::ji(\"money_bag\"), emo::ji(\"memo\")),\n    paste0(emo::ji(\"hourglass_not_done\"), emo::ji(\"zombie\")),\n    paste0(emo::ji(\"woman_scientist\"), emo::ji(\"man_scientist\"))\n  )\n)\n\nobstacles$label &lt;- as.character(obstacles$label)\n\n# Build ggplot\np &lt;- ggplot() +\n  geom_line(\n    aes(x, y = plan_y),\n    color = \"steelblue\",\n    linetype = \"dashed\",\n    linewidth = 1\n  ) +\n  geom_line(aes(x, y = reality_y), color = \"red\", linewidth = 1.5) +\n  geom_text(\n    data = data,\n    aes(x, y, label = student, family = \"emoji\"),\n    size = 10\n  ) +\n  geom_text(\n    data = obstacles,\n    aes(x, y, label = label),\n    size = 10,\n    family = \"emoji\"\n  ) +\n  theme_minimal(base_size = 16) +\n  annotate(\n    \"text\",\n    x = -0.5,\n    y = 0,\n    label = \"Plan\",\n    color = \"steelblue\",\n    size = 6\n  ) +\n  annotate(\n    \"text\",\n    x = -0.5,\n    y = 2,\n    label = \"Reality\",\n    color = \"red\",\n    size = 6\n  ) +\n  geom_text(\n    aes(x = 10.3, y = 0, label = as.character(emo::ji(\"graduation_cap\"))),\n    size = 10,\n    family = \"emoji\"\n  ) +\n  theme_void(base_size = 16) +\n  labs(title = \"PhD Journey: Plan vs Reality\")\n\n# -----------------------------\n# Animate along frames\n# -----------------------------\nanim &lt;- p + transition_reveal(along = frame)\n\ngif_plot &lt;- animate(\n  anim,\n  nframes = 200,\n  fps = 15,\n  width = 800,\n  height = 400,\n  device = \"ragg_png\",\n  renderer = gifski_renderer()\n)\n\n# -----------------------------\n# Save GIF\n# -----------------------------\nanim_save(\n  filename = \"phd_journey.gif\",\n  animation = gif_plot,\n  path = here()\n)\n\n\n\nPlot 13\n\nCodeaqtib &lt;- as_tibble(airquality) |&gt;\n  drop_na()\n\nggplot(\n  aqtib,\n  mapping = aes(\n    x = Day,\n    y = Ozone,\n    color = Temp\n  )\n) +\n  geom_point(shape = 8, alpha = 0.5) +\n  scale_x_reverse() +\n  scale_y_log10() +\n  scale_color_gradientn(colours = rainbow(9)) +\n  geom_smooth(method = lm, na.rm = FALSE, orientation = NA, se = FALSE) +\n  facet_wrap(\n    ~Month,\n    labeller = labeller(\n      Month = c(\n        \"5\" = \"yam\",\n        \"6\" = \"enuj\",\n        \"7\" = \"yulj\",\n        \"8\" = \"tsugua\",\n        \"9\" = \"rebmetpes\"\n      )\n    )\n  ) +\n  labs(\n    x = \"Month time (days) -&gt;\",\n    y = \"OO O ( b  i  l  l  i    o   n    s   )\",\n    title = \"global warming in new york is in june and september\",\n    caption = \"(august seems to get cold. hard to tell, but seems like its still snowing)\"\n  ) +\n  theme(\n    plot.background = element_rect(fill = \"yellow\"),\n    strip.background = element_blank(),\n    strip.text = element_text(size = 13, color = \"orange\"),\n    panel.border = element_rect(color = \"yellow3\", fill = NA, size = 1),\n    panel.background = element_rect(fill = \"yellow\"),\n    panel.grid.major = element_line(color = \"yellow\"),\n    panel.grid.minor = element_line(\n      color = \"blue\",\n      linetype = \"dotted\",\n      linewidth = 1\n    ),\n    axis.title.x = element_text(size = 13, color = \"yellow3\", angle = 180),\n    axis.title.y = element_text(size = 13, color = \"darkgreen\"),\n    legend.background = element_rect(fill = \"yellow\"),\n  ) +\n  geom_segment(\n    data = subset(aqtib, Month == \"6\"),\n    aes(x = 3, y = 3, xend = 12, yend = 15),\n    arrow = arrow(length = unit(0.2, \"inches\")),\n    color = \"red\"\n  ) +\n  geom_segment(\n    data = subset(aqtib, Month == \"7\"),\n    aes(x = 20, y = 2, xend = 16, yend = 6),\n    arrow = arrow(length = unit(0.2, \"inches\")),\n    color = \"blue\"\n  ) +\n  geom_segment(\n    data = subset(aqtib, Month == \"9\"),\n    aes(x = 27, y = 2, xend = 14, yend = 17),\n    arrow = arrow(length = unit(0.2, \"inches\")),\n    color = \"red\"\n  ) +\n  geom_text(\n    data = subset(aqtib, Month == \"6\"),\n    aes(x = 5, y = 3, label = \"blast off!\"),\n    color = \"purple\",\n    fontface = \"bold\"\n  ) +\n  geom_text(\n    data = subset(aqtib, Month == \"9\"),\n    aes(x = 25, y = 2, label = \"heat rises!\"),\n    color = \"purple\",\n    fontface = \"bold\"\n  ) +\n  geom_text(\n    data = subset(aqtib, Month == \"7\"),\n    aes(x = 20, y = 2, label = \"still snowing???\"),\n    color = \"grey\"\n  )\n\n\n\n\n\n\n\nPlot 14\n\nCodePattern &lt;- read_csv(here(\"Cross-Stitch-Pattern_250901.csv\"))\n\nFloss_colors &lt;- c(\n  \"Black\" = \"#000000\",\n  \"Cinnamon\" = \"#E69F00\",\n  \"Fern Green\" = \"#009E73\",\n  \"Raspberry - Light\" = \"#CC79A7\",\n  \"Stone Grey - Dark\" = \"#B0B0B0\",\n  \"Surf Blue - Light\" = \"#56B4E9\",\n  \"Topaz - Light\" = \"#D55E00\"\n)\n\nggplot(\n  Pattern,\n  aes(x = x, y = y, color = color_name)\n) +\n  geom_point(\n    shape = 4,\n    size = 1.6,\n    stroke = 1.3\n  ) +\n  scale_color_manual(values = Floss_colors) +\n  coord_fixed(ratio = 1) +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Cross Stitch Pattern\"\n  ) +\n  theme(\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    panel.background = element_blank(),\n    legend.position = \"none\",\n    plot.title = element_text(\n      size = 18,\n      face = \"bold\",\n      family = \"mono\",\n      hjust = 0.5\n    )\n  )\n\n\n\nPlot 15\n\nCodelibrary(tidyverse)\nlibrary(emo)\n# library(emojifont)\nlibrary(here)\nlibrary(gganimate)\nlibrary(ragg)\ndata(\"WorldPhones\")\n\nset.seed(42)\n\nworldphones_tidy &lt;- WorldPhones %&gt;%\n  as.data.frame() %&gt;%\n  rownames_to_column(var = \"year\") %&gt;%\n  pivot_longer(\n    cols = -year,\n    names_to = \"region\",\n    values_to = \"phones\"\n  ) %&gt;%\n  mutate(\n    emoji = case_when(\n      region == \"N.Amer\" ~ emo::ji(\"eagle\"),\n      region == \"Europe\" ~ emo::ji(\"bear\"),\n      region == \"Asia\" ~ emo::ji(\"tiger\"),\n      region == \"S.Amer\" ~ emo::ji(\"monkey\"),\n      region == \"Oceania\" ~ emo::ji(\"penguin\"),\n      region == \"Africa\" ~ emo::ji(\"giraffe\"),\n      region == \"Mid.Amer\" ~ emo::ji(\"cow\")\n    )\n  ) %&gt;%\n  select(\n    year,\n    emoji,\n    region,\n    phones\n  )\n\nggplot(\n  worldphones_tidy,\n  aes(\n    x = year,\n    y = phones,\n    color = region\n  )\n) +\n  geom_text(\n    aes(label = emoji),\n    size = 4,\n    show.legend = FALSE\n  ) +\n  labs(\n    x = \"BEST YEARS\",\n    y = \"TOO MANY PHONES\",\n    title = \"ANIMALS LOVE PHONES\",\n    caption = \"eagles are addicted to phones\"\n  ) +\n  scale_y_continuous(\n    limits = c(0, 100000),\n    breaks = seq(0, 100000, 10000),\n    labels = scales::comma\n  ) +\n  scale_x_discrete(position = \"top\") +\n  theme(\n    axis.text.x = element_text(\n      face = \"bold\",\n      color = \"#ffeda0\",\n      size = 13,\n      angle = 179\n    ),\n    axis.text.y = element_text(\n      face = \"bold\",\n      color = \"orange\",\n      size = 10,\n      angle = 180\n    ),\n    plot.background = element_rect(fill = \"pink\"),\n    plot.title = element_text(\n      face = \"bold.italic\",\n      color = \"green\",\n      size = 18,\n      angle = 183\n    ),\n    plot.caption = element_text(color = \"white\", size = 12),\n    axis.title.x = element_text(size = 22, color = \"dark blue\", angle = 12),\n    axis.title.y = element_text(color = \"orange\", angle = 181, size = 14),\n    panel.background = element_rect(fill = \"light blue\")\n  )\nprint(worldphones_tidy)\n\n\n\nPlot 16\n\nCodelibrary(ggplot2)\nlibrary(tidyverse)\necho = TRUE\nsun_tib &lt;- tibble(\n  year = as.numeric(time(sunspots)),\n  sunspots = as.numeric(sunspots)\n)\n\nggplot(\n  sun_tib,\n  aes(x = year, y = sunspots)\n) +\n  geom_bar(\n    stat = \"identity\",\n    fill = \"green\",\n    color = \"red\",\n    width = 100\n  ) +\n  geom_line(color = \"purple\", linewidth = 5, linetype = \"dotdash\") +\n  geom_point(color = \"yellow\", size = 2, alpha = 0.3, shape = 8) +\n  geom_smooth(\n    method = \"loess\",\n    span = .04,\n    color = \"white\",\n    fill = \"orange\",\n    formula = y ~ x,\n  ) +\n  scale_y_reverse() +\n  theme_void(base_size = 28) +\n  theme(\n    panel.background = element_rect(fill = \"pink\"),\n    plot.background = element_rect(fill = \"#FFDB58\"),\n    plot.title = element_text(\n      color = \"limegreen\",\n      face = \"bold\",\n      hjust = 0.5,\n      family = \"Comic Sans MS\",\n      angle = 2,\n      size = 35\n    ),\n    axis.text.x = element_text(\n      face = \"bold.italic\",\n      color = \"red\",\n      size = 4,\n      angle = 180\n    ),\n    axis.title.x = element_text(\n      size = 12,\n      color = \"orange\",\n      angle = 2\n    ),\n    plot.subtitle = element_text(\n      color = \"orange\",\n      face = \"bold\",\n      family = \"Comic Sans MS\",\n      size = 20,\n      hjust = \".4\"\n    ),\n    plot.caption = element_text(\n      color = \"white\",\n      face = \"italic\",\n      family = \"Comic Sans MS\",\n      size = 30,\n      hjust = \".5\"\n    )\n  ) +\n  labs(\n    title = \" SUNSPOTs\",\n    subtitle = \"Hotter  than  the hottest flame  on  earth\",\n    caption = \"Cant escape the sunspots\",\n    x = \"time is relative\",\n    y = \"spotty bois\"\n  )\n\n\n\n\n\n\n\nPlot 17\n\nCodelibrary(ggplot2)\nlibrary(dplyr)\nlibrary(purrr)\nset.seed(1972)\nlibrary(gganimate)\n\nletters_df &lt;- data.frame(\n  x = 1:4,\n  y = 0,\n  lab = c(\"A\", \"B\", \"B\", \"A\"),\n  col = c(\"#e91e63\", \"#ff8fc7\", \"#ff8fc7\", \"#e91e63\") # pinks\n)\n\n\nshape_pool &lt;- c(8, 3, 4, 18, 17)\nn_sparkles &lt;- 700\nsparkles &lt;- data.frame(\n  x = runif(n_sparkles, 0.3, 4.7),\n  y = runif(n_sparkles, -1.2, 1.2),\n  size = runif(n_sparkles, 0.8, 3.0),\n  alpha = runif(n_sparkles, 0.80, 1),\n  col = sample(\n    c(\"#f72585\", \"#ff5fa2\", \"#ff8fc7\", \"#ffd1e8\", \"#ffd166\"),\n    n_sparkles,\n    TRUE\n  ),\n  shape = sample(shape_pool, n_sparkles, TRUE)\n)\n\nmake_bursts &lt;- function(n_bursts = 40, min_rays = 6, max_rays = 10) {\n  centers &lt;- data.frame(\n    x0 = runif(n_bursts, 0.4, 4.6),\n    y0 = runif(n_bursts, -1.1, 1.1)\n  )\n  bursts &lt;- do.call(\n    rbind,\n    lapply(1:nrow(centers), function(i) {\n      k &lt;- sample(min_rays:max_rays, 1)\n      th &lt;- seq(0, 2 * pi, length.out = k + 1)[-(k + 1)]\n      L &lt;- runif(k, 0.05, 0.12)\n      data.frame(\n        x = centers$x0[i],\n        y = centers$y0[i],\n        xend = centers$x0[i] + L * cos(th),\n        yend = centers$y0[i] + L * sin(th),\n        alpha = runif(1, 0.08, 0.18),\n        size = runif(1, 0.4, 0.9),\n        col = sample(c(\"#f72585\", \"#ff8fc7\", \"#ffd1e8\"), 1)\n      )\n    })\n  )\n  bursts\n}\nbursts &lt;- make_bursts()\n\ngg &lt;- ggplot() +\n  geom_segment(\n    data = bursts,\n    aes(\n      x = x,\n      y = y,\n      xend = xend,\n      yend = yend,\n      alpha = alpha,\n      size = size,\n      color = col\n    ),\n    lineend = \"round\",\n    show.legend = FALSE\n  ) +\n  geom_point(\n    data = sparkles,\n    aes(x, y, shape = shape, size = size, alpha = alpha, color = col),\n    show.legend = FALSE\n  ) +\n  geom_text(\n    data = letters_df,\n    aes(x, y, label = lab, color = col),\n    fontface = \"bold\",\n    size = 30\n  ) +\n  scale_shape_identity() +\n  scale_size_identity() +\n  scale_alpha_identity() +\n  scale_color_identity() +\n  coord_cartesian(xlim = c(0.2, 4.8), ylim = c(-1.4, 1.4), expand = FALSE) +\n  theme_void(base_size = 14) +\n  theme(\n    plot.background = element_rect(fill = \"white\", color = NA),\n    panel.background = element_rect(fill = \"white\", color = NA),\n    plot.margin = margin(30, 30, 30, 30)\n  )\n\ngg\n\n\n\n\n\n\n\nPlot 18\n\nCodelibrary(tidyverse)\nlibrary(ggplot2)\n\nmsleep_tbl &lt;- drop_na(msleep)\n\nggplot(\n  msleep_tbl,\n  aes(\n    x = brainwt,\n    y = sleep_rem,\n    color = order,\n    shape = vore\n  )\n) +\n  geom_jitter(size = 10) +\n  theme(\n    plot.background = element_rect(fill = \"#c3cb6e\"),\n    plot.title = element_text(\n      size = 30,\n      hjust = 0.25,\n      color = \"#72601b\",\n      angle = 3\n    ),\n    plot.caption = element_text(size = 10, face = \"italic\", angle = 25),\n\n    panel.background = element_rect(fill = '#c6c58b', size = 4),\n    panel.border = element_rect(fill = 'NA', color = \"#818c3c\", size = 2),\n\n    axis.title.x = element_text(\n      face = \"bold.italic\",\n      size = 13,\n      color = \"#e4e6a8\",\n      angle = 70\n    ),\n    axis.title.y = element_text(\n      face = \"bold\",\n      size = 20,\n      color = \"#e4e6a8\",\n      angle = 115\n    ),\n    axis.text = element_text(face = \"italic\", size = 15),\n    axis.text.x.bottom = element_text(angle = 140),\n\n    legend.background = element_rect(fill = \"#fbff00\"),\n    legend.key = element_rect(fill = \"#b78b3c\"),\n    #legend.direction = \"vertical\",\n    legend.position = \"bottom\",\n    #legend.justification = \"left\",\n    legend.title = element_text(family = \"serif\", color = \"#ef9e3a\", size = 2),\n    legend.text = element_text(\n      family = \"mono\",\n      face = \"italic\",\n      color = \"#c89c45\",\n      size = 4\n    )\n  ) +\n  labs(\n    title = \"More sleeps = big brain?\",\n    x = \"Brain Weight\",\n    y = \"REM Cycles\",\n    col = \"Species Order\"\n  )\n\n\n\n\n\n\n\nPlot 19\n\nCodelibrary(tidyverse)\n\nset.seed(999)\nn_layers &lt;- 50\nn_points &lt;- 6\n\npolys &lt;- tibble()\nfor (i in 1:n_layers) {\n  angle &lt;- seq(0, 2 * pi, length.out = n_points + 1)[-1]\n  radius &lt;- runif(n_points, min = i * 0.5, max = i * 1.5)\n  x &lt;- radius * cos(angle) + rnorm(n_points, 0, 0.3)\n  y &lt;- radius * sin(angle) + rnorm(n_points, 0, 0.3)\n\n  temp &lt;- tibble(\n    layer = i,\n    x = x,\n    y = y,\n    fill = sample(c(\"#FF3C38\", \"#38FFDC\", \"#FFC738\", \"#8A38FF\"), 1)\n  )\n  polys &lt;- bind_rows(polys, temp)\n}\n\nn_rows &lt;- nrow(polys)\n\nggplot(polys, aes(x = x, y = y, group = layer, fill = fill)) +\n  geom_polygon(alpha = 0.5, color = \"white\", linewidth = 0.2) +\n  geom_point(\n    aes(\n      x = x + rnorm(n_rows, 0, 0.1),\n      y = y + rnorm(n_rows, 0, 0.1),\n      color = fill\n    ),\n    size = 1,\n    alpha = 0.7\n  ) +\n  scale_fill_identity() +\n  scale_color_identity() +\n  coord_fixed() +\n  theme_void() +\n  theme(\n    plot.background = element_rect(fill = \"#000000\"),\n    panel.background = element_rect(fill = \"#000000\")\n  )\n\n\n\n\n\n\n\nPlot 20\n\nCodelibrary(ggplot2)\nlibrary(ggforce)\nlibrary(RColorBrewer)\nlibrary(dplyr)\n\nhori_lines &lt;- tibble(\n  x = seq(1, -1, by = -.08),\n  xend = seq(1, -1, by = -.08),\n  y = -1,\n  yend = 1\n)\n\ninner_circle &lt;- tibble(\n  x = 0,\n  y = 0,\n  radius = 0.6\n)\n\narc &lt;- tibble(\n  x = 0,\n  y = 0,\n  r = .5,\n  start = seq(0, 2 * pi, length.out = 9)[-9],\n  end = seq(0, 2 * pi, length.out = 9)[-1],\n  type = c(\"A\", \"B\", \"B\", \"A\", \"A\", \"B\", \"B\", \"A\")\n)\n\nneon_rain_palette &lt;- c(\"#32faca\", \"#58d0cb\", \"#7fa5cb\", \"#a57bcc\", \"#cc51cd\")\n\np &lt;- ggplot() +\n\n  geom_segment(\n    data = hori_lines,\n    aes(x = x, xend = xend, y = y, yend = yend, color = \"lines\"),\n    size = 1\n  ) +\n\n  geom_circle(\n    data = inner_circle,\n    aes(x0 = x, y0 = y, r = radius, fill = \"circle_fill\"),\n    size = 1,\n    alpha = 0.75,\n    color = \"#1A1A1A\" # Dark border to contrast with the neon colors\n  ) +\n\n  geom_arc(\n    data = arc,\n    aes(\n      x0 = x,\n      y0 = y,\n      r = r,\n      start = start,\n      end = end,\n      color = \"arc_lines\",\n      type = type\n    ),\n    size = 1\n  ) +\n\n  scale_color_manual(\n    values = c(\n      \"lines\" = neon_rain_palette[5], # A bright purple for the lines\n      \"arc_lines\" = neon_rain_palette[1] # A bright teal for the arc\n    )\n  ) +\n\n  scale_fill_manual(\n    values = c(\n      \"circle_fill\" = neon_rain_palette[3] # A muted blue for the circle fill\n    )\n  ) +\n\n  coord_fixed() +\n  theme_void() +\n  theme(\n    legend.position = \"none\",\n    plot.background = element_rect(fill = \"#1A1A1A\")\n  )\n\nprint(p)",
    "crumbs": [
      "Resources",
      "Plot Competition 2025"
    ]
  }
]