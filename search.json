[
  {
    "objectID": "zzz.html",
    "href": "zzz.html",
    "title": "dummy file so that downlit ends up",
    "section": "",
    "text": "dummy file so that downlit ends up\nin the renv lock file.\n\nlibrary(downlit)\n# library(gitcreds)"
  },
  {
    "objectID": "resources/block-rna-resources.html",
    "href": "resources/block-rna-resources.html",
    "title": "Resources for the RNA block",
    "section": "",
    "text": "These studies below laid the methodological groundwork for RNA-sequencing, ribosome profiling, and mapping binding sites of RNA-binding proteins using UV-crosslinking based approaches (CLIP-seq/PAR-CLIP).\n\n\nMortazavi A, Williams BA, McCue K, Schaeffer L, Wold B. Mapping and quantifying mammalian transcriptomes by RNA-Seq. Nat Methods. 2008 Jul;5(7):621-8. doi: 10.1038/nmeth.1226. Epub 2008 May 30. PMID: 18516045. [Link]\n\n\n\nIngolia NT, Ghaemmaghami S, Newman JR, Weissman JS. Genome-wide analysis in vivo of translation with nucleotide resolution using ribosome profiling. Science. 2009 Apr 10;324(5924):218-23. doi: 10.1126/science.1168978. Epub 2009 Feb 12. PMID: 19213877; PMCID: PMC2746483.[Link]\n\n\n\nUle J, Jensen KB, Ruggiu M, Mele A, Ule A, Darnell RB. CLIP identifies Nova-regulated RNA networks in the brain. Science. 2003 Nov 14;302(5648):1212-5. doi: 10.1126/science.1090095. PMID: 14615540. [Link]\nHafner M, Landthaler M, Burger L, Khorshid M, Hausser J, Berninger P, Rothballer A, Ascano M Jr, Jungkamp AC, Munschauer M, Ulrich A, Wardle GS, Dewell S, Zavolan M, Tuschl T. Transcriptome-wide identification of RNA-binding protein and microRNA target sites by PAR-CLIP. Cell. 2010 Apr 2;141(1):129-41. doi: 10.1016/j.cell.2010.03.009. PMID: 20371350; PMCID: PMC2861495. [Link]",
    "crumbs": [
      "Resources",
      "RNA Block resources"
    ]
  },
  {
    "objectID": "resources/block-rna-resources.html#foundational-work",
    "href": "resources/block-rna-resources.html#foundational-work",
    "title": "Resources for the RNA block",
    "section": "",
    "text": "These studies below laid the methodological groundwork for RNA-sequencing, ribosome profiling, and mapping binding sites of RNA-binding proteins using UV-crosslinking based approaches (CLIP-seq/PAR-CLIP).\n\n\nMortazavi A, Williams BA, McCue K, Schaeffer L, Wold B. Mapping and quantifying mammalian transcriptomes by RNA-Seq. Nat Methods. 2008 Jul;5(7):621-8. doi: 10.1038/nmeth.1226. Epub 2008 May 30. PMID: 18516045. [Link]\n\n\n\nIngolia NT, Ghaemmaghami S, Newman JR, Weissman JS. Genome-wide analysis in vivo of translation with nucleotide resolution using ribosome profiling. Science. 2009 Apr 10;324(5924):218-23. doi: 10.1126/science.1168978. Epub 2009 Feb 12. PMID: 19213877; PMCID: PMC2746483.[Link]\n\n\n\nUle J, Jensen KB, Ruggiu M, Mele A, Ule A, Darnell RB. CLIP identifies Nova-regulated RNA networks in the brain. Science. 2003 Nov 14;302(5648):1212-5. doi: 10.1126/science.1090095. PMID: 14615540. [Link]\nHafner M, Landthaler M, Burger L, Khorshid M, Hausser J, Berninger P, Rothballer A, Ascano M Jr, Jungkamp AC, Munschauer M, Ulrich A, Wardle GS, Dewell S, Zavolan M, Tuschl T. Transcriptome-wide identification of RNA-binding protein and microRNA target sites by PAR-CLIP. Cell. 2010 Apr 2;141(1):129-41. doi: 10.1016/j.cell.2010.03.009. PMID: 20371350; PMCID: PMC2861495. [Link]",
    "crumbs": [
      "Resources",
      "RNA Block resources"
    ]
  },
  {
    "objectID": "resources/block-rna-resources.html#software",
    "href": "resources/block-rna-resources.html#software",
    "title": "Resources for the RNA block",
    "section": "Software",
    "text": "Software\n\nAlignment software\nSTAR and minimap2 are popular choices for short read alignment. They are fast, free, and well-maintained.\n\n\nTranscript Quantification\nSalmon is a pseuodoalignment based approach for quantifying transcripts from RNA-seq data. See the salmon documentation and documentation for importing salmon data into R using txipmort\n\n\nPeak calling\nPARalyzer is the gold-standard in peak calling for PAR-CLIP data. It models read coverage and nucleotide conversions using a kernel density estimate classification to generate a high-resolution map of RNA-protein interaction sites.",
    "crumbs": [
      "Resources",
      "RNA Block resources"
    ]
  },
  {
    "objectID": "problem-sets/ps-05.html",
    "href": "problem-sets/ps-05.html",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "",
    "text": "Your objective is to create some new extreme art using R, something either ugly or sublime. What you cannot do is be boring; your goal is to stay on the fringe.\nYour submission (a Quarto .qmd file) is due Tues Sept 2 by 5pm. If you submit an entry, you get full credit on the problem set. Entries will be anonymized and winners will selected by popular vote."
  },
  {
    "objectID": "problem-sets/ps-05.html#extreme-art-objective",
    "href": "problem-sets/ps-05.html#extreme-art-objective",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "",
    "text": "Your objective is to create some new extreme art using R, something either ugly or sublime. What you cannot do is be boring; your goal is to stay on the fringe.\nYour submission (a Quarto .qmd file) is due Tues Sept 2 by 5pm. If you submit an entry, you get full credit on the problem set. Entries will be anonymized and winners will selected by popular vote."
  },
  {
    "objectID": "problem-sets/ps-05.html#favorite-rtists",
    "href": "problem-sets/ps-05.html#favorite-rtists",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "Favorite Rtists",
    "text": "Favorite Rtists\nHere are some of my favorite generative artists who use R. Be inspired!\n\nDanielle Navarro [Art] [Github]\n\nIjeamaka Anyene [Github] and this study in particular.\nClaus Wilke [Art] [Github], a biologist at UT Austin who also wrote the book on data visualization (it’s excellent).\nThomas Lin Pederesen [Art] [Github]. I have some of his pieces in my office.\ninconvergent [Art] [Github]. It’s lisp, not R. But it’s so good.\n\nThere are several resources for color palettes, an important component of any hideous or beautiful creation.\n\nThe section in Data Viz for R on color is worth a read.\nThe colors in e.g. scale_color_brewer come from Cynthia Brewer, a cartographer who makes visually informative maps.\n\ncolor-hex has collections of complementary color palettes.\n\nThere are also several R packages that might help you build Rtistic plots.\n\n\ngganimate provides tools to bring your plots to life.\n\nggforce provides interesting geoms that build on ggplot2.\n\npatchwork provides layout functions for plots."
  },
  {
    "objectID": "problem-sets/ps-05.html#informative-but-boring.",
    "href": "problem-sets/ps-05.html#informative-but-boring.",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "Informative, but boring.",
    "text": "Informative, but boring.\nThis is an informative but relatively boring plot. NOT THE GOAL HERE.\n\nCodelibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(cowplot)\n\npenguins_clean &lt;- drop_na(penguins)\n\nggplot(\n  penguins_clean,\n  aes(\n    x = body_mass_g / 1000,\n    y = bill_length_mm\n  )\n) +\n  geom_point(\n    aes(\n      shape = sex,\n      color = species\n    )\n  ) +\n  facet_grid(~island) +\n  theme_minimal_grid() +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(\n    title = \"Analysis of geographic isolation on penguin phenotypes\",\n    x = \"Body mass (kg)\",\n    y = \"Bill length (mm)\"\n  )"
  },
  {
    "objectID": "problem-sets/ps-05.html#ugly-plots",
    "href": "problem-sets/ps-05.html#ugly-plots",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "Ugly Plots",
    "text": "Ugly Plots\nYikes. We can thank Yunus Ozekin for this abomination.\n\nCodelibrary(tidyverse)\ntitanic_tbl &lt;- as_tibble(Titanic)\n\nggplot(\n  titanic_tbl,\n  aes(\n    x = Survived,\n    y = n,\n    color = Class,\n    shape = Sex,\n    size = 6\n  )\n) +\n  geom_jitter() +\n  scale_y_sqrt() +\n  labs(\n    x = \"Not Dead?\",\n    y = \"How many? (ppl)\",\n    title = \"WhO dIEd In titaNic?\",\n    caption = \"Some lived, some died.\"\n  ) +\n  scale_x_discrete(position = \"top\") +\n  theme(\n    axis.text.x = element_text(\n      face = \"bold.italic\",\n      color = \"#993333\",\n      size = 18,\n      angle = 180\n    ),\n    axis.text.y = element_text(\n      face = \"bold\",\n      color = \"orange\",\n      size = 18,\n      angle = 135\n    ),\n    plot.background = element_rect(fill = \"darkblue\"),\n    plot.title = element_text(\n      face = \"italic\",\n      color = \"green\",\n      size = 48,\n      angle = 183\n    ),\n    plot.caption = element_text(color = \"white\", size = 22),\n    axis.title.x = element_text(size = 22, color = \"pink\", angle = 12),\n    axis.title.y = element_text(color = \"yellow\", angle = 273, size = 17),\n    legend.background = element_rect(fill = \"yellow\"),\n    legend.title = element_text(\n      angle = 71,\n      face = \"bold\",\n      color = \"purple\",\n      size = 12\n    ),\n    legend.key = element_rect(color = \"green\", fill = \"orange\"),\n    legend.text = element_text(color = \"red\", size = 14),\n    panel.background = element_rect(fill = \"yellow\"),\n    panel.grid.major.y = element_line(\n      color = \"green\",\n      linetype = \"dotdash\",\n      linewidth = 1.2\n    ),\n    panel.grid.major.x = element_line(\n      color = \"purple\",\n      linewidth = 3,\n      linetype = \"twodash\"\n    ),\n    panel.grid.minor = element_line(\n      color = \"red\",\n      linewidth = 2,\n      linetype = \"dashed\"\n    ),\n    legend.position = \"bottom\"\n  )"
  },
  {
    "objectID": "problem-sets/ps-05.html#beautiful-plots",
    "href": "problem-sets/ps-05.html#beautiful-plots",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "Beautiful Plots",
    "text": "Beautiful Plots\nThis is a piece from Ijeamaka Anyene’s ode to coord_polar() (link above). Reminds me of Miro.\n\nCodelibrary(tidyverse)\n\napply_pattern_theme &lt;- function(bg_hex, caption_hex) {\n  theme(\n    plot.background = element_rect(fill = bg_hex),\n    panel.background = element_rect(fill = bg_hex),\n    panel.grid = element_blank(),\n    plot.caption = element_text(\n      family = \"Open Sans\",\n      size = 6,\n      color = caption_hex\n    ),\n    legend.position = \"none\",\n    axis.title = element_blank(),\n    axis.text = element_blank(),\n    axis.ticks = element_blank()\n  )\n}\n\noutline &lt;- tibble(\n  x = 1,\n  xend = 7,\n  y = 15,\n  yend = 15\n)\nsegment_line &lt;- tibble(\n  x = c(1, 7),\n  xend = c(1, 7),\n  y = c(0, 2),\n  yend = 15\n)\narea &lt;- tibble(\n  x = c(3, 5, 6),\n  y = c(5, 7.5, 2),\n  type = LETTERS[1:3]\n)\npalette_values &lt;- c(\"#2a2640\", \"#a64e46\", \"#f29544\")\nggplot() +\n  geom_col(\n    data = area,\n    aes(x = x, y = y, fill = type),\n    alpha = 0.75,\n    width = 4\n  ) +\n  geom_segment(\n    data = outline,\n    aes(\n      x = x,\n      y = y,\n      xend = xend,\n      yend = yend\n    ),\n    size = 0.5\n  ) +\n  geom_segment(\n    data = segment_line,\n    aes(\n      x = x,\n      xend = xend,\n      y = y,\n      yend = yend\n    ),\n    size = 0.5\n  ) +\n  geom_point(aes(x = 5, y = 0)) +\n  scale_fill_manual(values = palette_values) +\n  scale_y_continuous(limits = c(0, 15)) +\n  scale_x_continuous(limits = c(1, 10)) +\n  coord_polar() +\n  labs(caption = \"Ijeamaka Anyene | @ijeamaka_a\") +\n  apply_pattern_theme(\n    bg_hex = \"#ded5c9\",\n    caption_hex = \"black\"\n  )\n\n\n\n\n\n\n\nHere’s another more complex geometric creation, again using coord_polar(). This will take a few seconds to render.\n\nCode# https://twitter.com/aschinchon/status/1095057262744387587\nlibrary(tidyverse)\n\nxy &lt;- seq(-2, 2, by = .005)\nexpand.grid(x = xy, y = xy) |&gt;\n  ggplot(\n    aes(\n      x = (cos(x)^2 + sin(y^2)),\n      y = (sin(y)^3 - cos(x^2))\n    )\n  ) +\n  geom_point(alpha = .01, shape = 20, size = 0) +\n  theme_void() +\n  coord_polar()"
  },
  {
    "objectID": "problem-sets/ps-03.html",
    "href": "problem-sets/ps-03.html",
    "title": "R Bootcamp Problem Set 3",
    "section": "",
    "text": "Start by loading libraries you need analysis in the code chunk below. When in doubt, start by loading the tidyverse package."
  },
  {
    "objectID": "problem-sets/ps-03.html#setup",
    "href": "problem-sets/ps-03.html#setup",
    "title": "R Bootcamp Problem Set 3",
    "section": "",
    "text": "Start by loading libraries you need analysis in the code chunk below. When in doubt, start by loading the tidyverse package."
  },
  {
    "objectID": "problem-sets/ps-03.html#problem-set",
    "href": "problem-sets/ps-03.html#problem-set",
    "title": "R Bootcamp Problem Set 3",
    "section": "Problem Set",
    "text": "Problem Set\nEach problem below is worth 5 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Aug 28.\nGrading rubric\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-sets/ps-03.html#question-1",
    "href": "problem-sets/ps-03.html#question-1",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 1",
    "text": "Question 1\nLoad the palmerpenguins package (already done above). Inspect the penguins tibble with summary() to see the distribution of variables and any missing values.\nUse drop_na() to remove rows with NA values in the penguins tibble. Calculate how many rows were removed by subtracting the new count from the original count using nrow().\nThen, use count() to explore the data and see how many penguins of each species we have. This is a simple but powerful way to understand your data!\nThen, use replace_na() to replace NA values in bill_length_mm and bill_depth_mm with a value of 0. You’ll need to:\n\nProvide the data frame as the first argument\nProvide a named list showing which columns to replace and what values to use"
  },
  {
    "objectID": "problem-sets/ps-03.html#question-2",
    "href": "problem-sets/ps-03.html#question-2",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 2",
    "text": "Question 2\nUse arrange, filter, and select on a data frame. Let’s build this step by step to understand how pipes work:\n\nImport the data set data/data_transcript_exp_tidy.csv using read_csv() and here().\n\nStep 2a: First, just sort the tibble by expression data (count) from highest to lowest level using arrange(). Use desc() to get descending order.\n\nStep 2b: Then add filter() to keep only rows where count &gt; 100. Chain this with the pipe operator.\n\nStep 2c: Finally, add select() to choose all columns except for type. Use the - operator to exclude columns."
  },
  {
    "objectID": "problem-sets/ps-03.html#question-3",
    "href": "problem-sets/ps-03.html#question-3",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 3",
    "text": "Question 3\nHow will you:\n\ncreate a new column log10count that contains log10 transformed count values using mutate() and log10() and\nrearrange the columns in the following order: ensembl_transcript_id, type, time, replicate, count, log10count using select().\n\nBefore showing the solution, remember: - mutate() adds new columns (or modifies existing ones) - it keeps all existing columns - select() chooses columns and can reorder them - list them in the order you want"
  },
  {
    "objectID": "problem-sets/ps-03.html#question-4",
    "href": "problem-sets/ps-03.html#question-4",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 4",
    "text": "Question 4\nLet’s explore grouping operations step by step. We’ll build your understanding progressively, starting with simple examples and then combining concepts.\nStep 4a: First, try a simple grouping operation. Calculate the total count per transcript (ignoring time). Use:\n\n\ngroup_by() to group by transcript ID\n\nsummarize() to calculate the sum of counts\n\n.groups = \"drop\" to remove grouping afterward (good practice!)\n\nStep 4b: Now calculate a per-transcript sum, while keeping the time information (group by both transcript and time). This creates separate groups for each combination of transcript AND time:"
  },
  {
    "objectID": "problem-sets/ps-03.html#question-5",
    "href": "problem-sets/ps-03.html#question-5",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 5",
    "text": "Question 5\nCreate meaningful categories from your data using case_when(). This function lets you create new variables based on multiple conditions - it’s like a more powerful version of if_else().\nCategorize the expression levels in the count column into meaningful groups: - “Low” for counts less than 50 - “Medium” for counts between 50 and 200 (inclusive of 50, exclusive of 200) - “High” for counts between 200 and 1000 (inclusive of 200, exclusive of 1000) - “Very High” for counts 1000 and above\nUse case_when() inside mutate() to create a new column called expression_level, then use count() to see how many transcripts fall into each category."
  },
  {
    "objectID": "problem-sets/ps-03.html#question-6",
    "href": "problem-sets/ps-03.html#question-6",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 6",
    "text": "Question 6\nTry to state and answer a new question! Stitch together several dplyr fuctions to answer a new question. I’m trying to wean you off the fill-in-the-blanks approach and get you to think independently using the tidyverse.\nHere are some ideas to get you started, you don’t have to use any of them:\n\nWhich transcript has the highest expression level at each time point? (Hint: use dplyr::slice_max() after grouping by time)\nWhat is the average expression level for each transcript across all time points? (Hint: use group_by() and summarize())\nWhich time point has the highest total expression level across all transcripts? (Hint: group by time and summarize total count)"
  },
  {
    "objectID": "problem-sets/ps-01.html",
    "href": "problem-sets/ps-01.html",
    "title": "Problem Set 1 Key",
    "section": "",
    "text": "Each problem below is worth 5 points.\nThe problem set is due 12pm on Aug 26.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-sets/ps-01.html#problem-set",
    "href": "problem-sets/ps-01.html#problem-set",
    "title": "Problem Set 1 Key",
    "section": "",
    "text": "Each problem below is worth 5 points.\nThe problem set is due 12pm on Aug 26.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-sets/ps-01.html#setup",
    "href": "problem-sets/ps-01.html#setup",
    "title": "Problem Set 1 Key",
    "section": "Setup",
    "text": "Setup\nStart by loading libraries you need analysis below. When in doubt, start by loading the tidyverse package.\n\nlibrary(___)"
  },
  {
    "objectID": "problem-sets/ps-01.html#question-1",
    "href": "problem-sets/ps-01.html#question-1",
    "title": "Problem Set 1 Key",
    "section": "Question 1",
    "text": "Question 1\nCreate 3 different vectors called x, y, and z:\n\n\nx should be character vector of length 5 (hint: use LETTERS or letters)\n\ny should be a numeric vector of length 5 (hint: try 1:5 or c(1, 2, 3, 4, 5))\n\nz should be a logical vector of length 5 (hint: use TRUE and FALSE values)\n\nUse length() to calculate the length of each vector."
  },
  {
    "objectID": "problem-sets/ps-01.html#question-2",
    "href": "problem-sets/ps-01.html#question-2",
    "title": "Problem Set 1 Key",
    "section": "Question 2",
    "text": "Question 2\nUsing the vectors you created above, create a new tibble with column names x, y, and z. Use the tibble() function to combine your vectors into a data frame.\nUse nrow() and ncol() to calculate the number of rows and columns, both with and without the pipe operator.\nUse glimpse() to get a quick overview of your tibble - this shows data types and first few values.\nWhat do you notice about the length of the vectors and the number of rows?\n\ntbl &lt;- tibble(___)\n\nnrow(___)\nncol(___)\n\n# Get a quick overview\nglimpse(___)\n\nAnswer\nThe length of the vectors and the number of rows are the same, because tibble columns are simply the vectors we started with."
  },
  {
    "objectID": "problem-sets/ps-01.html#question-3",
    "href": "problem-sets/ps-01.html#question-3",
    "title": "Problem Set 1 Key",
    "section": "Question 3",
    "text": "Question 3\nLet’s explore the penguins dataset that we loaded.\n\nLook at the number of rows with nrow() - this tells us how many penguins are in the dataset\nLook at the number of columns with ncol() - this tells us how many variables we measured\nLook at the column names with names() - this shows us what variables we have\nGet a glimpse of the data with glimpse() - this shows data types and sample values\n\n\n# Explore the penguins dataset\nnrow(___)\nncol(___)\nnames(___)\nglimpse(___)"
  },
  {
    "objectID": "problem-sets/ps-01.html#question-4",
    "href": "problem-sets/ps-01.html#question-4",
    "title": "Problem Set 1 Key",
    "section": "Question 4",
    "text": "Question 4\nNext we will think about data tidying. Let’s start by analyzing the penguins dataset.\nPart A: Is the penguins dataset tidy? To determine this, we need to think about the three principles of tidy data:\n\nEach variable forms a column\nEach observation forms a row\nEach type of observational unit forms a table\n\nLook at the penguins dataset and answer:\n\nWhat are the variables in the dataset? (Hint: use names(penguins) to see them)\nDoes each column represent a single variable?\nDoes each row represent a single penguin observation?\n\nPart B: Now let’s examine some datasets that are NOT tidy. Use data() to see available datasets, then look at these two examples:\nExample 1: anscombe - This is a classic statistics dataset.\n\n# Look at the anscombe dataset. Start by reading the help page with `?anscombe`\n\nIs anscombe tidy? Think about:\n\nWhat are the actual variables? (Hint: x and y coordinates for different datasets)\nHow many different datasets are encoded in the column names?\nWhat would a tidy version look like?\n\nExample 2: Choose another dataset - Pick one more dataset from data() and analyze whether it’s tidy:\n\n# Look at available datasets\ndata()\n\nIs this other data set tidy? Think about:\n\nWhat are the actual variables? (Hint: x and y coordinates for different datasets)\nHow many different datasets are encoded in the column names?\nWhat would a tidy version look like?\n\nPart C: Write a brief explanation (2-3 sentences) for each dataset about:\n\nWhether it’s tidy or not\nWhat makes it tidy/untidy\nWhat the variables actually represent\n\nYour Analysis:\npenguins: [Your answer here]\nanscombe: [Your answer here]\n[Your chosen dataset]: [Your answer here]"
  },
  {
    "objectID": "problem-sets/ps-01.html#submit",
    "href": "problem-sets/ps-01.html#submit",
    "title": "Problem Set 1 Key",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of the Posit Cloud project (NOT the HTML link) into the problem set on Canvas."
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html",
    "href": "problem-set-keys/ps-key-04.html",
    "title": "R Bootcamp Problem Set 4",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Sept 1."
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#problem-set",
    "href": "problem-set-keys/ps-key-04.html#problem-set",
    "title": "R Bootcamp Problem Set 4",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Sept 1."
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#grading-rubric",
    "href": "problem-set-keys/ps-key-04.html#grading-rubric",
    "title": "R Bootcamp Problem Set 4",
    "section": "Grading rubric",
    "text": "Grading rubric\n\nEverything is good: full points\nPartially correct answer: depends on how many steps are correct\nReasonable attempt: half points"
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#question-1-5-points",
    "href": "problem-set-keys/ps-key-04.html#question-1-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 1 5 points\n",
    "text": "Question 1 5 points\n\n\nLoad the tidyverse and here packages using library().\nImport datasets: data/data_rna_protein.csv.gz using read_csv() and here().\n\ndata_rna_protein.csv.gz: This is a combined dataset from an RNAseq and SILAC proteomics experiment, where a transcription factor (TF) was differentially expressed and the fold change in RNA and protein calculated between TF-expressing and non-expressing cells.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950\n\nexp_tbl &lt;- read_csv(\n  here(\"data/bootcamp/data_rna_protein.csv.gz\")\n)\n\nRows: 21282 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): geneid\ndbl (16): iDUX4_logFC, iDUX4_logCPM, iDUX4_LR, iDUX4_pval, iDUX4_fdr, hl.rat...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#question-2-5-points",
    "href": "problem-set-keys/ps-key-04.html#question-2-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 2 5 points\n",
    "text": "Question 2 5 points\n\nLet’s build a data processing workflow step by step. This teaches you how to build complex pipelines gradually - a key skill in data analysis.\nStep 1: First, explore the data so you know what you’re working with. Use glimpse() to see column types and summary() to see distributions:\n\n# Always explore your data first!\nexp_tbl |&gt; glimpse()\n\nRows: 21,282\nColumns: 17\n$ geneid         &lt;chr&gt; \"RFPL1\", \"DUXA\", \"RFPL2\", \"LEUTX\", \"RFPL3S\", \"ZSCAN5C\",…\n$ iDUX4_logFC    &lt;dbl&gt; 9.366333, 8.728522, 8.582827, 8.136148, 8.031894, 7.837…\n$ iDUX4_logCPM   &lt;dbl&gt; 8.568344, 9.740241, 9.760915, 8.702694, 5.563714, 6.532…\n$ iDUX4_LR       &lt;dbl&gt; 2910.21184, 5195.45733, 4397.04659, 3276.44418, 392.901…\n$ iDUX4_pval     &lt;dbl&gt; 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 1.93e-87, 5.12e…\n$ iDUX4_fdr      &lt;dbl&gt; 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 8.64e-86, 5.76e…\n$ hl.ratio       &lt;dbl&gt; 4.415276, 8.919536, 3.032258, 7.151629, NA, 3.910093, N…\n$ area           &lt;dbl&gt; 222742.2, 3523464.3, 119468.9, 1579141.5, NA, 307343.6,…\n$ protein.length &lt;dbl&gt; 317, 204, 378, 168, NA, 496, NA, NA, 465, NA, 474, NA, …\n$ rep            &lt;dbl&gt; 3.760000, 3.500000, 3.888889, 3.333333, NA, 4.000000, N…\n$ IQR            &lt;dbl&gt; 1.952243, 6.435921, 1.694725, 5.303046, NA, 0.000000, N…\n$ QCoD           &lt;dbl&gt; 0.4421564, 0.7215533, 0.5588985, 0.7415158, NA, 0.00000…\n$ count          &lt;dbl&gt; 25, 32, 9, 6, NA, 1, NA, NA, 21, NA, 10, NA, 1, 80, NA,…\n$ mean           &lt;dbl&gt; 0.004465732, -0.003224870, 0.024341945, -0.009047206, N…\n$ sd             &lt;dbl&gt; 0.17197783, 0.13994973, 0.29149227, 0.38073424, NA, 2.0…\n$ zscore         &lt;dbl&gt; 25.647554, 63.756902, 10.319026, 18.807544, NA, 1.89808…\n$ pval           &lt;dbl&gt; 4.500000e-145, 0.000000e+00, 5.780000e-25, 6.550000e-79…\n\nexp_tbl |&gt; summary()\n\n    geneid           iDUX4_logFC       iDUX4_logCPM       iDUX4_LR        \n Length:21282       Min.   :-3.4751   Min.   : 1.264   Min.   :    0.000  \n Class :character   1st Qu.:-0.9996   1st Qu.: 3.385   1st Qu.:    2.068  \n Mode  :character   Median :-0.3772   Median : 4.780   Median :    9.049  \n                    Mean   :-0.1574   Mean   : 4.801   Mean   :   53.971  \n                    3rd Qu.: 0.3977   3rd Qu.: 6.064   3rd Qu.:   30.949  \n                    Max.   : 9.3663   Max.   :14.915   Max.   :13648.327  \n                    NA's   :8950      NA's   :8950     NA's   :8950       \n   iDUX4_pval       iDUX4_fdr         hl.ratio             area          \n Min.   :0.0000   Min.   :0.0000   Min.   :-19.6540   Min.   :     7952  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: -0.3842   1st Qu.:   290641  \n Median :0.0026   Median :0.0052   Median : -0.0529   Median :   545151  \n Mean   :0.1341   Mean   :0.1520   Mean   : -0.0306   Mean   :  1112496  \n 3rd Qu.:0.1504   3rd Qu.:0.2002   3rd Qu.:  0.2283   3rd Qu.:  1014351  \n Max.   :0.9976   Max.   :0.9980   Max.   : 19.3091   Max.   :878105037  \n NA's   :8950     NA's   :8950     NA's   :15969      NA's   :15969      \n protein.length        rep             IQR               QCoD          \n Min.   :  19.0   Min.   :3.000   Min.   : 0.0000   Min.   :-7521.713  \n 1st Qu.: 260.0   1st Qu.:3.333   1st Qu.: 0.3805   1st Qu.:   -2.960  \n Median : 433.0   Median :3.495   Median : 0.8014   Median :    0.000  \n Mean   : 603.4   Mean   :3.446   Mean   : 1.1079   Mean   :   -1.100  \n 3rd Qu.: 728.0   3rd Qu.:3.560   3rd Qu.: 1.1911   3rd Qu.:    2.122  \n Max.   :8797.0   Max.   :4.000   Max.   :26.1119   Max.   : 3618.200  \n NA's   :15969    NA's   :15969   NA's   :15969     NA's   :15969      \n     count             mean               sd             zscore        \n Min.   :   1.0   Min.   :-0.1496   Min.   :0.0152   Min.   :-77.7125  \n 1st Qu.:   2.0   1st Qu.:-0.0024   1st Qu.:0.1453   1st Qu.: -1.1955  \n Median :   8.0   Median : 0.0024   Median :0.3121   Median : -0.1833  \n Mean   :  42.1   Mean   : 0.0239   Mean   :0.6794   Mean   :  0.2260  \n 3rd Qu.:  31.0   3rd Qu.: 0.0315   3rd Qu.:1.3565   3rd Qu.:  0.7153  \n Max.   :2646.0   Max.   : 0.3272   Max.   :2.5400   Max.   :105.5495  \n NA's   :15969    NA's   :15969     NA's   :15969    NA's   :15969     \n      pval       \n Min.   :0.0000  \n 1st Qu.:0.0315  \n Median :0.3171  \n Mean   :0.3816  \n 3rd Qu.:0.7035  \n Max.   :1.0000  \n NA's   :15969   \n\n\nStep 2: Select only the columns we need:\n\n\ngeneid (gene identifier)\n\niDUX4_logFC (RNA fold change)\n\niDUX4_fdr (RNA pvalue)\n\nhl.ratio (protein fold change)\n\npval (protein pvalue)\n\nUse select() and list the columns you want to keep:\n\nexp_tbl |&gt;\n  select(geneid, iDUX4_logFC, iDUX4_fdr, hl.ratio, pval)\n\n# A tibble: 21,282 × 5\n   geneid   iDUX4_logFC iDUX4_fdr hl.ratio       pval\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 RFPL1           9.37 0             4.42  4.50e-145\n 2 DUXA            8.73 0             8.92  0        \n 3 RFPL2           8.58 0             3.03  5.78e- 25\n 4 LEUTX           8.14 0             7.15  6.55e- 79\n 5 RFPL3S          8.03 8.64e- 86    NA    NA        \n 6 ZSCAN5C         7.84 5.76e-169     3.91  5.77e-  2\n 7 USP29           7.71 4.48e- 36    NA    NA        \n 8 FAM189A2        7.68 1.46e- 41    NA    NA        \n 9 CCNA1           7.66 0             5.11  7.10e-169\n10 ZNF280A         7.55 2.35e- 54    NA    NA        \n# ℹ 21,272 more rows\n\n\nStep 3: Rename columns for clarity (this makes your code more readable).\nUse dplyr::rename() with the pattern new_name = old_name, ...:\n\nexp_tbl |&gt;\n  select(geneid, iDUX4_logFC, iDUX4_fdr, hl.ratio, pval) |&gt;\n  rename(\n    rna_FC = iDUX4_logFC,\n    rna_pval = iDUX4_fdr,\n    protein_FC = hl.ratio,\n    protein_pval = pval\n  )\n\n# A tibble: 21,282 × 5\n   geneid   rna_FC  rna_pval protein_FC protein_pval\n   &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 RFPL1      9.37 0               4.42    4.50e-145\n 2 DUXA       8.73 0               8.92    0        \n 3 RFPL2      8.58 0               3.03    5.78e- 25\n 4 LEUTX      8.14 0               7.15    6.55e- 79\n 5 RFPL3S     8.03 8.64e- 86      NA      NA        \n 6 ZSCAN5C    7.84 5.76e-169       3.91    5.77e-  2\n 7 USP29      7.71 4.48e- 36      NA      NA        \n 8 FAM189A2   7.68 1.46e- 41      NA      NA        \n 9 CCNA1      7.66 0               5.11    7.10e-169\n10 ZNF280A    7.55 2.35e- 54      NA      NA        \n# ℹ 21,272 more rows\n\n\nStep 4: Clean the data by removing rows with missing values. Use drop_na() to remove rows with any missing values, and distinct() to remove duplicate rows:\n\nexp_tbl |&gt;\n  select(geneid, iDUX4_logFC, iDUX4_fdr, hl.ratio, pval) |&gt;\n  rename(\n    rna_FC = iDUX4_logFC,\n    rna_pval = iDUX4_fdr,\n    protein_FC = hl.ratio,\n    protein_pval = pval\n  ) |&gt;\n  drop_na() |&gt; # Remove rows with any missing values\n  distinct() # Remove duplicate rows\n\n# A tibble: 4,931 × 5\n   geneid   rna_FC  rna_pval protein_FC protein_pval\n   &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 RFPL1      9.37 0               4.42    4.50e-145\n 2 DUXA       8.73 0               8.92    0        \n 3 RFPL2      8.58 0               3.03    5.78e- 25\n 4 LEUTX      8.14 0               7.15    6.55e- 79\n 5 ZSCAN5C    7.84 5.76e-169       3.91    5.77e-  2\n 6 CCNA1      7.66 0               5.11    7.10e-169\n 7 PRAMEF1    7.54 0               4.82    3.49e- 76\n 8 TPRX1      7.29 2.41e-132       7.35    2.85e-  4\n 9 PRAMEF12   7.25 0               7.55    0        \n10 RFPL4B     7.16 0               7.46    0        \n# ℹ 4,921 more rows\n\n\nStep 5: Finally, arrange the data and save it. Use arrange() to sort by RNA fold change (high to low), then protein fold change (low to high):\n\nexp_tbl_subset &lt;- exp_tbl |&gt;\n  select(geneid, iDUX4_logFC, iDUX4_fdr, hl.ratio, pval) |&gt;\n  rename(\n    rna_FC = iDUX4_logFC,\n    rna_pval = iDUX4_fdr,\n    protein_FC = hl.ratio,\n    protein_pval = pval\n  ) |&gt;\n  drop_na() |&gt;\n  distinct() |&gt;\n  arrange(desc(rna_FC), protein_FC) # Sort by RNA fold change (high to low), then protein fold change (low to high)\n\nexp_tbl_subset\n\n# A tibble: 4,931 × 5\n   geneid   rna_FC  rna_pval protein_FC protein_pval\n   &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 RFPL1      9.37 0               4.42    4.50e-145\n 2 DUXA       8.73 0               8.92    0        \n 3 RFPL2      8.58 0               3.03    5.78e- 25\n 4 LEUTX      8.14 0               7.15    6.55e- 79\n 5 ZSCAN5C    7.84 5.76e-169       3.91    5.77e-  2\n 6 CCNA1      7.66 0               5.11    7.10e-169\n 7 PRAMEF1    7.54 0               4.82    3.49e- 76\n 8 TPRX1      7.29 2.41e-132       7.35    2.85e-  4\n 9 PRAMEF12   7.25 0               7.55    0        \n10 RFPL4B     7.16 0               7.46    0        \n# ℹ 4,921 more rows"
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#question-3-5-points",
    "href": "problem-set-keys/ps-key-04.html#question-3-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 3 5 points\n",
    "text": "Question 3 5 points\n\nLet’s practice good data analysis habits by checking for potential issues. Quality control is essential in real data analysis.\nCheck for duplicates and missing values:\n\nUse count() to check for duplicate genes\nUse summarize() with across() to count missing values in all columns\nUse summary statistics to understand data distributions\n\n\n# Check for duplicate genes (there shouldn't be any after distinct())\ndup_tbl &lt;-\n  exp_tbl_subset |&gt;\n  count(geneid) |&gt;\n  filter(n &gt; 1) # Any genes appearing more than once?\n\nThere are 14 duplicate genes in the dataset.\n\n# Summary of missing values by column\nexp_tbl_subset |&gt;\n  summarize(\n    across(everything(), ~ sum(is.na(.)))\n  )\n\n# A tibble: 1 × 5\n  geneid rna_FC rna_pval protein_FC protein_pval\n   &lt;int&gt;  &lt;int&gt;    &lt;int&gt;      &lt;int&gt;        &lt;int&gt;\n1      0      0        0          0            0\n\n\n\n# Look at the distribution of our main variables\nexp_tbl_subset |&gt;\n  summarize(\n    across(\n      c(rna_FC, protein_FC),\n      list(\n        mean = ~ mean(., na.rm = TRUE),\n        median = ~ median(., na.rm = TRUE),\n        sd = ~ sd(., na.rm = TRUE)\n      )\n    ),\n    .groups = \"drop\"\n  )\n\n# A tibble: 1 × 6\n  rna_FC_mean rna_FC_median rna_FC_sd protein_FC_mean protein_FC_median\n        &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;           &lt;dbl&gt;             &lt;dbl&gt;\n1      -0.176        -0.309      1.12         -0.0376           -0.0543\n# ℹ 1 more variable: protein_FC_sd &lt;dbl&gt;\n\n\nFor your reference, here are three different ways to write the same function inside across(). They all compute the mean while ignoring NA values.\n\nexp_tbl_subset |&gt;\n  summarize(\n    across(\n      c(rna_FC, protein_FC),\n      list(\n        # Three different ways to write the same function\n        mean1 = ~ mean(., na.rm = TRUE),\n        mean2 = function(x) mean(, na.rm = TRUE),\n        mean3 = \\(x) mean(x, na.rm = TRUE),\n      )\n    )\n  )"
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#question-4-5-points",
    "href": "problem-set-keys/ps-key-04.html#question-4-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 4 5 points\n",
    "text": "Question 4 5 points\n\nHow well do the overall rna_FC and protein_FC values correlate in this experiment? We’ll explore this with visualization and statistics.\nStep 1: Create a scatter plot of rna_FC vs protein_FC using ggplot(). Use:\n\n\naes() to map x and y variables\n\ngeom_point() to create the scatter plot\n\nlabs() to add informative axis labels and title\n\n\nggplot(\n  exp_tbl_subset,\n  aes(\n    x = rna_FC,\n    y = protein_FC\n  )\n) +\n  geom_point() +\n  labs(\n    x = \"RNA Fold Change (log2)\",\n    y = \"Protein Fold Change (log2)\",\n    title = \"RNA vs Protein Expression Changes\"\n  )\n\n\n\n\n\n\n\nStep 2: Add reference lines to help interpret the correlation. Use:\n\n\ngeom_abline(slope = 1, intercept = 0) for perfect correlation line\n\ngeom_smooth(method = \"lm\", se = FALSE) for the computed trend line\nadjust the geom_point() aesthetic to alpha = 0.6, making points slightly transparent for better visualization\n\n\nggplot(\n  exp_tbl_subset,\n  aes(\n    x = rna_FC,\n    y = protein_FC\n  )\n) +\n  geom_point(alpha = 0.6) + # Make points a bit transparent\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linewidth = 1) + # Perfect correlation line\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\", linewidth = 1) + # Actual relationship\n  labs(\n    x = \"RNA Fold Change (log2)\",\n    y = \"Protein Fold Change (log2)\",\n    title = \"RNA vs Protein Expression Changes\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nStep 3: Calculate the correlation coefficient using cor(). Use Spearman correlation since it’s robust to outliers. Use ?cor to see the function documentation. You will need to specify two vectors for the calculation, and it’s easiest to provide them using the $ operator to extract columns from the data frame.\n\nrna_prot_cor &lt;- cor(\n  exp_tbl_subset$rna_FC,\n  exp_tbl_subset$protein_FC,\n  method = \"spearman\"\n)\n\nrna_prot_cor\n\n[1] 0.3458433\n\n\nAnswer\nThe green line shows perfect correlation (y = x), and the blue line shows the actual relationship in our data. The Spearman correlation is 0.346, indicating a strong positive correlation between RNA and protein changes, but not perfect correlation."
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#submit",
    "href": "problem-set-keys/ps-key-04.html#submit",
    "title": "R Bootcamp Problem Set 4",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of this Posit Cloud project into the problem set on Canvas."
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html",
    "href": "problem-set-keys/ps-key-02.html",
    "title": "Problem Set 2 Key",
    "section": "",
    "text": "Each problem below is worth 4 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Aug 27.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html#problem-set",
    "href": "problem-set-keys/ps-key-02.html#problem-set",
    "title": "Problem Set 2 Key",
    "section": "",
    "text": "Each problem below is worth 4 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Aug 27.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html#question-1",
    "href": "problem-set-keys/ps-key-02.html#question-1",
    "title": "Problem Set 2 Key",
    "section": "Question 1",
    "text": "Question 1\nStart by loading the libraries you need for analysis below. When in doubt, start by loading the tidyverse package. You should also load here.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950\n\n\nNow import the dataset data_transcript_exp_subset using the readr package. Use read_csv() to import the file.\nThe file is located at data/data_transcript_exp_subset.csv.gz - use here() to create the complete path.\n\nx &lt;- read_csv(here(\"data/bootcamp/data_transcript_exp_subset.csv.gz\"))\n\nRows: 100 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): ensembl_transcript_id\ndbl (6): rna_0h_rep1, rna_0h_rep2, rna_0h_rep3, rna_14h_rep1, rna_14h_rep2, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html#question-2",
    "href": "problem-set-keys/ps-key-02.html#question-2",
    "title": "Problem Set 2 Key",
    "section": "Question 2",
    "text": "Question 2\nExplore the dataset. Is this dataset tidy? If not, why not?\nThis data frame is a subset (100 lines) of transcript-level gene expression data where transcript abundance was measured at two different time points of a certain treatment conducted in triplicates. The column names have the format of molecule_time_replicate\nFirst, explore the structure of the dataset using some of the functions we learned in class. Try using glimpse(), summary(), and names() to understand the data structure.\n\nx\n\n# A tibble: 100 × 7\n   ensembl_transcript_id        rna_0h_rep1 rna_0h_rep2 rna_0h_rep3 rna_14h_rep1\n   &lt;chr&gt;                              &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n 1 ENST00000327044.6_51_2298          243         322         303         177   \n 2 ENST00000338591.7_360_2034          19          17          15           9   \n 3 ENST00000379389.4_176_647           45          53          48          11   \n 4 ENST00000379370.6_1158_6186         42          50          52          32   \n 5 ENST00000379339.5_212_1352          17          19          25           3   \n 6 ENST00000263741.11_1328_1496        27.5        33.7        36.3        22.5 \n 7 ENST00000360001.10_285_1350        158         170.        171.        121   \n 8 ENST00000263741.11_315_1338        148.        162.        158.        116.  \n 9 ENST00000379198.3_138_1002          11          21          23           6   \n10 ENST00000347370.6_475_1096          27.3        23.8        28.5         7.33\n# ℹ 90 more rows\n# ℹ 2 more variables: rna_14h_rep2 &lt;dbl&gt;, rna_14h_rep3 &lt;dbl&gt;\n\n\n\n# Let's explore the data more systematically\n# Look at the column names\nnames(x)\n\n[1] \"ensembl_transcript_id\" \"rna_0h_rep1\"           \"rna_0h_rep2\"          \n[4] \"rna_0h_rep3\"           \"rna_14h_rep1\"          \"rna_14h_rep2\"         \n[7] \"rna_14h_rep3\"         \n\n\n\nsummary(x)\n\n ensembl_transcript_id  rna_0h_rep1       rna_0h_rep2        rna_0h_rep3      \n Length:100            Min.   :   0.00   Min.   :    0.00   Min.   :    0.00  \n Class :character      1st Qu.:  10.70   1st Qu.:   11.88   1st Qu.:   11.12  \n Mode  :character      Median :  27.41   Median :   31.05   Median :   31.91  \n                       Mean   : 173.31   Mean   :  196.08   Mean   :  186.10  \n                       3rd Qu.:  87.08   3rd Qu.:  105.00   3rd Qu.:   88.33  \n                       Max.   :9802.00   Max.   :11144.00   Max.   :10619.00  \n  rna_14h_rep1       rna_14h_rep2       rna_14h_rep3     \n Min.   :   0.000   Min.   :   0.000   Min.   :   0.000  \n 1st Qu.:   3.875   1st Qu.:   3.962   1st Qu.:   5.000  \n Median :  10.435   Median :   9.665   Median :   9.665  \n Mean   : 102.875   Mean   :  93.370   Mean   : 111.515  \n 3rd Qu.:  41.000   3rd Qu.:  38.750   3rd Qu.:  48.750  \n Max.   :5292.000   Max.   :5090.000   Max.   :6012.000  \n\n\n\nglimpse(x)\n\nRows: 100\nColumns: 7\n$ ensembl_transcript_id &lt;chr&gt; \"ENST00000327044.6_51_2298\", \"ENST00000338591.7_…\n$ rna_0h_rep1           &lt;dbl&gt; 243.00, 19.00, 45.00, 42.00, 17.00, 27.50, 158.0…\n$ rna_0h_rep2           &lt;dbl&gt; 322.00, 17.00, 53.00, 50.00, 19.00, 33.67, 169.6…\n$ rna_0h_rep3           &lt;dbl&gt; 303.00, 15.00, 48.00, 52.00, 25.00, 36.33, 171.3…\n$ rna_14h_rep1          &lt;dbl&gt; 177.00, 9.00, 11.00, 32.00, 3.00, 22.50, 121.00,…\n$ rna_14h_rep2          &lt;dbl&gt; 177.00, 5.00, 5.00, 31.00, 0.00, 29.17, 124.17, …\n$ rna_14h_rep3          &lt;dbl&gt; 239.00, 8.00, 14.00, 30.00, 2.00, 27.33, 155.33,…\n\n\nComment on whether this dataset is tidy, and if not, list the reasons why.\nHint: In a tidy dataframe, every column represents a single variable and every row represents a single observation\nAnswer\nIt is not tidy because: 1. The time points and replicates are not in their own columns 2. Multiple variables (molecule type, time, replicate) are encoded in column names 3. Each row contains multiple observations (different time points and replicates)"
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html#question-3",
    "href": "problem-set-keys/ps-key-02.html#question-3",
    "title": "Problem Set 2 Key",
    "section": "Question 3",
    "text": "Question 3\nHow will you reshape the data frame so that each row has only one experimental observation?\nBefore we reshape, let’s think about what we want:\n\nWhich column should stay the same? (The transcript ID)\nWhich columns contain the measurements? (All the others)\nWhat should we call the new column names?\n\nUse pivot_longer() to reshape the data. You’ll want to:\n\nKeep the ensembl_transcript_id column as-is (use cols = -ensembl_transcript_id)\nCreate a new column for the condition names (use names_to = \"condition\")\nCreate a new column for the values (use values_to = \"count\")\n\n\n# Reshape the data so each row is one observation\nx_long &lt;-\n  pivot_longer(\n    x,\n    cols = -ensembl_transcript_id, # everything except the ID column\n    names_to = \"condition\", # new column for the condition names\n    values_to = \"count\" # new column for the count values\n  )\n\nx_long\n\n# A tibble: 600 × 3\n   ensembl_transcript_id      condition    count\n   &lt;chr&gt;                      &lt;chr&gt;        &lt;dbl&gt;\n 1 ENST00000327044.6_51_2298  rna_0h_rep1    243\n 2 ENST00000327044.6_51_2298  rna_0h_rep2    322\n 3 ENST00000327044.6_51_2298  rna_0h_rep3    303\n 4 ENST00000327044.6_51_2298  rna_14h_rep1   177\n 5 ENST00000327044.6_51_2298  rna_14h_rep2   177\n 6 ENST00000327044.6_51_2298  rna_14h_rep3   239\n 7 ENST00000338591.7_360_2034 rna_0h_rep1     19\n 8 ENST00000338591.7_360_2034 rna_0h_rep2     17\n 9 ENST00000338591.7_360_2034 rna_0h_rep3     15\n10 ENST00000338591.7_360_2034 rna_14h_rep1     9\n# ℹ 590 more rows\n\n\nQuestion 4\nHow will you modify the dataframe so that multiple variables are not present in a single column?\nUse separate_wider_delim() to split the condition column into separate variables. You need to:\n\nSpecify which column to separate (condition)\nSpecify the delimiter character (delim = \"_\")\nProvide the new column names (names = c(\"molecule\", \"timepoint\", \"replicate\"))\n\n\nx_tidy &lt;-\n  separate_wider_delim(\n    x_long,\n    condition,\n    delim = \"_\",\n    names = c(\"molecule\", \"timepoint\", \"replicate\")\n  )\n\nx_tidy\n\n# A tibble: 600 × 5\n   ensembl_transcript_id      molecule timepoint replicate count\n   &lt;chr&gt;                      &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;\n 1 ENST00000327044.6_51_2298  rna      0h        rep1        243\n 2 ENST00000327044.6_51_2298  rna      0h        rep2        322\n 3 ENST00000327044.6_51_2298  rna      0h        rep3        303\n 4 ENST00000327044.6_51_2298  rna      14h       rep1        177\n 5 ENST00000327044.6_51_2298  rna      14h       rep2        177\n 6 ENST00000327044.6_51_2298  rna      14h       rep3        239\n 7 ENST00000338591.7_360_2034 rna      0h        rep1         19\n 8 ENST00000338591.7_360_2034 rna      0h        rep2         17\n 9 ENST00000338591.7_360_2034 rna      0h        rep3         15\n10 ENST00000338591.7_360_2034 rna      14h       rep1          9\n# ℹ 590 more rows\n\n\nQuestion 5\nHow will you save your output as a TSV file?\nUse write_tsv() from the readr package to save your tidy data. Provide the data object and a filename.\nHint: Use the readr cheatsheet at the bottom of this page to figure this out.\nAfter running your new code, you should have a new file called transcripts.tidy.tsv in your working directory.\n\nwrite_tsv(x_tidy, \"transcripts.tidy.tsv\")\n\nQuestion 6\nCan you reverse the process? How would you go from tidy back to wide format?\nUse pivot_wider() to go from the tidy format back to the original wide format. You need to:\n\nSpecify where the new column names come from (names_from = c(molecule, timepoint, replicate))\nSpecify where the values come from (values_from = count)\nSpecify how to combine the names (names_sep = \"_\")\n\n\n# Going back to wide format\npivot_wider(\n  x_tidy,\n  names_from = c(molecule, timepoint, replicate),\n  values_from = count,\n  names_sep = \"_\"\n)\n\n# A tibble: 100 × 7\n   ensembl_transcript_id        rna_0h_rep1 rna_0h_rep2 rna_0h_rep3 rna_14h_rep1\n   &lt;chr&gt;                              &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n 1 ENST00000327044.6_51_2298          243         322         303         177   \n 2 ENST00000338591.7_360_2034          19          17          15           9   \n 3 ENST00000379389.4_176_647           45          53          48          11   \n 4 ENST00000379370.6_1158_6186         42          50          52          32   \n 5 ENST00000379339.5_212_1352          17          19          25           3   \n 6 ENST00000263741.11_1328_1496        27.5        33.7        36.3        22.5 \n 7 ENST00000360001.10_285_1350        158         170.        171.        121   \n 8 ENST00000263741.11_315_1338        148.        162.        158.        116.  \n 9 ENST00000379198.3_138_1002          11          21          23           6   \n10 ENST00000347370.6_475_1096          27.3        23.8        28.5         7.33\n# ℹ 90 more rows\n# ℹ 2 more variables: rna_14h_rep2 &lt;dbl&gt;, rna_14h_rep3 &lt;dbl&gt;"
  },
  {
    "objectID": "prepare/prepare-08.html",
    "href": "prepare/prepare-08.html",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look through this study from Brauer et al. This is a rich data set for exploring relationships between gene expression and cellular physiology. Focus on familiarizing yourself with the design of the experiment.\n\nBrauer MJ, Huttenhower C, Airoldi EM, Rosenstein R, Matese JC, Gresham D, Boer VM, Troyanskaya OG, Botstein D. Coordination of growth rate, cell cycle, stress response, and metabolic activity in yeast. Mol Biol Cell. 2008 Jan;19(1):352-67. doi: 10.1091/mbc.e07-08-0779. Epub 2007 Oct 24. PMID: 17959824; PMCID: PMC2174172."
  },
  {
    "objectID": "prepare/prepare-08.html#prepare",
    "href": "prepare/prepare-08.html#prepare",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look through this study from Brauer et al. This is a rich data set for exploring relationships between gene expression and cellular physiology. Focus on familiarizing yourself with the design of the experiment.\n\nBrauer MJ, Huttenhower C, Airoldi EM, Rosenstein R, Matese JC, Gresham D, Boer VM, Troyanskaya OG, Botstein D. Coordination of growth rate, cell cycle, stress response, and metabolic activity in yeast. Mol Biol Cell. 2008 Jan;19(1):352-67. doi: 10.1091/mbc.e07-08-0779. Epub 2007 Oct 24. PMID: 17959824; PMCID: PMC2174172."
  },
  {
    "objectID": "prepare/prepare-04.html",
    "href": "prepare/prepare-04.html",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look over the ggplot2 cheatsheet.\nWe’ll be using the basic ggplot2 structure with ggplot(), aes(), and various geom_*() functions like geom_point(), geom_bar(), and geom_histogram(). Pay special attention to the aesthetics section (color, size, shape) and the faceting functions facet_wrap() and facet_grid()."
  },
  {
    "objectID": "prepare/prepare-04.html#prepare",
    "href": "prepare/prepare-04.html#prepare",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look over the ggplot2 cheatsheet.\nWe’ll be using the basic ggplot2 structure with ggplot(), aes(), and various geom_*() functions like geom_point(), geom_bar(), and geom_histogram(). Pay special attention to the aesthetics section (color, size, shape) and the faceting functions facet_wrap() and facet_grid()."
  },
  {
    "objectID": "prepare/prepare-02.html",
    "href": "prepare/prepare-02.html",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look over the tidyr cheatsheet.\nWe’ll be using the pivot_*, separate(), and unite() functions, and discuss handling NA values. We won’t cover the nesting appproaches tomorrow so you can skip for now (skip the back page)."
  },
  {
    "objectID": "prepare/prepare-02.html#prepare",
    "href": "prepare/prepare-02.html#prepare",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look over the tidyr cheatsheet.\nWe’ll be using the pivot_*, separate(), and unite() functions, and discuss handling NA values. We won’t cover the nesting appproaches tomorrow so you can skip for now (skip the back page)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MOLB 7950: Informatics and Statistics for Molecular Biology",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMOLB 7950 - Fall 2025 Schedule\n\n\nClasses held in-person from 9:00-10:30am in AHSB 2200\n\n\n\nDate\nBlock\nTopic\nInstructor\nTitle\n\nLinks\n\n\n\nPrepare\nSlides\nExercises\nHW\nKey\n\n\n\n\nWeek 1\n\n\n01\nMon, Aug 25, 2025\nBootcamp\nR\nHesselberth\nIntro to R & RStudio\n📖\n📄\n💪\n🧠\n🔑\n\n\n02\nTue, Aug 26, 2025\nBootcamp\nR\nHesselberth\nTidy data & tidyr\n📖\n📄\n💪\n🧠\n🔑\n\n\n03\nWed, Aug 27, 2025\nBootcamp\nR\nHesselberth\ndplyr\n📖\n📄\n💪\n🧠\n🔑\n\n\n04\nThu, Aug 28, 2025\nBootcamp\nR\nHesselberth\nggplot2\n📖\n📄\n💪\n🧠\n🔑\n\n\n05\nFri, Aug 29, 2025\nBootcamp\nR\nHesselberth\nggplot2\n.\n📄\n💪\n🧠\n🔑\n\n\nWeek 2\n\n\n06\nMon, Sep 1, 2025\n-\n-\n-\nNO CLASS - LABOR DAY\n.\n.\n.\n.\n.\n\n\n07\nTue, Sep 2, 2025\nBootcamp\nR\nHesselberth\ntidyverse odds & ends\n📖\n📄\n💪\n.\n.\n\n\n08\nWed, Sep 3, 2025\nBootcamp\nR\nHesselberth\nputting it all together\n📖\n.\n💪\n.\n.\n\n\n09\nThu, Sep 4, 2025\nBootcamp\nR\nHesselberth\nputting it all together\n.\n.\n.\n.\n.\n\n\n10\nFri, Sep 5, 2025\nBootcamp\nStatistics\nMukherjee\nStats intro and history\n.\n.\n.\n.\n.\n\n\nWeek 3\n\n\n11\nMon, Sep 8, 2025\nBootcamp\nStatistics\nMukherjee\nProbability and descriptive stats\n.\n.\n.\n.\n.\n\n\n12\nTue, Sep 9, 2025\nBootcamp\nStatistics\nMukherjee\nHypothesis testing\n.\n.\n.\n.\n.\n\n\n13\nWed, Sep 10, 2025\nBootcamp\nStatistics\nMukherjee\nHypothesis testing\n.\n.\n.\n.\n.\n\n\n14\nThu, Sep 11, 2025\nBootcamp\nStatistics\nMukherjee\nExploratory data analysis\n.\n.\n.\n.\n.\n\n\n15\nFri, Sep 12, 2025\nBootcamp\nStatistics\nMukherjee\nBig data concerns\n.\n.\n.\n.\n.\n\n\nWeek 4\n\n\n16\nMon, Sep 15, 2025\nDNA\nMapping chromatin structure and transactions\nHesselberth\nExperimental overview\n.\n.\n.\n.\n.\n\n\n17\nWed, Sep 17, 2025\nDNA\nChromatin-centric methods\nHesselberth\nInformation from fragment length distributions\n.\n.\n.\n.\n.\n\n\n18\nFri, Sep 19, 2025\nDNA\nChromatin-centric methods\nHesselberth\nMeta-plots and heatmaps\n.\n.\n.\n.\n.\n\n\nWeek 5\n\n\n19\nMon, Sep 22, 2025\nDNA\nWhere do proteins bind in the genome?\nHesselberth\nExperimental overview\n.\n.\n.\n.\n.\n\n\n20\nWed, Sep 24, 2025\nDNA\nFactor-centric methods\nHesselberth\nPeak calling\n.\n.\n.\n.\n.\n\n\n21\nFri, Sep 26, 2025\nDNA\nFactor-centric methods\nHesselberth\nSequence motif analysis\n.\n.\n.\n.\n.\n\n\nWeek 6\n\n\n22\nMon, Sep 29, 2025\nRNA\nRNA-seq Overview\nMukherjee\nConcepts and techniques\n.\n.\n.\n.\n.\n\n\n23\nWed, Oct 1, 2025\nRNA\nImport, filtering, QC\nMukherjee\nmetrics and sample similarity\n.\n.\n.\n.\n.\n\n\n24\nFri, Oct 3, 2025\nRNA\nDifferential Gene Expression\nMukherjee\nDESeq2\n.\n.\n.\n.\n.\n\n\nWeek 7\n\n\n25\nMon, Oct 6, 2025\nRNA\nAlternative Splicing\nMukherjee\nrMATS\n.\n.\n.\n.\n.\n\n\n26\nWed, Oct 8, 2025\nRNA\nReview Proposals\nHesselberth\nReview Proposals\n.\n.\n.\n.\n.\n\n\n27\nFri, Oct 10, 2025\nRNA\nRBP-RNA 1\nMukherjee\nCLIP-seq\n.\n.\n.\n.\n.\n\n\nWeek 8\n\n\n28\nMon, Oct 13, 2025\nRNA\nRBP-RNA 2\nMukherjee\nData integrations\n.\n.\n.\n.\n.\n\n\n29\nWed, Oct 15, 2025\nRNA\nLong-read sequencing\nHesselberth\n-\n.\n.\n.\n.\n.\n\n\n30\nFri, Oct 17, 2025\n-\n-\n-\nNO CLASS: MOLB RETREAT\n.\n.\n.\n.\n.\n\n\nWeek 9\n\n\n31\nMon, Oct 20, 2025\nRNA\nSingle-cell\nWells-Wrasman\n-\n.\n.\n.\n.\n.\n\n\n32\nWed, Oct 22, 2025\nRNA\nSingle-cell\nWells-Wrasman\n-\n.\n.\n.\n.\n.\n\n\n33\nFri, Oct 24, 2025\n-\n-\n-\nNO CLASS: CSDV RETREAT\n.\n.\n.\n.\n.\n\n\nWeek 10\n\n\n34\nMon, Oct 27, 2025\nFinal\n-\n-\nFinal project presentations\n.\n.\n.\n.\n.\n\n\n35\nWed, Oct 29, 2025\nFinal\n-\n-\nFinal project presentations\n.\n.\n.\n.\n.",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "exercises/ex-07.html",
    "href": "exercises/ex-07.html",
    "title": "R Bootcamp - Class 7",
    "section": "",
    "text": "String manipulation with stringr\n\nFactor operations with forcats\n\nJoin functions with dplyr\n\nAdvanced plotting with ggplot2"
  },
  {
    "objectID": "exercises/ex-07.html#class-7-outline",
    "href": "exercises/ex-07.html#class-7-outline",
    "title": "R Bootcamp - Class 7",
    "section": "",
    "text": "String manipulation with stringr\n\nFactor operations with forcats\n\nJoin functions with dplyr\n\nAdvanced plotting with ggplot2"
  },
  {
    "objectID": "exercises/ex-07.html#setup",
    "href": "exercises/ex-07.html#setup",
    "title": "R Bootcamp - Class 7",
    "section": "Setup",
    "text": "Setup"
  },
  {
    "objectID": "exercises/ex-07.html#combining-strings-with-str_c",
    "href": "exercises/ex-07.html#combining-strings-with-str_c",
    "title": "R Bootcamp - Class 7",
    "section": "Combining strings with str_c()\n",
    "text": "Combining strings with str_c()\n\n\n\nstr_c() is similar to paste and paste0 but the behavior is more consistent."
  },
  {
    "objectID": "exercises/ex-07.html#detecting-patterns-with-str_detect",
    "href": "exercises/ex-07.html#detecting-patterns-with-str_detect",
    "title": "R Bootcamp - Class 7",
    "section": "Detecting patterns with str_detect()\n",
    "text": "Detecting patterns with str_detect()"
  },
  {
    "objectID": "exercises/ex-07.html#splitting-strings-with-str_split",
    "href": "exercises/ex-07.html#splitting-strings-with-str_split",
    "title": "R Bootcamp - Class 7",
    "section": "Splitting strings with str_split()\n",
    "text": "Splitting strings with str_split()"
  },
  {
    "objectID": "exercises/ex-07.html#counting-factor-levels-with-fct_count",
    "href": "exercises/ex-07.html#counting-factor-levels-with-fct_count",
    "title": "R Bootcamp - Class 7",
    "section": "Counting factor levels with fct_count()\n",
    "text": "Counting factor levels with fct_count()"
  },
  {
    "objectID": "exercises/ex-07.html#reordering-factors-with-fct_reorder",
    "href": "exercises/ex-07.html#reordering-factors-with-fct_reorder",
    "title": "R Bootcamp - Class 7",
    "section": "Reordering factors with fct_reorder()\n",
    "text": "Reordering factors with fct_reorder()"
  },
  {
    "objectID": "exercises/ex-07.html#lumping-infrequent-levels-with-fct_lump",
    "href": "exercises/ex-07.html#lumping-infrequent-levels-with-fct_lump",
    "title": "R Bootcamp - Class 7",
    "section": "Lumping infrequent levels with fct_lump()\n",
    "text": "Lumping infrequent levels with fct_lump()\n\n\n\n\n\nDo your numbers look different? sample() is not reproducible by default."
  },
  {
    "objectID": "exercises/ex-07.html#aside-on-sample-and-reproducibility",
    "href": "exercises/ex-07.html#aside-on-sample-and-reproducibility",
    "title": "R Bootcamp - Class 7",
    "section": "Aside on sample() and reproducibility",
    "text": "Aside on sample() and reproducibility\n\n\n\nthis also applies to rnorm(), runif(), and other random number generation functions."
  },
  {
    "objectID": "exercises/ex-07.html#setup-1",
    "href": "exercises/ex-07.html#setup-1",
    "title": "R Bootcamp - Class 7",
    "section": "Setup",
    "text": "Setup\nOpen up the tidyexplain page."
  },
  {
    "objectID": "exercises/ex-07.html#understanding-joins",
    "href": "exercises/ex-07.html#understanding-joins",
    "title": "R Bootcamp - Class 7",
    "section": "Understanding joins",
    "text": "Understanding joins\nJoins combine data from two tables based on matching keys."
  },
  {
    "objectID": "exercises/ex-07.html#left_join---keep-all-rows-from-left-table",
    "href": "exercises/ex-07.html#left_join---keep-all-rows-from-left-table",
    "title": "R Bootcamp - Class 7",
    "section": "\nleft_join() - keep all rows from left table",
    "text": "left_join() - keep all rows from left table\nMost common join - keeps all observations from the “primary” table."
  },
  {
    "objectID": "exercises/ex-07.html#inner_join---keep-only-matching-rows",
    "href": "exercises/ex-07.html#inner_join---keep-only-matching-rows",
    "title": "R Bootcamp - Class 7",
    "section": "\ninner_join() - keep only matching rows",
    "text": "inner_join() - keep only matching rows\nOnly keeps rows that exist in both tables."
  },
  {
    "objectID": "exercises/ex-07.html#full_join---keep-all-rows-from-both-tables",
    "href": "exercises/ex-07.html#full_join---keep-all-rows-from-both-tables",
    "title": "R Bootcamp - Class 7",
    "section": "\nfull_join() - keep all rows from both tables",
    "text": "full_join() - keep all rows from both tables\nKeeps everything, filling missing values with NA."
  },
  {
    "objectID": "exercises/ex-07.html#setup-2",
    "href": "exercises/ex-07.html#setup-2",
    "title": "R Bootcamp - Class 7",
    "section": "Setup",
    "text": "Setup"
  },
  {
    "objectID": "exercises/ex-07.html#scale-functions-in-ggplot2",
    "href": "exercises/ex-07.html#scale-functions-in-ggplot2",
    "title": "R Bootcamp - Class 7",
    "section": "scale functions in ggplot2",
    "text": "scale functions in ggplot2\n\n\nscale_color_brewer() and scale_fill_brewer() control color and fill aesthetics.\nSee available ggplot2 brewer palettes"
  },
  {
    "objectID": "exercises/ex-07.html#combining-multiple-plots-into-a-figure",
    "href": "exercises/ex-07.html#combining-multiple-plots-into-a-figure",
    "title": "R Bootcamp - Class 7",
    "section": "Combining multiple plots into a figure?",
    "text": "Combining multiple plots into a figure?\nUse the {patchwork} package."
  },
  {
    "objectID": "exercises/ex-07.html#saving-plots",
    "href": "exercises/ex-07.html#saving-plots",
    "title": "R Bootcamp - Class 7",
    "section": "Saving plots",
    "text": "Saving plots\nSaves last plot as 5’ x 5’ file named plot_final.png in working directory.\nMatches file type to file extension (*.png, *.jpeg, *.pdf)."
  },
  {
    "objectID": "exercises/ex-07.html#using-knitrkable",
    "href": "exercises/ex-07.html#using-knitrkable",
    "title": "R Bootcamp - Class 7",
    "section": "Using knitr::kable()\n",
    "text": "Using knitr::kable()"
  },
  {
    "objectID": "exercises/ex-07.html#using-gt",
    "href": "exercises/ex-07.html#using-gt",
    "title": "R Bootcamp - Class 7",
    "section": "Using gt\n",
    "text": "Using gt"
  },
  {
    "objectID": "exercises/ex-04.html#todays-datasets",
    "href": "exercises/ex-04.html#todays-datasets",
    "title": "R Bootcamp - Day 4",
    "section": "Today’s datasets",
    "text": "Today’s datasets\nIn this class, we will use a data set from ggplot2: diamonds contains thousands of gem prices and qualities.\nThere are many interesting data sets you can install as R packages for learning to manipulate and plot data:\n\nbabynames\ngapminder\npalmerpenguins"
  },
  {
    "objectID": "exercises/ex-04.html#getting-familiar-with-the-data---exercise-1",
    "href": "exercises/ex-04.html#getting-familiar-with-the-data---exercise-1",
    "title": "R Bootcamp - Day 4",
    "section": "Getting familiar with the data - Exercise 1",
    "text": "Getting familiar with the data - Exercise 1"
  },
  {
    "objectID": "exercises/ex-04.html#the-syntax-of-ggplot",
    "href": "exercises/ex-04.html#the-syntax-of-ggplot",
    "title": "R Bootcamp - Day 4",
    "section": "The syntax of ggplot()\n",
    "text": "The syntax of ggplot()"
  },
  {
    "objectID": "exercises/ex-04.html#making-a-plot-step-by-step-exercise-2",
    "href": "exercises/ex-04.html#making-a-plot-step-by-step-exercise-2",
    "title": "R Bootcamp - Day 4",
    "section": "Making a plot step-by-step (Exercise 2)",
    "text": "Making a plot step-by-step (Exercise 2)\n\nInitialize a plot with data.\nNext, specify the coordinate system.\nAdd a geom (geom_point).\nMap aesthetics to other variables.\n\nReduce overplotting by adjusting the transparency of points."
  },
  {
    "objectID": "exercises/ex-04.html#looking-under-the-hood-of-ggplot-exercise-3",
    "href": "exercises/ex-04.html#looking-under-the-hood-of-ggplot-exercise-3",
    "title": "R Bootcamp - Day 4",
    "section": "Looking under the hood of ggplot (Exercise 3)",
    "text": "Looking under the hood of ggplot (Exercise 3)"
  },
  {
    "objectID": "exercises/ex-04.html#ggplot-is-powerfully-simple-for-making-complex-plots",
    "href": "exercises/ex-04.html#ggplot-is-powerfully-simple-for-making-complex-plots",
    "title": "R Bootcamp - Day 4",
    "section": "ggplot is powerfully simple for making complex plots",
    "text": "ggplot is powerfully simple for making complex plots\nWhy can’t I just do this?"
  },
  {
    "objectID": "exercises/ex-04.html#geom-functions",
    "href": "exercises/ex-04.html#geom-functions",
    "title": "R Bootcamp - Day 4",
    "section": "Geom functions",
    "text": "Geom functions\n\nUse a geom function to represent data points, use the geom aesthetic properties to represent variables.\nEach function returns a plot layer.\nThere are many geoms in ggplot that are specific to plots with 1, 2, or 3 variables\n\nMake a bar plot.\n\nUpdate the bar plot aesthetics.\n\nChange to a density plot.\n\nColor the density plot.\n\nPlot subsets by mapping fill to cut\n\nUse ggridges to plot staggered subsets.\nhttps://wilkelab.org/ggridges/"
  },
  {
    "objectID": "exercises/ex-04.html#geom-functions-for-two-variables",
    "href": "exercises/ex-04.html#geom-functions-for-two-variables",
    "title": "R Bootcamp - Day 4",
    "section": "Geom functions for two variables",
    "text": "Geom functions for two variables\nMake a column plot.\nSame data with a box plot.\n\nBox plot, with fill color by cut.\nViolin plot with fill color by cut."
  },
  {
    "objectID": "exercises/ex-04.html#continuous-x-continuous-y---exercise-6",
    "href": "exercises/ex-04.html#continuous-x-continuous-y---exercise-6",
    "title": "R Bootcamp - Day 4",
    "section": "continuous x, continuous y - Exercise 6",
    "text": "continuous x, continuous y - Exercise 6\nSubset diamonds to see points more clearly.\nMake a scatter plot.\nNow add a smoothing line.\nHere we can combine geoms to see points & the fit"
  },
  {
    "objectID": "exercises/ex-02.html",
    "href": "exercises/ex-02.html",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "",
    "text": "Explore table1, table2, table3, table4a, table4b, and table5, which all display the number of TB cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000.\n\nR provides many functions to examine features of a data object\n\nView() - To open the table up in an excel-like interface - not recommended for large tables\nclass() - what kind of object is it (high-level)?\ntypeof() - what is the object’s data type (low-level)?\nis_tibble() - use is.? to confirm data type\nstr() - what is the structure of the object?\nattributes() - does it have any metadata?\nLet’s explore table1\n\nSome of the useful functions for data.frames / tibbles are as follows:\n\n\nhead() - shows first 6 rows\n\ntail() - shows last 6 rows\n\ndim() - returns the dimensions of data frame (i.e. number of rows and number of columns)\n\nnrow() - number of rows\n\nncol() - number of columns\n\nnames() or colnames() - both show the names attribute for a data frame\nglimpse()"
  },
  {
    "objectID": "exercises/ex-02.html#data-sets-for-tidying---exercise-2",
    "href": "exercises/ex-02.html#data-sets-for-tidying---exercise-2",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "",
    "text": "Explore table1, table2, table3, table4a, table4b, and table5, which all display the number of TB cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000."
  },
  {
    "objectID": "exercises/ex-02.html#getting-familiar-with-the-data---exercise-3",
    "href": "exercises/ex-02.html#getting-familiar-with-the-data---exercise-3",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "",
    "text": "R provides many functions to examine features of a data object\n\nView() - To open the table up in an excel-like interface - not recommended for large tables\nclass() - what kind of object is it (high-level)?\ntypeof() - what is the object’s data type (low-level)?\nis_tibble() - use is.? to confirm data type\nstr() - what is the structure of the object?\nattributes() - does it have any metadata?\nLet’s explore table1"
  },
  {
    "objectID": "exercises/ex-02.html#getting-familiar-with-the-data---exercise-4",
    "href": "exercises/ex-02.html#getting-familiar-with-the-data---exercise-4",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "",
    "text": "Some of the useful functions for data.frames / tibbles are as follows:\n\n\nhead() - shows first 6 rows\n\ntail() - shows last 6 rows\n\ndim() - returns the dimensions of data frame (i.e. number of rows and number of columns)\n\nnrow() - number of rows\n\nncol() - number of columns\n\nnames() or colnames() - both show the names attribute for a data frame\nglimpse()"
  },
  {
    "objectID": "exercises/ex-02.html#pivot_wider---exercise-6",
    "href": "exercises/ex-02.html#pivot_wider---exercise-6",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "pivot_wider - Exercise 6",
    "text": "pivot_wider - Exercise 6\nWhat will the output look like?\nIf you want to save the output, assign it to a new variable. This new variable will appear in your Environment tab."
  },
  {
    "objectID": "exercises/ex-02.html#pivot_longer---exercise-7",
    "href": "exercises/ex-02.html#pivot_longer---exercise-7",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "pivot_longer - Exercise 7",
    "text": "pivot_longer - Exercise 7\nWhat will the output look like?"
  },
  {
    "objectID": "exercises/ex-02.html#separate_wider_delim---exercise-8",
    "href": "exercises/ex-02.html#separate_wider_delim---exercise-8",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "separate_wider_delim - Exercise 8",
    "text": "separate_wider_delim - Exercise 8\nWhat will the output look like?\nseparate_rows - Exercise 9"
  },
  {
    "objectID": "exercises/ex-02.html#unite---exercise-10",
    "href": "exercises/ex-02.html#unite---exercise-10",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "unite - Exercise 10",
    "text": "unite - Exercise 10"
  },
  {
    "objectID": "exercises/ex-02.html#missing-values",
    "href": "exercises/ex-02.html#missing-values",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "Missing values",
    "text": "Missing values"
  },
  {
    "objectID": "course-info/team.html",
    "href": "course-info/team.html",
    "title": "MOLB 7950 — Teaching Team",
    "section": "",
    "text": "TA office hours will be 1-2:30 PM on Tues and Thurs. Please coordinate with the TAs to determine whether you want to meet in person or virtually. You can also use slack to ask questions outside of office hours.\n\n\n\n\n\n\n\n\n\nInstructor\nE-mail\n\n\n\n\nNeel Mukherjee\n\n\n\nJay Hesselberth\n\n\n\nSrinivas Ramachandran\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstructor\nE-mail\n\n\n\n\nNathaly Limon de la Rosa\n\n\n\nIlin Joshi",
    "crumbs": [
      "Course information",
      "Teaching team"
    ]
  },
  {
    "objectID": "course-info/team.html#teaching-team-and-office-hours",
    "href": "course-info/team.html#teaching-team-and-office-hours",
    "title": "MOLB 7950 — Teaching Team",
    "section": "",
    "text": "TA office hours will be 1-2:30 PM on Tues and Thurs. Please coordinate with the TAs to determine whether you want to meet in person or virtually. You can also use slack to ask questions outside of office hours.\n\n\n\n\n\n\n\n\n\nInstructor\nE-mail\n\n\n\n\nNeel Mukherjee\n\n\n\nJay Hesselberth\n\n\n\nSrinivas Ramachandran\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstructor\nE-mail\n\n\n\n\nNathaly Limon de la Rosa\n\n\n\nIlin Joshi",
    "crumbs": [
      "Course information",
      "Teaching team"
    ]
  },
  {
    "objectID": "course-info/support.html",
    "href": "course-info/support.html",
    "title": "MOLB 7950 — Getting help",
    "section": "",
    "text": "Course discussion will be through the Slack MOLB7950 organization.\nGuidelines for using Slack:\n\nUse dedicated channels for discussion in #class, questions about your #problem-sets, and your #final-project\nYou can ask for help by tagging the TAs in the #class channel. If you post @ta help, someone will start a thread where you can ask a question.\nIf needed, we can talk face-to-face via the /zoom integration.\n\n\n\n\n\nOur TAs will be available Tues-Thurs afternoons from 1-2:30pm.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-info/support.html#how-to-get-help",
    "href": "course-info/support.html#how-to-get-help",
    "title": "MOLB 7950 — Getting help",
    "section": "",
    "text": "Course discussion will be through the Slack MOLB7950 organization.\nGuidelines for using Slack:\n\nUse dedicated channels for discussion in #class, questions about your #problem-sets, and your #final-project\nYou can ask for help by tagging the TAs in the #class channel. If you post @ta help, someone will start a thread where you can ask a question.\nIf needed, we can talk face-to-face via the /zoom integration.\n\n\n\n\n\nOur TAs will be available Tues-Thurs afternoons from 1-2:30pm.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-info/final-projects.html",
    "href": "course-info/final-projects.html",
    "title": "MOLB 7950 – Final Projects",
    "section": "",
    "text": "Please submit a short proposal for your final projects with the following information.\n\nthe names of people you are working with\na description of the data set you will be working worth. This can refer to a publication and/or contain a link to public data available at NCBI GEO.\na hypothesis (tentative) you will be testing\na few bullets on your planned analysis approach.\n\nPlease include this information in a quarto document in a new Posit cloud project.",
    "crumbs": [
      "Assignments",
      "Final Project Overview"
    ]
  },
  {
    "objectID": "course-info/final-projects.html#short-proposal",
    "href": "course-info/final-projects.html#short-proposal",
    "title": "MOLB 7950 – Final Projects",
    "section": "",
    "text": "Please submit a short proposal for your final projects with the following information.\n\nthe names of people you are working with\na description of the data set you will be working worth. This can refer to a publication and/or contain a link to public data available at NCBI GEO.\na hypothesis (tentative) you will be testing\na few bullets on your planned analysis approach.\n\nPlease include this information in a quarto document in a new Posit cloud project.",
    "crumbs": [
      "Assignments",
      "Final Project Overview"
    ]
  },
  {
    "objectID": "course-info/final-projects.html#overview",
    "href": "course-info/final-projects.html#overview",
    "title": "MOLB 7950 – Final Projects",
    "section": "Overview",
    "text": "Overview\n\nFinal projects can involve groups of 1-3 people.\n\nProjects are choose your own adventure:\n\nThe resource documents contain data sets in from human S. cerevisiae. For example, sub-nucleosomal fragments provide a DNA-based signal to understand chromatin transactions that lead to transcription.\nYou could find a data set on NCBI GEO of interest (e.g., relevant to your thesis work), and work it up with salmon, DEseq, and exploratory analysis. We are happy to help you work through the pseudo-alignment steps.\nYou can start with your own sequencing data (bulk/single-cell RNA seq, DNA sequencing).",
    "crumbs": [
      "Assignments",
      "Final Project Overview"
    ]
  },
  {
    "objectID": "course-info/final-projects.html#deliverables",
    "href": "course-info/final-projects.html#deliverables",
    "title": "MOLB 7950 – Final Projects",
    "section": "Deliverables",
    "text": "Deliverables\n\nA Quarto document with code, plots, interpretations, and next steps.\nIf you work in a group, list the members of the group at the top of the document, and make it clear which parts are your work by adding your initials to code chunks.\nShort presentations (5-8 minutes) by the groups the week of Nov 1. Presentations should include 1-2 slides of background, a hypothesis for the approach, code output (table or graph) that addresses the hypothesis, and one or more tests of the statistical significance of the observation.",
    "crumbs": [
      "Assignments",
      "Final Project Overview"
    ]
  },
  {
    "objectID": "course-info/final-projects.html#grading-and-rubric",
    "href": "course-info/final-projects.html#grading-and-rubric",
    "title": "MOLB 7950 – Final Projects",
    "section": "Grading and rubric",
    "text": "Grading and rubric\nThe final project will be worth 20% of your grade and we will use the grading scheme outlined in the grading rubric.\nEach individual in a group will be evaluated separately, so contributions must be clearly marked in the document, using e.g. using chunk labels:\n\n```{r}\n#| label: plotting-code-by-jay-h\n#| eval: false\n#| fig.alt: \"Description of the plot - PLEASE FILL IN\"\nggplot(mtcars, aes(hp, mpg)) +\n  geom_point()\n```",
    "crumbs": [
      "Assignments",
      "Final Project Overview"
    ]
  },
  {
    "objectID": "course-info/problem-sets.html",
    "href": "course-info/problem-sets.html",
    "title": "MOLB 7950 — Problem Sets",
    "section": "",
    "text": "We reinforce concepts with problem sets assigned at the end of each class. During the main blocks, problem sets on Mon and Wed should take ~60 minutes to complete. Problems sets assigned on Friday will be more substantial, requiring ~1-2 hours to complete. Together the problem sets constitute 60% of your grade.\n\n\n\nProblem sets are distributed as Posit Cloud assignments. You will work on problem sets in an Rmarkdown document in the assignment. When complete, complete your assignment by submitting the URL from your Posit Cloud assignment into the assignment submission on Canvas. We will grade your problem directly in the Posit Cloud assignment.\n\n\n\n\n\n\n\n\n\n\nAssigned\nDue\nGrades By\nWho grades\nTime to complete (approx)\n\n\n\n\nMon @ 12pm\nTues @ 5pm\nWed @ 5pm\nInstructors / TAs\n60 min\n\n\nTue @ 12pm\nWed @ 5pm\nThurs @ 5pm\nInstructors / TAs\n60 min\n\n\nWed @ 12pm\nThurs @ 5pm\nFri @ 5pm\nInstructors / TAs\n60 min\n\n\nThurs @ 12pm\nFri @ 5pm\nTues @ 5pm\nInstructors / TAs\n60 min\n\n\nFri @ 12pm\nMon @ 5pm\nWed @ 5pm\nInstructors / TAs\n1-2 hr\n\n\n\n\n\n\nProblem sets are worth 60% of your grade. Values in parentheses represent point values for each level from 20 points total. This rubric will be assessed at the end of the semester.\n\n\n\n\n\n\n\n\n\nCriteria\nExpert\nCompetent\nNeeds Improvement\n\n\n\n\nCoding style\nStudent has gone beyond what was expected and required, coding manual is followed, code is well commented\nCoding style lacks refinement and has some errors, but code is readable and has some comments\nMany errors in coding style, little attention paid to making the code human readable\n\n\nCoding strategy\nComplicated problem broken down into sub-problems that are individually much simpler. Code is efficient, correct, and minimal. Code uses appropriate data structure (list, data frame, vector/matrix/array). Code checks for common errors\nCode is correct, but could be edited down to leaner code. Some “hacking” instead of using suitable data structure. Some checks for errors.\nCode tackles complicated problem in one big chunk. Code is repetitive and could easily be functionalized. No anticipation of errors.\n\n\nPresentation: graphs\nGraph(s) carefully tuned for desired purpose. One graph illustrates one point\nGraph(s) well chosen, but with a few minor problems: inappropriate aspect ratios, poor labels.\nGraph(s) poorly chosen to support questions.\n\n\nPresentation: tables\nTable(s) carefully constructed to make it easy to perform important comparisons. Careful styling highlights important features.\nTable(s) generally appropriate but possibly some minor formatting deficiencies.\nTable(s) with too many, or inconsistent, decimal places. Table(s) not appropriate for questions and findings. Major display problems.\n\n\nAchievement, mastery, cleverness, creativity\nStudent has gone beyond what was expected and required, e.g., extraordinary effort, additional tools not addressed by this course, unusually sophisticated application of tools from course.\nTools and techniques from the course are applied very competently and, perhaps,somewhat creatively. Chosen task was acceptable, but fairly conservative in ambition.\nStudent does not display the expected level of mastery of the tools and techniques in this course. Chosen task was too limited in scope.\n\n\nEase of access for instructor, compliance with course conventions for submitted work\nAccess as easy as possible, code runs!\nSatisfactory\nNot an earnest effort to reduce friction and comply with conventions and/or code does not run",
    "crumbs": [
      "Assignments",
      "Problet Set Overview"
    ]
  },
  {
    "objectID": "course-info/problem-sets.html#problem-set-overview",
    "href": "course-info/problem-sets.html#problem-set-overview",
    "title": "MOLB 7950 — Problem Sets",
    "section": "",
    "text": "We reinforce concepts with problem sets assigned at the end of each class. During the main blocks, problem sets on Mon and Wed should take ~60 minutes to complete. Problems sets assigned on Friday will be more substantial, requiring ~1-2 hours to complete. Together the problem sets constitute 60% of your grade.\n\n\n\nProblem sets are distributed as Posit Cloud assignments. You will work on problem sets in an Rmarkdown document in the assignment. When complete, complete your assignment by submitting the URL from your Posit Cloud assignment into the assignment submission on Canvas. We will grade your problem directly in the Posit Cloud assignment.\n\n\n\n\n\n\n\n\n\n\nAssigned\nDue\nGrades By\nWho grades\nTime to complete (approx)\n\n\n\n\nMon @ 12pm\nTues @ 5pm\nWed @ 5pm\nInstructors / TAs\n60 min\n\n\nTue @ 12pm\nWed @ 5pm\nThurs @ 5pm\nInstructors / TAs\n60 min\n\n\nWed @ 12pm\nThurs @ 5pm\nFri @ 5pm\nInstructors / TAs\n60 min\n\n\nThurs @ 12pm\nFri @ 5pm\nTues @ 5pm\nInstructors / TAs\n60 min\n\n\nFri @ 12pm\nMon @ 5pm\nWed @ 5pm\nInstructors / TAs\n1-2 hr\n\n\n\n\n\n\nProblem sets are worth 60% of your grade. Values in parentheses represent point values for each level from 20 points total. This rubric will be assessed at the end of the semester.\n\n\n\n\n\n\n\n\n\nCriteria\nExpert\nCompetent\nNeeds Improvement\n\n\n\n\nCoding style\nStudent has gone beyond what was expected and required, coding manual is followed, code is well commented\nCoding style lacks refinement and has some errors, but code is readable and has some comments\nMany errors in coding style, little attention paid to making the code human readable\n\n\nCoding strategy\nComplicated problem broken down into sub-problems that are individually much simpler. Code is efficient, correct, and minimal. Code uses appropriate data structure (list, data frame, vector/matrix/array). Code checks for common errors\nCode is correct, but could be edited down to leaner code. Some “hacking” instead of using suitable data structure. Some checks for errors.\nCode tackles complicated problem in one big chunk. Code is repetitive and could easily be functionalized. No anticipation of errors.\n\n\nPresentation: graphs\nGraph(s) carefully tuned for desired purpose. One graph illustrates one point\nGraph(s) well chosen, but with a few minor problems: inappropriate aspect ratios, poor labels.\nGraph(s) poorly chosen to support questions.\n\n\nPresentation: tables\nTable(s) carefully constructed to make it easy to perform important comparisons. Careful styling highlights important features.\nTable(s) generally appropriate but possibly some minor formatting deficiencies.\nTable(s) with too many, or inconsistent, decimal places. Table(s) not appropriate for questions and findings. Major display problems.\n\n\nAchievement, mastery, cleverness, creativity\nStudent has gone beyond what was expected and required, e.g., extraordinary effort, additional tools not addressed by this course, unusually sophisticated application of tools from course.\nTools and techniques from the course are applied very competently and, perhaps,somewhat creatively. Chosen task was acceptable, but fairly conservative in ambition.\nStudent does not display the expected level of mastery of the tools and techniques in this course. Chosen task was too limited in scope.\n\n\nEase of access for instructor, compliance with course conventions for submitted work\nAccess as easy as possible, code runs!\nSatisfactory\nNot an earnest effort to reduce friction and comply with conventions and/or code does not run",
    "crumbs": [
      "Assignments",
      "Problet Set Overview"
    ]
  },
  {
    "objectID": "course-info/syllabus.html",
    "href": "course-info/syllabus.html",
    "title": "MOLB 7950 Syllabus",
    "section": "",
    "text": "MOLB 7950 is a hands-on tutorial of skills and theory needed to process, analyze, and visualize output from large biological data sets. We emphasize the R statistical computing environment.\n🗓️ Class will run from Aug 26 - Oct 29\n📍 Classes will be held in-person at locations found on the schedule page.\n🕘 Class time is 9:00-10:30am\nMOLB 7950 is a three credit hour course.\nThe course is divided into blocks:\n\n\nTHe Bootcamp block covers R programming and introduces important statistical concepts and approaches. We will also cover data types you will encounter during biological data analysis and approaches for their analysis.\nDuring the bootcamp block, we will meet everyday for 90 minutes to cover fundamental concepts you will need throughout the course.\n\n\n\nAfter Bootcamp, will cover experimental approaches used to analyze DNA and RNA. Each block spans ~4 weeks, with each week focused on a particular type of experiment (see below). Each block covers statistical concepts needed for rigorous analysis and analysis approaches to process raw data to results (tables and figures) using reproducible coding techniques.\nIn most weeks we will discuss and analyze data from a publication. You are responsible for reading the week’s material before class begins on Monday.\n\n\n\nThe DNA block covers genome sequencing for identifying mutations, and two approaches for analyzing chromatin state (ChIP-seq and MNase-seq).\nThe RNA block covers RNA-seq, alternative splicing, differential gene expression, and RNA:protein interactions.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#course-overview",
    "href": "course-info/syllabus.html#course-overview",
    "title": "MOLB 7950 Syllabus",
    "section": "",
    "text": "MOLB 7950 is a hands-on tutorial of skills and theory needed to process, analyze, and visualize output from large biological data sets. We emphasize the R statistical computing environment.\n🗓️ Class will run from Aug 26 - Oct 29\n📍 Classes will be held in-person at locations found on the schedule page.\n🕘 Class time is 9:00-10:30am\nMOLB 7950 is a three credit hour course.\nThe course is divided into blocks:\n\n\nTHe Bootcamp block covers R programming and introduces important statistical concepts and approaches. We will also cover data types you will encounter during biological data analysis and approaches for their analysis.\nDuring the bootcamp block, we will meet everyday for 90 minutes to cover fundamental concepts you will need throughout the course.\n\n\n\nAfter Bootcamp, will cover experimental approaches used to analyze DNA and RNA. Each block spans ~4 weeks, with each week focused on a particular type of experiment (see below). Each block covers statistical concepts needed for rigorous analysis and analysis approaches to process raw data to results (tables and figures) using reproducible coding techniques.\nIn most weeks we will discuss and analyze data from a publication. You are responsible for reading the week’s material before class begins on Monday.\n\n\n\nThe DNA block covers genome sequencing for identifying mutations, and two approaches for analyzing chromatin state (ChIP-seq and MNase-seq).\nThe RNA block covers RNA-seq, alternative splicing, differential gene expression, and RNA:protein interactions.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#schedule",
    "href": "course-info/syllabus.html#schedule",
    "title": "MOLB 7950 Syllabus",
    "section": "Schedule",
    "text": "Schedule\nClasses begin on August 26 and end on October 29. Dates are from the Fall 2025 Academic Calendar.\nDuring the Bootcamp block, classes will be held every day, Mon-Fri from 9:00-10:30am.\nDuring the DNA & RNA blocks, we will have in-class exercises and discussion on Mon-Wed-Fri 9:00-10:30am.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#location",
    "href": "course-info/syllabus.html#location",
    "title": "MOLB 7950 Syllabus",
    "section": "Location",
    "text": "Location\nClasses will be held in-person in a variety of different rooms. Please check the schedule page to see each class’s room assignment. All classes will be recorded and made available through Canvas.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#policies",
    "href": "course-info/syllabus.html#policies",
    "title": "MOLB 7950 Syllabus",
    "section": "Policies",
    "text": "Policies\n\nAttendance\nClass attendance is a firm expectation; frequent absences or tardiness are considered cause for a grade reduction.\nif you are sick, please let us know (e-mail Srinivas and Matt) and STAY HOME.\nAnticipated absences outside of sickness should be reported to the instructors of a given block as soon as possible to make plans for possible accommodation.\nWe will record all lectures on Panopto and they will be available online through Canvas.\n\n\nLate and missed work\nWe have a late work policy for homework assignments:\n\nIf a problem set set is late but within 24 hours of due date/time, the grade will be reduced by 50%\nIf a problem set is returned any later, no credit will be given.\nAll regrade requests must be discussed with the professor within one week of receiving your grade. There will be no grade changes after the final project.\n\n\n\nDiversity & Inclusiveness\nOur view is that students from all diverse backgrounds and perspectives will be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class iss a resource, strength, and benefit.\n\n\nDisability Policy\nStudents with disabilities who need accommodations are encouraged to contact the Office of Disability, Access & Inclusion as soon as possible to ensure that accommodations are implemented in a timely fashion.\n\n\nHonor code\nAcademic dishonesty will not be tolerated and is grounds for dismissal from the class with a failing grade (“F”). For other information, please consult the Graduate Student Handbook.\nChatGPT will probably be able to answer most coding questions you ask of it. While it is useful for fleshing out an initial approach from pseudocode, we do not recommend using it, as these conceptual approaches are an essential foundation for buildling expertise in bioinformatic analysis.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#problem-sets",
    "href": "course-info/syllabus.html#problem-sets",
    "title": "MOLB 7950 Syllabus",
    "section": "Problem Sets",
    "text": "Problem Sets\n\nProblem sets will be assigned at the end of each class.\nYou can use external resources but must explicitly cite where you have obtained code (both code you used directly and “paraphrased” code / code used as inspiration). Any reused code that is not explicitly cited will be treated as plagiarism.\nYou can discuss the content of assignments with others in this class. If you do so, you must acknowledge your collaborator(s) at the top of your assignment, for example: “Collaborators: Hillary and Bernie”. Failure to acknowledge collaborators will result in a grade of 0. You may not copy code and/or answers directly from another student. If you copy other work, both parties will receive a grade of 0.\nThe problem set with the lowest score for each student will be dropped.\nRather than copying someone’s work, ask for help. You are not alone in this course!",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#professionalism",
    "href": "course-info/syllabus.html#professionalism",
    "title": "MOLB 7950 Syllabus",
    "section": "Professionalism",
    "text": "Professionalism\n\nPlease refrain from texting or using your computer for anything other than coursework during class.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#assignments-and-grading",
    "href": "course-info/syllabus.html#assignments-and-grading",
    "title": "MOLB 7950 Syllabus",
    "section": "Assignments and Grading",
    "text": "Assignments and Grading\nThe course measures learning through daily problem sets, a final project, and your participation.\n\n\n\nType\n% of grade\n\n\n\n\nProblem Sets\n60\n\n\nFinal Project\n20\n\n\nParticipation\n20\n\n\n\nGrades will be assigned as follows:\n\n\n\nPercent total points\nGrade\n\n\n\n\n&gt;= 95\nA\n\n\n&gt;= 90\nA-\n\n\n&gt;= 85\nB+\n\n\n&gt;= 80\nB\n\n\n\n\nProblem sets\nWe reinforce concepts with problem sets assigned at the end of class that should take ~60 minutes to complete.\nProblems sets assigned on Friday will be more substantial, requiring ~1-2 hours to complete.\nTogether the problem sets constitute 60% of your grade.\n\n\n\n\n\n\n\n\n\n\nAssigned\nDue\nGrades By\nWho grades\nTime to complete (approx)\n\n\n\n\nMon @ 12pm\nTues @ 5pm\nWed @ 5pm\nInstructors / TAs\n60 min\n\n\nTue @ 12pm\nWed @ 5pm\nThurs @ 5pm\nInstructors / TAs\n60 min\n\n\nWed @ 12pm\nThurs @ 5pm\nFri @ 5pm\nInstructors / TAs\n60 min\n\n\nThurs @ 12pm\nFri @ 5pm\nTues @ 5pm\nInstructors / TAs\n60 min\n\n\nFri @ 12pm\nMon @ 5pm\nWed @ 5pm\nInstructors / TAs\n1-2 hr\n\n\n\n\n\nFinal projects\nFinal projects can be completed in groups of 1-3 people. Projects will involve analysis of existing public data sets and end with a short presentation the last week of class. The final project constitutes 20% of your grade.\n\n\nGrading Rubrics\n\nProblem Set Rubric\nProblem sets are worth 60% of your grade. Values in parentheses represent point values for each level from 20 points total. This rubric will be assessed at the end of the semester.\n\n\n\n\n\n\n\n\n\nCriteria\nExpert\nCompetent\nNeeds Improvement\n\n\n\n\nCoding style\nStudent has gone beyond what was expected and required, coding manual is followed, code is well commented\nCoding style lacks refinement and has some errors, but code is readable and has some comments\nMany errors in coding style, little attention paid to making the code human readable\n\n\nCoding strategy\nComplicated problem broken down into sub-problems that are individually much simpler. Code is efficient, correct, and minimal. Code uses appropriate data structure (list, data frame, vector/matrix/array). Code checks for common errors\nCode is correct, but could be edited down to leaner code. Some “hacking” instead of using suitable data structure. Some checks for errors.\nCode tackles complicated problem in one big chunk. Code is repetitive and could easily be functionalized. No anticipation of errors.\n\n\nPresentation: graphs\nGraph(s) carefully tuned for desired purpose. One graph illustrates one point\nGraph(s) well chosen, but with a few minor problems: inappropriate aspect ratios, poor labels.\nGraph(s) poorly chosen to support questions.\n\n\nPresentation: tables\nTable(s) carefully constructed to make it easy to perform important comparisons. Careful styling highlights important features.\nTable(s) generally appropriate but possibly some minor formatting deficiencies.\nTable(s) with too many, or inconsistent, decimal places. Table(s) not appropriate for questions and findings. Major display problems.\n\n\nAchievement, mastery, cleverness, creativity\nStudent has gone beyond what was expected and required, e.g., extraordinary effort, additional tools not addressed by this course, unusually sophisticated application of tools from course.\nTools and techniques from the course are applied very competently and, perhaps,somewhat creatively. Chosen task was acceptable, but fairly conservative in ambition.\nStudent does not display the expected level of mastery of the tools and techniques in this course. Chosen task was too limited in scope.\n\n\nEase of access for instructor, compliance with course conventions for submitted work\nAccess as easy as possible, code runs!\nSatisfactory\nNot an earnest effort to reduce friction and comply with conventions and/or code does not run\n\n\n\n\n\nParticipation rubric\nAttendance & participation is worth 20% of your grade. Values in parentheses represent point values for each level from 20 points total. This rubric will be assessed at the end of the semester.\n\n\n\n\n\n\n\n\n\nCriteria\nExpert\nCompetent\nNeeds improvement\n\n\n\n\nAttendance (physically present for class, or coordinating with instructor when absent)\nAttends class regularly (5)\nAttends most classes (4)\nAttends some classes (0-3)\n\n\nPreparation (activities required for in-class participation, like surveys and software installation)\nCompletes requested activities prior to class (5)\nCompletes most requested activities prior to class, sometimes needs to finish during class (4)\nRarely completes requested activities prior to class, often takes class time to complete (0-3)\n\n\nEngagement (in-class activities like coding exercises and discussion)\nActively engages in class activities (10)\nSometimes engages in class activities (8)\nDoesn’t engage in class activities (0-7)",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#related-coursework",
    "href": "course-info/syllabus.html#related-coursework",
    "title": "MOLB 7950 Syllabus",
    "section": "Related coursework",
    "text": "Related coursework\nIn previous iterations of this course, we taught command-line (bash, grep, awk, etc) and Python programming. These skills are useful, but for consistency we opted to focus on R programming and RStudio as an analysis environment.\nAMC also offers shorter workshops on specific analysis strategies that you might find helpful.\n\nMOLB 7900: Practical Computational Biology for Biologists — Python (Taliaferro and Ramachandran)\nMOLB 7910: Practical Computational Biology for Biologists — R/R Studio (Jagannathan and Mukherjee)",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#acknowldgements-attribution",
    "href": "course-info/syllabus.html#acknowldgements-attribution",
    "title": "MOLB 7950 Syllabus",
    "section": "Acknowldgements & Attribution",
    "text": "Acknowldgements & Attribution\n\nInstructor contributions\nSeveral people have contributed to course development over the past several years.\n\nSujatha Jagannathan contributed the original R bootcamp material.\nSrinivas Ramachandran contributed material for the DNA block, including lecture material and examples for yeast chromatin accessibility and factor mapping.\nMatt Taliaferro contributed material for the RNA block, including lecture material and examples for RNA expression and splicing analysis.\nKent Riemondy and Kristen Wells contributed material for single-cell RNA sequencing.\nJay Hesselberth and Neel Mukherjee revamped much of this material in Fall 2023.\n\n\n\nExternal resources\nWe have borrowed from several (open licensed) resources for course content, including:\n\nStats 545 at UBC, particularly their grading rubrics\nCourses from Mine Çetinkaya-Rundel, particularly inspiration for quarto websites",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#land-acknowledgement",
    "href": "course-info/syllabus.html#land-acknowledgement",
    "title": "MOLB 7950 Syllabus",
    "section": "Land acknowledgement",
    "text": "Land acknowledgement\nThe University of Colorado honors and recognizes the many contributions of Indigenous peoples in our state. The University of Colorado acknowledges that it is located on the traditional territories and ancestral homelands of the Cheyenne, Arapaho, Ute and many other Native American nations. Their forced removal from these territories has caused devastating and lasting impacts. While the University of Colorado can never undo or rectify the devastation wrought on Indigenous peoples, we commit to improving and enhancing engagement with Indigenous peoples and issues locally and globally.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "exercises/ex-01.html",
    "href": "exercises/ex-01.html",
    "title": "R Bootcamp - Day 1",
    "section": "",
    "text": "We are using RStudio through Posit Cloud for the class.\nLook at RStudio panels one at a time.\nEnvironment, History, Console, Files, Plots, Packages, Help, etc.\n\nSee menu:\nHelp &gt; Cheat Sheets &gt; RStudio IDE Cheat Sheet"
  },
  {
    "objectID": "exercises/ex-01.html#rstudio---exercise-1",
    "href": "exercises/ex-01.html#rstudio---exercise-1",
    "title": "R Bootcamp - Day 1",
    "section": "",
    "text": "We are using RStudio through Posit Cloud for the class.\nLook at RStudio panels one at a time.\nEnvironment, History, Console, Files, Plots, Packages, Help, etc.\n\nSee menu:\nHelp &gt; Cheat Sheets &gt; RStudio IDE Cheat Sheet"
  },
  {
    "objectID": "exercises/ex-01.html#r-as-a-calculator---exercise-2",
    "href": "exercises/ex-01.html#r-as-a-calculator---exercise-2",
    "title": "R Bootcamp - Day 1",
    "section": "R as a calculator - Exercise 2",
    "text": "R as a calculator - Exercise 2\n\nR can function like an advanced calculator\n\n\nTry simple math.\nAssign a numeric value to an object.\n\n\n&lt;- and = are assignment operators.\nBy convention, R programmers use &lt;-.\n\nx &lt;- 1 reads “set the value of x to 1”.\n\n. . .\n= and == are two different operators.\n\na = is used for assignment (e.g., x = 1)\na == tests for equivalence (e.g. x == 1 says “does x equal 1?”)"
  },
  {
    "objectID": "exercises/ex-01.html#functions-and-arguments---exercise-3",
    "href": "exercises/ex-01.html#functions-and-arguments---exercise-3",
    "title": "R Bootcamp - Day 1",
    "section": "Functions and arguments - Exercise 3",
    "text": "Functions and arguments - Exercise 3"
  },
  {
    "objectID": "exercises/ex-01.html#writing-a-simple-function---exercise-4",
    "href": "exercises/ex-01.html#writing-a-simple-function---exercise-4",
    "title": "R Bootcamp - Day 1",
    "section": "Writing a simple function - Exercise 4",
    "text": "Writing a simple function - Exercise 4"
  },
  {
    "objectID": "exercises/ex-01.html#data-types---exercise-5",
    "href": "exercises/ex-01.html#data-types---exercise-5",
    "title": "R Bootcamp - Day 1",
    "section": "Data types - Exercise 5",
    "text": "Data types - Exercise 5\n\nThere are many data types in R.\nWe’ll mainly use numeric, character, and logical."
  },
  {
    "objectID": "exercises/ex-01.html#vectors---exercise-6",
    "href": "exercises/ex-01.html#vectors---exercise-6",
    "title": "R Bootcamp - Day 1",
    "section": "Vectors - Exercise 6",
    "text": "Vectors - Exercise 6\nLet’s create some vectors.\n\nThe c function combines values together (e.g., c(1,2,3))\n\n. . ."
  },
  {
    "objectID": "exercises/ex-01.html#data-frames",
    "href": "exercises/ex-01.html#data-frames",
    "title": "R Bootcamp - Day 1",
    "section": "Data frames",
    "text": "Data frames\n\nA data.frame is a rectangle, where each column is a vector, and each row is a slice across vectors.\ndata.frame columns are vectors, and can have different types (numeric, character, factor, etc.).\nA data.frame is constructed with data.frame()."
  },
  {
    "objectID": "exercises/ex-01.html#data-frames-tibbles---exercise-7",
    "href": "exercises/ex-01.html#data-frames-tibbles---exercise-7",
    "title": "R Bootcamp - Day 1",
    "section": "Data frames & tibbles - Exercise 7",
    "text": "Data frames & tibbles - Exercise 7\nCreate a data.frame and tibble.\nNow echo the contents of df and tbl to the console and inspect"
  },
  {
    "objectID": "exercises/ex-01.html#r-packages---exercise-8",
    "href": "exercises/ex-01.html#r-packages---exercise-8",
    "title": "R Bootcamp - Day 1",
    "section": "R packages - Exercise 8",
    "text": "R packages - Exercise 8\nLet’s do the following to explore R packages:\n\nLook at the “Environment” panel in Rstudio\nExplore Global Environment\nExplore the contents of a package"
  },
  {
    "objectID": "exercises/ex-01.html#quarto-exercise---exercise-9",
    "href": "exercises/ex-01.html#quarto-exercise---exercise-9",
    "title": "R Bootcamp - Day 1",
    "section": "Quarto Exercise - Exercise 9",
    "text": "Quarto Exercise - Exercise 9\nLet’s do the following to explore Quarto documents:\n\nCreate a new Quarto document\nRender the document to see the output"
  },
  {
    "objectID": "exercises/ex-01.html#problem-sets-and-submission",
    "href": "exercises/ex-01.html#problem-sets-and-submission",
    "title": "R Bootcamp - Day 1",
    "section": "Problem sets and submission",
    "text": "Problem sets and submission\nYour first problem set is in problem-sets/ps-01.qmd"
  },
  {
    "objectID": "exercises/ex-03.html",
    "href": "exercises/ex-03.html",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "",
    "text": "Explore these data sets:\n\ndplyr::starwars\n\ndplyr::band_members, dplyr::band_instruments, dplyr::band_instruments2"
  },
  {
    "objectID": "exercises/ex-03.html#todays-datasets---exercise-1",
    "href": "exercises/ex-03.html#todays-datasets---exercise-1",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "",
    "text": "Explore these data sets:\n\ndplyr::starwars\n\ndplyr::band_members, dplyr::band_instruments, dplyr::band_instruments2"
  },
  {
    "objectID": "exercises/ex-03.html#arrange---exercise-2",
    "href": "exercises/ex-03.html#arrange---exercise-2",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "arrange - Exercise 2",
    "text": "arrange - Exercise 2"
  },
  {
    "objectID": "exercises/ex-03.html#filter---exercise-3",
    "href": "exercises/ex-03.html#filter---exercise-3",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "filter - Exercise 3",
    "text": "filter - Exercise 3\nfilter by membership\n\n# filter based on skin color\n\nConditions can be combined using & (and), | (or).\n\n# filter on skin and eye color\n\nselect - Exercise 4\nmutate (& pipe |&gt;)- Exercise 5\n\n# create a new column to display height in meters\n\n# using the pipe to feed data into multiple functions sequentially\n\n# mutate allows you to refer to columns that you’ve just created\n\n# output needs to be saved into a new dataframe since dplyr does not \"change\" the original dataframe\n\n# using if_else clauses with mutate"
  },
  {
    "objectID": "exercises/ex-03.html#case_when---exercise-6",
    "href": "exercises/ex-03.html#case_when---exercise-6",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "case_when - Exercise 6",
    "text": "case_when - Exercise 6\n\n# create categories based on height\n\n\n# multiple conditions with case_when\n\nsummarise - Exercise 7\ngroup_by + summarize - Exercise 8\n\n# multiple grouping variables"
  },
  {
    "objectID": "exercises/ex-03.html#across---exercise-9",
    "href": "exercises/ex-03.html#across---exercise-9",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "across - Exercise 9",
    "text": "across - Exercise 9\n\n# apply mean to multiple columns\n\n\n# apply multiple functions with list()\n\n\n# combine across() with group_by()"
  },
  {
    "objectID": "exercises/ex-05.html",
    "href": "exercises/ex-05.html",
    "title": "R Bootcamp - Day 5",
    "section": "",
    "text": "Introduce ggplot2 & today’s data sets (Exercise 1)\nUnderstand the basics of ggplot2 (Exercise 2, 3)\nGeom functions (Exercise 4-8)\nGeom_point properties (Exercise 9)\nPosition adjustments (Exercise 10)\nCoordinate and Scale Functions (Exercise 11)\nZooming into a plot (Exercise 12)\n\n\n\nFaceting (Exercise 13)\nThemes (Exercise 14)\nLabels & Legends (Exercise 15)\nAdding lines to plots (Exercise 16)\nMaking multi-panel figures (Exercise 17)\nSaving a plot (Exercise 18)"
  },
  {
    "objectID": "exercises/ex-05.html#class-4-5-outline",
    "href": "exercises/ex-05.html#class-4-5-outline",
    "title": "R Bootcamp - Day 5",
    "section": "",
    "text": "Introduce ggplot2 & today’s data sets (Exercise 1)\nUnderstand the basics of ggplot2 (Exercise 2, 3)\nGeom functions (Exercise 4-8)\nGeom_point properties (Exercise 9)\nPosition adjustments (Exercise 10)\nCoordinate and Scale Functions (Exercise 11)\nZooming into a plot (Exercise 12)\n\n\n\nFaceting (Exercise 13)\nThemes (Exercise 14)\nLabels & Legends (Exercise 15)\nAdding lines to plots (Exercise 16)\nMaking multi-panel figures (Exercise 17)\nSaving a plot (Exercise 18)"
  },
  {
    "objectID": "exercises/ex-05.html#shape-size-fill-color-and-transparency---exercise-9",
    "href": "exercises/ex-05.html#shape-size-fill-color-and-transparency---exercise-9",
    "title": "R Bootcamp - Day 5",
    "section": "shape, size, fill, color, and transparency - Exercise 9",
    "text": "shape, size, fill, color, and transparency - Exercise 9\nGet a diamonds subset.\nNote that aesthetics can also be defined within a geom.\nThis is useful if you use two different geoms that share an aesthetic."
  },
  {
    "objectID": "exercises/ex-05.html#position-adjustments---exercise-10",
    "href": "exercises/ex-05.html#position-adjustments---exercise-10",
    "title": "R Bootcamp - Day 5",
    "section": "Position adjustments - Exercise 10",
    "text": "Position adjustments - Exercise 10\nA stacked bar chart.\nDodged bars are easier to read (proportions are clearer)"
  },
  {
    "objectID": "exercises/ex-05.html#coordinate-and-scale-functions---exercise-11",
    "href": "exercises/ex-05.html#coordinate-and-scale-functions---exercise-11",
    "title": "R Bootcamp - Day 5",
    "section": "Coordinate and Scale Functions - Exercise 11",
    "text": "Coordinate and Scale Functions - Exercise 11\nLogarithmic axes - 1\nNote the difference between axis labels in these two examples.\n\nLogarithmic axes - 2\n\nFlipping coordinate system (swapping x and y)\n\nNow flip the axis.\nBrief aside: ggplot can handle on-the-fly data transformations.\nHere we log-transform carat and convert USD to CAD."
  },
  {
    "objectID": "exercises/ex-05.html#zooming-into-a-plot---exercise-12",
    "href": "exercises/ex-05.html#zooming-into-a-plot---exercise-12",
    "title": "R Bootcamp - Day 5",
    "section": "Zooming into a plot - Exercise 12",
    "text": "Zooming into a plot - Exercise 12\nWe might want to change the limits of x or y axes to zoom in."
  },
  {
    "objectID": "exercises/ex-05.html#faceting-to-plot-subsets-of-data-into-separate-panels---exercise-13",
    "href": "exercises/ex-05.html#faceting-to-plot-subsets-of-data-into-separate-panels---exercise-13",
    "title": "R Bootcamp - Day 5",
    "section": "Faceting to plot subsets of data into separate panels - Exercise 13",
    "text": "Faceting to plot subsets of data into separate panels - Exercise 13\nA density plot we’ve seen before.\nWhich variables can we use to subdivide the data?\n\nFaceted by cut\nLet’s also use facet_grid() to facet by two variables.\nFaceted by clarity and cut.\n\nScatter plot with facets."
  },
  {
    "objectID": "exercises/ex-05.html#themes---exercise-14",
    "href": "exercises/ex-05.html#themes---exercise-14",
    "title": "R Bootcamp - Day 5",
    "section": "Themes - Exercise 14",
    "text": "Themes - Exercise 14\nScatter plot with default theme.\nChange the theme with theme_bw().\nMy go-to is cowplot::theme_cowplot().\nIt implements much of the advice in the “Dataviz” book, i.e.. YOUR LABELS ARE TOO SMALL.\nWe’re not going to cover it, but you can also customize pre-existing themes."
  },
  {
    "objectID": "exercises/ex-05.html#labels-legends---exercise-15",
    "href": "exercises/ex-05.html#labels-legends---exercise-15",
    "title": "R Bootcamp - Day 5",
    "section": "Labels & Legends - Exercise 15",
    "text": "Labels & Legends - Exercise 15\nUse labs() to add / change plot labels."
  },
  {
    "objectID": "exercises/ex-05.html#how-to-add-a-line-to-a-plot-exercise-16",
    "href": "exercises/ex-05.html#how-to-add-a-line-to-a-plot-exercise-16",
    "title": "R Bootcamp - Day 5",
    "section": "How to add a line to a plot? (Exercise 16)",
    "text": "How to add a line to a plot? (Exercise 16)\n\nAlso try:"
  },
  {
    "objectID": "exercises/ex-05.html#how-to-combine-multiple-plots-into-a-figure-exercise-17",
    "href": "exercises/ex-05.html#how-to-combine-multiple-plots-into-a-figure-exercise-17",
    "title": "R Bootcamp - Day 5",
    "section": "How to combine multiple plots into a figure? (Exercise 17)",
    "text": "How to combine multiple plots into a figure? (Exercise 17)\nWe have 4 legends - can they be condensed?\nYes, but it is not exactly straightforward.\nneed to scroll below"
  },
  {
    "objectID": "exercises/ex-05.html#saving-plots-exercise-18",
    "href": "exercises/ex-05.html#saving-plots-exercise-18",
    "title": "R Bootcamp - Day 5",
    "section": "Saving plots (Exercise 18)",
    "text": "Saving plots (Exercise 18)\nSaves last plot as 5’ x 5’ file named “plot_final.png” in working directory.\nMatches file type to file extension."
  },
  {
    "objectID": "exercises/ex-08.html",
    "href": "exercises/ex-08.html",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "",
    "text": "In this problem set, you’ll work with the Brauer gene expression dataset to practice comprehensive tidyverse skills including data tidying, transformation, joins, pivoting, string manipulation, and statistical modeling using broom. The dataset contains gene expression measurements for yeast genes under different nutrient limitations and growth rates.\n\nBefore we start tidying and analyzing the data, take a moment to predict what you might find.\n\nQuestion: What patterns do you expect to see in gene expression across different nutrients and growth rates?\nHypothesis: Genes involved in nutrient uptake and metabolism will show higher expression under their respective limiting conditions."
  },
  {
    "objectID": "exercises/ex-08.html#predictions",
    "href": "exercises/ex-08.html#predictions",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "",
    "text": "Before we start tidying and analyzing the data, take a moment to predict what you might find.\n\nQuestion: What patterns do you expect to see in gene expression across different nutrients and growth rates?\nHypothesis: Genes involved in nutrient uptake and metabolism will show higher expression under their respective limiting conditions."
  },
  {
    "objectID": "exercises/ex-08.html#load-required-libraries",
    "href": "exercises/ex-08.html#load-required-libraries",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n2.1 Load Required Libraries",
    "text": "2.1 Load Required Libraries\n\nCode# Load required libraries"
  },
  {
    "objectID": "exercises/ex-08.html#load-the-data",
    "href": "exercises/ex-08.html#load-the-data",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n2.2 Load the Data",
    "text": "2.2 Load the Data\nTask 1: Load the raw Brauer gene expression data and examine its structure. What makes this data “messy” or untidy?\nBreadcrumbs: Use read_tsv() to load the data from the URL. Examine column names and the first few rows. Think about tidy data principles - what issues do you see with the current format?\n\nCode# Load the Brauer gene expression data\n# URL: \"https://github.com/rnabioco/molb-7950/raw/refs/heads/main/data/bootcamp/brauer_gene_exp_raw.tsv.gz\"\n\n\n\nCode# Examine the structure of the data"
  },
  {
    "objectID": "exercises/ex-08.html#separate-the-name-column",
    "href": "exercises/ex-08.html#separate-the-name-column",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n3.1 Separate the NAME Column",
    "text": "3.1 Separate the NAME Column\nTask 2: The NAME column contains multiple pieces of information separated by “||”. Split this into meaningful columns.\nBreadcrumbs: Use separate_wider_delim() to split the NAME column. You’ll want columns for gene name, biological process, molecular function, systematic name, and number. Don’t forget to clean up whitespace and handle empty strings.\n\nCode# Separate the NAME column into meaningful components"
  },
  {
    "objectID": "exercises/ex-08.html#create-a-tidy-dataset",
    "href": "exercises/ex-08.html#create-a-tidy-dataset",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n3.2 Create a Tidy Dataset",
    "text": "3.2 Create a Tidy Dataset\nTask 3: Transform the wide-format expression data into a long format suitable for analysis.\nBreadcrumbs: First select the relevant columns (systematic_name and the expression columns). Then use pivot_longer() to convert expression columns to rows. The column names contain both nutrient type and growth rate information.\n\nCode# Transform to long format"
  },
  {
    "objectID": "exercises/ex-08.html#parse-nutrient-and-rate-information",
    "href": "exercises/ex-08.html#parse-nutrient-and-rate-information",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n3.3 Parse Nutrient and Rate Information",
    "text": "3.3 Parse Nutrient and Rate Information\nTask 4: Extract nutrient type and growth rate from the column names in your long dataset.\nBreadcrumbs: The column names follow a pattern like “G0.05” where the first character is the nutrient abbreviation and the rest is the growth rate. Use separate_wider_position() to split these. Create a lookup table for nutrient abbreviations.\n\nCode# Extract nutrient and growth rate information\n\n\n\nCode# Create nutrient lookup table"
  },
  {
    "objectID": "exercises/ex-08.html#filter-and-clean",
    "href": "exercises/ex-08.html#filter-and-clean",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n4.1 Filter and Clean",
    "text": "4.1 Filter and Clean\nTask 5: Remove any rows with missing systematic names and add meaningful nutrient names.\nBreadcrumbs: Use filter() to remove empty systematic names. Create a nutrient lookup table and use left_join() to add full nutrient names. Convert appropriate columns to factors.\n\nCode# Filter and clean the data"
  },
  {
    "objectID": "exercises/ex-08.html#explore-expression-patterns",
    "href": "exercises/ex-08.html#explore-expression-patterns",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n4.2 Explore Expression Patterns",
    "text": "4.2 Explore Expression Patterns\nTask 6: Calculate summary statistics for gene expression by nutrient type.\nBreadcrumbs: Use group_by() and summarize() to calculate mean, median, and standard deviation of expression values for each nutrient. Which nutrients show the highest variability in expression?\n\nCode# Calculate summary statistics by nutrient"
  },
  {
    "objectID": "exercises/ex-08.html#identify-high-and-low-expression",
    "href": "exercises/ex-08.html#identify-high-and-low-expression",
    "title": "Exercises 8: Gene Expression Analysis with Tidyverse",
    "section": "\n4.3 Identify High and Low Expression",
    "text": "4.3 Identify High and Low Expression\nTask 7: Find genes with extreme expression values under different conditions.\nBreadcrumbs: For each nutrient-rate combination, identify the top 5 highest and lowest expressing genes. Use slice_max() and slice_min() or ranking functions. What patterns do you notice?\n\nCode# Find genes with extreme expression values"
  },
  {
    "objectID": "prepare/prepare-01.html",
    "href": "prepare/prepare-01.html",
    "title": "R Bootcamp",
    "section": "",
    "text": "Important\n\n\n\nBefore class begins, login with your CU credentials at Posit Cloud: https://sso.posit.cloud/cu-anschutz"
  },
  {
    "objectID": "prepare/prepare-01.html#prepare",
    "href": "prepare/prepare-01.html#prepare",
    "title": "R Bootcamp",
    "section": "Prepare",
    "text": "Prepare\n📖 Read the syllabus\n📖 Read the support resources\n📖 Look over the RStudio cheatsheet"
  },
  {
    "objectID": "prepare/prepare-03.html",
    "href": "prepare/prepare-03.html",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look over the dplyr cheatsheet.\nWe’ll be using the filter(), select(), mutate(), arrange(), group_by(), and summarise() functions. Pay special attention to the comparison operators and logical operators sections, as well as case_when() for conditional logic."
  },
  {
    "objectID": "prepare/prepare-03.html#prepare",
    "href": "prepare/prepare-03.html#prepare",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look over the dplyr cheatsheet.\nWe’ll be using the filter(), select(), mutate(), arrange(), group_by(), and summarise() functions. Pay special attention to the comparison operators and logical operators sections, as well as case_when() for conditional logic."
  },
  {
    "objectID": "prepare/prepare-07.html",
    "href": "prepare/prepare-07.html",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look at the *_join() functions in the dplyr cheatsheet. These animations are helpful visualizations of the join transformations.\nLook over the cheatsheets for stringr and forcats.\nLook over the scale_*() functions (second page) in the ggplot2 cheatsheet."
  },
  {
    "objectID": "prepare/prepare-07.html#prepare",
    "href": "prepare/prepare-07.html#prepare",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look at the *_join() functions in the dplyr cheatsheet. These animations are helpful visualizations of the join transformations.\nLook over the cheatsheets for stringr and forcats.\nLook over the scale_*() functions (second page) in the ggplot2 cheatsheet."
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html",
    "href": "problem-set-keys/ps-key-01.html",
    "title": "Problem Set 1 Key",
    "section": "",
    "text": "Each problem below is worth 8 points.\nThe problem set is due 12pm on Aug 30.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#problem-set",
    "href": "problem-set-keys/ps-key-01.html#problem-set",
    "title": "Problem Set 1 Key",
    "section": "",
    "text": "Each problem below is worth 8 points.\nThe problem set is due 12pm on Aug 30.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#setup",
    "href": "problem-set-keys/ps-key-01.html#setup",
    "title": "Problem Set 1 Key",
    "section": "Setup",
    "text": "Setup\nStart by loading libraries you need analysis below. When in doubt, start by loading the tidyverse package.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#question-1",
    "href": "problem-set-keys/ps-key-01.html#question-1",
    "title": "Problem Set 1 Key",
    "section": "Question 1",
    "text": "Question 1\nCreate 3 different vectors called x, y, and z:\n\n\nx should be character vector of length 5 (hint: use LETTERS or letters)\n\ny should be a numeric vector of length 5 (hint: try 1:5 or c(1, 2, 3, 4, 5))\n\nz should be a logical vector of length 5 (hint: use TRUE and FALSE values)\n\nUse length() to calculate the length of each vector.\n\nx &lt;- LETTERS[1:5]\ny &lt;- 1:5\nz &lt;- c(TRUE, TRUE, FALSE, FALSE, FALSE)\n\nx\n\n[1] \"A\" \"B\" \"C\" \"D\" \"E\"\n\ny\n\n[1] 1 2 3 4 5\n\nz\n\n[1]  TRUE  TRUE FALSE FALSE FALSE\n\n# Traditional way\nlength(x)\n\n[1] 5\n\nlength(y)\n\n[1] 5\n\nlength(z)\n\n[1] 5"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#question-2",
    "href": "problem-set-keys/ps-key-01.html#question-2",
    "title": "Problem Set 1 Key",
    "section": "Question 2",
    "text": "Question 2\nUsing the vectors you created above, create a new tibble with column names x, y, and z. Use the tibble() function to combine your vectors into a data frame.\nUse nrow() and ncol() to calculate the number of rows and columns, both with and without the pipe operator.\nUse glimpse() to get a quick overview of your tibble - this shows data types and first few values.\nWhat do you notice about the length of the vectors and the number of rows?\n\ntbl &lt;- tibble(x = x, y = y, z = z)\n\n# Traditional way\nnrow(tbl)\n\n[1] 5\n\nncol(tbl)\n\n[1] 3\n\n# Get a quick overview\nglimpse(tbl)\n\nRows: 5\nColumns: 3\n$ x &lt;chr&gt; \"A\", \"B\", \"C\", \"D\", \"E\"\n$ y &lt;int&gt; 1, 2, 3, 4, 5\n$ z &lt;lgl&gt; TRUE, TRUE, FALSE, FALSE, FALSE\n\n\nAnswer\nThe length of the vectors and the number of rows are the same, because tibble columns are simply the vectors we started with."
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#question-3",
    "href": "problem-set-keys/ps-key-01.html#question-3",
    "title": "Problem Set 1 Key",
    "section": "Question 3",
    "text": "Question 3\nLet’s explore the penguins dataset that we loaded.\n\nLook at the number of rows with nrow() - this tells us how many penguins are in the dataset\nLook at the number of columns with ncol() - this tells us how many variables we measured\nLook at the column names with names() - this shows us what variables we have\nGet a glimpse of the data with glimpse() - this shows data types and sample values\n\n\n# Explore the penguins dataset\nnrow(penguins)\n\n[1] 344\n\nncol(penguins)\n\n[1] 8\n\nnames(penguins)\n\n[1] \"species\"     \"island\"      \"bill_len\"    \"bill_dep\"    \"flipper_len\"\n[6] \"body_mass\"   \"sex\"         \"year\"       \n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species     &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Ad…\n$ island      &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgersen, Tor…\n$ bill_len    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, 42.0, …\n$ bill_dep    &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, 20.2, …\n$ flipper_len &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186, 180,…\n$ body_mass   &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, 4250, …\n$ sex         &lt;fct&gt; male, female, female, NA, female, male, female, male, NA, …\n$ year        &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#question-4",
    "href": "problem-set-keys/ps-key-01.html#question-4",
    "title": "Problem Set 1 Key",
    "section": "Question 4",
    "text": "Question 4\nNext we will think about data tidying. Let’s start by analyzing the penguins dataset.\nPart A: Is the penguins dataset tidy? To determine this, we need to think about the three principles of tidy data:\n\nEach variable forms a column\nEach observation forms a row\nEach type of observational unit forms a table\n\nLook at the penguins dataset and answer:\n\nWhat are the variables in the dataset? (Hint: use names(penguins) to see them)\nDoes each column represent a single variable?\nDoes each row represent a single penguin observation?\n\n\n# Look at the structure of penguins\npenguins |&gt; glimpse()\n\nRows: 344\nColumns: 8\n$ species     &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Ad…\n$ island      &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgersen, Tor…\n$ bill_len    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, 42.0, …\n$ bill_dep    &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, 20.2, …\n$ flipper_len &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186, 180,…\n$ body_mass   &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, 4250, …\n$ sex         &lt;fct&gt; male, female, female, NA, female, male, female, male, NA, …\n$ year        &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n# What are the variables?\nnames(penguins)\n\n[1] \"species\"     \"island\"      \"bill_len\"    \"bill_dep\"    \"flipper_len\"\n[6] \"body_mass\"   \"sex\"         \"year\"       \n\n# Look at a few rows\npenguins |&gt; head()\n\n  species    island bill_len bill_dep flipper_len body_mass    sex year\n1  Adelie Torgersen     39.1     18.7         181      3750   male 2007\n2  Adelie Torgersen     39.5     17.4         186      3800 female 2007\n3  Adelie Torgersen     40.3     18.0         195      3250 female 2007\n4  Adelie Torgersen       NA       NA          NA        NA   &lt;NA&gt; 2007\n5  Adelie Torgersen     36.7     19.3         193      3450 female 2007\n6  Adelie Torgersen     39.3     20.6         190      3650   male 2007\n\n\nAnswer: Yes, the penguins dataset is tidy because:\n\nEach column represents one variable (species, island, bill_length_mm, etc.)\nEach row represents one penguin observation\nAll observations are of the same type (penguin measurements)\n\nPart B: Now let’s examine some datasets that are NOT tidy. Use data() to see available datasets, then look at these two examples:\nExample 1: anscombe - This is a classic statistics dataset:\n\n# Look at the anscombe dataset\nanscombe\n\n   x1 x2 x3 x4    y1   y2    y3    y4\n1  10 10 10  8  8.04 9.14  7.46  6.58\n2   8  8  8  8  6.95 8.14  6.77  5.76\n3  13 13 13  8  7.58 8.74 12.74  7.71\n4   9  9  9  8  8.81 8.77  7.11  8.84\n5  11 11 11  8  8.33 9.26  7.81  8.47\n6  14 14 14  8  9.96 8.10  8.84  7.04\n7   6  6  6  8  7.24 6.13  6.08  5.25\n8   4  4  4 19  4.26 3.10  5.39 12.50\n9  12 12 12  8 10.84 9.13  8.15  5.56\n10  7  7  7  8  4.82 7.26  6.42  7.91\n11  5  5  5  8  5.68 4.74  5.73  6.89\n\nglimpse(anscombe)\n\nRows: 11\nColumns: 8\n$ x1 &lt;dbl&gt; 10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5\n$ x2 &lt;dbl&gt; 10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5\n$ x3 &lt;dbl&gt; 10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5\n$ x4 &lt;dbl&gt; 8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8\n$ y1 &lt;dbl&gt; 8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68\n$ y2 &lt;dbl&gt; 9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74\n$ y3 &lt;dbl&gt; 7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73\n$ y4 &lt;dbl&gt; 6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89\n\n\nIs anscombe tidy? Think about: - What are the actual variables? (Hint: x and y coordinates for different datasets) - How many different datasets are encoded in the column names? - What would a tidy version look like?\nExample 2: Choose another dataset - Pick one more dataset from data() and analyze whether it’s tidy:\n\n# Look at available datasets\ndata()\n\n# Choose one and examine it (examples: WorldPhones, UCBAdmissions, HairEyeColor)\n# Let's try WorldPhones as an example\nWorldPhones\n\n     N.Amer Europe Asia S.Amer Oceania Africa Mid.Amer\n1951  45939  21574 2876   1815    1646     89      555\n1956  60423  29990 4708   2568    2366   1411      733\n1957  64721  32510 5230   2695    2526   1546      773\n1958  68484  35218 6662   2845    2691   1663      836\n1959  71799  37598 6856   3000    2868   1769      911\n1960  76036  40341 8220   3145    3054   1905     1008\n1961  79831  43173 9053   3338    3224   2005     1076\n\n\n`\nPart C: Write a brief explanation (2-3 sentences) for each dataset about: 1. Whether it’s tidy or not 2. What makes it tidy/untidy 3. What the variables actually represent\nYour Analysis:\npenguins: The penguins dataset is tidy because each column represents a single variable (species, island, bill measurements, etc.), each row represents one penguin observation, and all data is the same type of observational unit (individual penguin measurements). The variables are clearly defined and there’s no mixing of different types of information in single columns.\nanscombe: The anscombe dataset is NOT tidy because it violates multiple tidy data principles. The actual variables are x-coordinates, y-coordinates, and dataset identifier, but the dataset identifier is encoded in the column names (x1, y1, x2, y2, etc.). Four different datasets are stored in one table, with each dataset’s x and y values spread across separate columns rather than being in rows with a dataset identifier column.\nWorldPhones: The WorldPhones dataset is NOT tidy because it has years as row names instead of a proper column, and regions are spread across columns rather than being values in a “region” variable. The actual variables should be year, region, and number of phones, but currently the year and region information is stored in the structure of the table rather than as data values. A tidy version would have one row per year-region combination."
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#submit",
    "href": "problem-set-keys/ps-key-01.html#submit",
    "title": "Problem Set 1 Key",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of the Posit Cloud project (NOT the HTML link) into the problem set on Canvas."
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html",
    "href": "problem-set-keys/ps-key-03.html",
    "title": "R Bootcamp Problem Set 3",
    "section": "",
    "text": "Start by loading libraries you need analysis in the code chunk below. When in doubt, start by loading the tidyverse package.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html#setup",
    "href": "problem-set-keys/ps-key-03.html#setup",
    "title": "R Bootcamp Problem Set 3",
    "section": "",
    "text": "Start by loading libraries you need analysis in the code chunk below. When in doubt, start by loading the tidyverse package.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html#problem-set",
    "href": "problem-set-keys/ps-key-03.html#problem-set",
    "title": "R Bootcamp Problem Set 3",
    "section": "Problem Set",
    "text": "Problem Set\nEach problem below is worth 5 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Aug 31.\nGrading rubric\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points ## Question 1\n\nLoad the palmerpenguins package (already done above). Inspect the penguins tibble with summary() to see the distribution of variables and any missing values.\nUse drop_na() to remove rows with NA values in the penguins tibble. Calculate how many rows were removed by subtracting the new count from the original count using nrow().\nThen, use count() to explore the data and see how many penguins of each species we have. This is a simple but powerful way to understand your data!\n\nsummary(penguins)\n\n      species          island       bill_len        bill_dep    \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n  flipper_len      body_mass        sex           year     \n Min.   :172.0   Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0   1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0   Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9   Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0   3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0   Max.   :6300                Max.   :2009  \n NA's   :2       NA's   :2                                 \n\n# Remove rows with any missing values\npenguins_nona &lt;- drop_na(penguins)\nnrow(penguins) - nrow(penguins_nona)\n\n[1] 11\n\n# Simple counting - this is a great way to explore data!\npenguins |&gt;\n  count(species)\n\n    species   n\n1    Adelie 152\n2 Chinstrap  68\n3    Gentoo 124\n\n# You can count by multiple variables too\npenguins |&gt;\n  count(species, island)\n\n    species    island   n\n1    Adelie    Biscoe  44\n2    Adelie     Dream  56\n3    Adelie Torgersen  52\n4 Chinstrap     Dream  68\n5    Gentoo    Biscoe 124\n\n\nThen, use replace_na() to replace NA values in bill_length_mm and bill_depth_mm with a value of 0. You’ll need to:\n\nProvide the data frame as the first argument\nProvide a named list showing which columns to replace and what values to use\n\n\nreplace_na(penguins, list(bill_length_mm = 0, bill_depth_mm = 0))\n\n      species    island bill_len bill_dep flipper_len body_mass    sex year\n1      Adelie Torgersen     39.1     18.7         181      3750   male 2007\n2      Adelie Torgersen     39.5     17.4         186      3800 female 2007\n3      Adelie Torgersen     40.3     18.0         195      3250 female 2007\n4      Adelie Torgersen       NA       NA          NA        NA   &lt;NA&gt; 2007\n5      Adelie Torgersen     36.7     19.3         193      3450 female 2007\n6      Adelie Torgersen     39.3     20.6         190      3650   male 2007\n7      Adelie Torgersen     38.9     17.8         181      3625 female 2007\n8      Adelie Torgersen     39.2     19.6         195      4675   male 2007\n9      Adelie Torgersen     34.1     18.1         193      3475   &lt;NA&gt; 2007\n10     Adelie Torgersen     42.0     20.2         190      4250   &lt;NA&gt; 2007\n11     Adelie Torgersen     37.8     17.1         186      3300   &lt;NA&gt; 2007\n12     Adelie Torgersen     37.8     17.3         180      3700   &lt;NA&gt; 2007\n13     Adelie Torgersen     41.1     17.6         182      3200 female 2007\n14     Adelie Torgersen     38.6     21.2         191      3800   male 2007\n15     Adelie Torgersen     34.6     21.1         198      4400   male 2007\n16     Adelie Torgersen     36.6     17.8         185      3700 female 2007\n17     Adelie Torgersen     38.7     19.0         195      3450 female 2007\n18     Adelie Torgersen     42.5     20.7         197      4500   male 2007\n19     Adelie Torgersen     34.4     18.4         184      3325 female 2007\n20     Adelie Torgersen     46.0     21.5         194      4200   male 2007\n21     Adelie    Biscoe     37.8     18.3         174      3400 female 2007\n22     Adelie    Biscoe     37.7     18.7         180      3600   male 2007\n23     Adelie    Biscoe     35.9     19.2         189      3800 female 2007\n24     Adelie    Biscoe     38.2     18.1         185      3950   male 2007\n25     Adelie    Biscoe     38.8     17.2         180      3800   male 2007\n26     Adelie    Biscoe     35.3     18.9         187      3800 female 2007\n27     Adelie    Biscoe     40.6     18.6         183      3550   male 2007\n28     Adelie    Biscoe     40.5     17.9         187      3200 female 2007\n29     Adelie    Biscoe     37.9     18.6         172      3150 female 2007\n30     Adelie    Biscoe     40.5     18.9         180      3950   male 2007\n31     Adelie     Dream     39.5     16.7         178      3250 female 2007\n32     Adelie     Dream     37.2     18.1         178      3900   male 2007\n33     Adelie     Dream     39.5     17.8         188      3300 female 2007\n34     Adelie     Dream     40.9     18.9         184      3900   male 2007\n35     Adelie     Dream     36.4     17.0         195      3325 female 2007\n36     Adelie     Dream     39.2     21.1         196      4150   male 2007\n37     Adelie     Dream     38.8     20.0         190      3950   male 2007\n38     Adelie     Dream     42.2     18.5         180      3550 female 2007\n39     Adelie     Dream     37.6     19.3         181      3300 female 2007\n40     Adelie     Dream     39.8     19.1         184      4650   male 2007\n41     Adelie     Dream     36.5     18.0         182      3150 female 2007\n42     Adelie     Dream     40.8     18.4         195      3900   male 2007\n43     Adelie     Dream     36.0     18.5         186      3100 female 2007\n44     Adelie     Dream     44.1     19.7         196      4400   male 2007\n45     Adelie     Dream     37.0     16.9         185      3000 female 2007\n46     Adelie     Dream     39.6     18.8         190      4600   male 2007\n47     Adelie     Dream     41.1     19.0         182      3425   male 2007\n48     Adelie     Dream     37.5     18.9         179      2975   &lt;NA&gt; 2007\n49     Adelie     Dream     36.0     17.9         190      3450 female 2007\n50     Adelie     Dream     42.3     21.2         191      4150   male 2007\n51     Adelie    Biscoe     39.6     17.7         186      3500 female 2008\n52     Adelie    Biscoe     40.1     18.9         188      4300   male 2008\n53     Adelie    Biscoe     35.0     17.9         190      3450 female 2008\n54     Adelie    Biscoe     42.0     19.5         200      4050   male 2008\n55     Adelie    Biscoe     34.5     18.1         187      2900 female 2008\n56     Adelie    Biscoe     41.4     18.6         191      3700   male 2008\n57     Adelie    Biscoe     39.0     17.5         186      3550 female 2008\n58     Adelie    Biscoe     40.6     18.8         193      3800   male 2008\n59     Adelie    Biscoe     36.5     16.6         181      2850 female 2008\n60     Adelie    Biscoe     37.6     19.1         194      3750   male 2008\n61     Adelie    Biscoe     35.7     16.9         185      3150 female 2008\n62     Adelie    Biscoe     41.3     21.1         195      4400   male 2008\n63     Adelie    Biscoe     37.6     17.0         185      3600 female 2008\n64     Adelie    Biscoe     41.1     18.2         192      4050   male 2008\n65     Adelie    Biscoe     36.4     17.1         184      2850 female 2008\n66     Adelie    Biscoe     41.6     18.0         192      3950   male 2008\n67     Adelie    Biscoe     35.5     16.2         195      3350 female 2008\n68     Adelie    Biscoe     41.1     19.1         188      4100   male 2008\n69     Adelie Torgersen     35.9     16.6         190      3050 female 2008\n70     Adelie Torgersen     41.8     19.4         198      4450   male 2008\n71     Adelie Torgersen     33.5     19.0         190      3600 female 2008\n72     Adelie Torgersen     39.7     18.4         190      3900   male 2008\n73     Adelie Torgersen     39.6     17.2         196      3550 female 2008\n74     Adelie Torgersen     45.8     18.9         197      4150   male 2008\n75     Adelie Torgersen     35.5     17.5         190      3700 female 2008\n76     Adelie Torgersen     42.8     18.5         195      4250   male 2008\n77     Adelie Torgersen     40.9     16.8         191      3700 female 2008\n78     Adelie Torgersen     37.2     19.4         184      3900   male 2008\n79     Adelie Torgersen     36.2     16.1         187      3550 female 2008\n80     Adelie Torgersen     42.1     19.1         195      4000   male 2008\n81     Adelie Torgersen     34.6     17.2         189      3200 female 2008\n82     Adelie Torgersen     42.9     17.6         196      4700   male 2008\n83     Adelie Torgersen     36.7     18.8         187      3800 female 2008\n84     Adelie Torgersen     35.1     19.4         193      4200   male 2008\n85     Adelie     Dream     37.3     17.8         191      3350 female 2008\n86     Adelie     Dream     41.3     20.3         194      3550   male 2008\n87     Adelie     Dream     36.3     19.5         190      3800   male 2008\n88     Adelie     Dream     36.9     18.6         189      3500 female 2008\n89     Adelie     Dream     38.3     19.2         189      3950   male 2008\n90     Adelie     Dream     38.9     18.8         190      3600 female 2008\n91     Adelie     Dream     35.7     18.0         202      3550 female 2008\n92     Adelie     Dream     41.1     18.1         205      4300   male 2008\n93     Adelie     Dream     34.0     17.1         185      3400 female 2008\n94     Adelie     Dream     39.6     18.1         186      4450   male 2008\n95     Adelie     Dream     36.2     17.3         187      3300 female 2008\n96     Adelie     Dream     40.8     18.9         208      4300   male 2008\n97     Adelie     Dream     38.1     18.6         190      3700 female 2008\n98     Adelie     Dream     40.3     18.5         196      4350   male 2008\n99     Adelie     Dream     33.1     16.1         178      2900 female 2008\n100    Adelie     Dream     43.2     18.5         192      4100   male 2008\n101    Adelie    Biscoe     35.0     17.9         192      3725 female 2009\n102    Adelie    Biscoe     41.0     20.0         203      4725   male 2009\n103    Adelie    Biscoe     37.7     16.0         183      3075 female 2009\n104    Adelie    Biscoe     37.8     20.0         190      4250   male 2009\n105    Adelie    Biscoe     37.9     18.6         193      2925 female 2009\n106    Adelie    Biscoe     39.7     18.9         184      3550   male 2009\n107    Adelie    Biscoe     38.6     17.2         199      3750 female 2009\n108    Adelie    Biscoe     38.2     20.0         190      3900   male 2009\n109    Adelie    Biscoe     38.1     17.0         181      3175 female 2009\n110    Adelie    Biscoe     43.2     19.0         197      4775   male 2009\n111    Adelie    Biscoe     38.1     16.5         198      3825 female 2009\n112    Adelie    Biscoe     45.6     20.3         191      4600   male 2009\n113    Adelie    Biscoe     39.7     17.7         193      3200 female 2009\n114    Adelie    Biscoe     42.2     19.5         197      4275   male 2009\n115    Adelie    Biscoe     39.6     20.7         191      3900 female 2009\n116    Adelie    Biscoe     42.7     18.3         196      4075   male 2009\n117    Adelie Torgersen     38.6     17.0         188      2900 female 2009\n118    Adelie Torgersen     37.3     20.5         199      3775   male 2009\n119    Adelie Torgersen     35.7     17.0         189      3350 female 2009\n120    Adelie Torgersen     41.1     18.6         189      3325   male 2009\n121    Adelie Torgersen     36.2     17.2         187      3150 female 2009\n122    Adelie Torgersen     37.7     19.8         198      3500   male 2009\n123    Adelie Torgersen     40.2     17.0         176      3450 female 2009\n124    Adelie Torgersen     41.4     18.5         202      3875   male 2009\n125    Adelie Torgersen     35.2     15.9         186      3050 female 2009\n126    Adelie Torgersen     40.6     19.0         199      4000   male 2009\n127    Adelie Torgersen     38.8     17.6         191      3275 female 2009\n128    Adelie Torgersen     41.5     18.3         195      4300   male 2009\n129    Adelie Torgersen     39.0     17.1         191      3050 female 2009\n130    Adelie Torgersen     44.1     18.0         210      4000   male 2009\n131    Adelie Torgersen     38.5     17.9         190      3325 female 2009\n132    Adelie Torgersen     43.1     19.2         197      3500   male 2009\n133    Adelie     Dream     36.8     18.5         193      3500 female 2009\n134    Adelie     Dream     37.5     18.5         199      4475   male 2009\n135    Adelie     Dream     38.1     17.6         187      3425 female 2009\n136    Adelie     Dream     41.1     17.5         190      3900   male 2009\n137    Adelie     Dream     35.6     17.5         191      3175 female 2009\n138    Adelie     Dream     40.2     20.1         200      3975   male 2009\n139    Adelie     Dream     37.0     16.5         185      3400 female 2009\n140    Adelie     Dream     39.7     17.9         193      4250   male 2009\n141    Adelie     Dream     40.2     17.1         193      3400 female 2009\n142    Adelie     Dream     40.6     17.2         187      3475   male 2009\n143    Adelie     Dream     32.1     15.5         188      3050 female 2009\n144    Adelie     Dream     40.7     17.0         190      3725   male 2009\n145    Adelie     Dream     37.3     16.8         192      3000 female 2009\n146    Adelie     Dream     39.0     18.7         185      3650   male 2009\n147    Adelie     Dream     39.2     18.6         190      4250   male 2009\n148    Adelie     Dream     36.6     18.4         184      3475 female 2009\n149    Adelie     Dream     36.0     17.8         195      3450 female 2009\n150    Adelie     Dream     37.8     18.1         193      3750   male 2009\n151    Adelie     Dream     36.0     17.1         187      3700 female 2009\n152    Adelie     Dream     41.5     18.5         201      4000   male 2009\n153    Gentoo    Biscoe     46.1     13.2         211      4500 female 2007\n154    Gentoo    Biscoe     50.0     16.3         230      5700   male 2007\n155    Gentoo    Biscoe     48.7     14.1         210      4450 female 2007\n156    Gentoo    Biscoe     50.0     15.2         218      5700   male 2007\n157    Gentoo    Biscoe     47.6     14.5         215      5400   male 2007\n158    Gentoo    Biscoe     46.5     13.5         210      4550 female 2007\n159    Gentoo    Biscoe     45.4     14.6         211      4800 female 2007\n160    Gentoo    Biscoe     46.7     15.3         219      5200   male 2007\n161    Gentoo    Biscoe     43.3     13.4         209      4400 female 2007\n162    Gentoo    Biscoe     46.8     15.4         215      5150   male 2007\n163    Gentoo    Biscoe     40.9     13.7         214      4650 female 2007\n164    Gentoo    Biscoe     49.0     16.1         216      5550   male 2007\n165    Gentoo    Biscoe     45.5     13.7         214      4650 female 2007\n166    Gentoo    Biscoe     48.4     14.6         213      5850   male 2007\n167    Gentoo    Biscoe     45.8     14.6         210      4200 female 2007\n168    Gentoo    Biscoe     49.3     15.7         217      5850   male 2007\n169    Gentoo    Biscoe     42.0     13.5         210      4150 female 2007\n170    Gentoo    Biscoe     49.2     15.2         221      6300   male 2007\n171    Gentoo    Biscoe     46.2     14.5         209      4800 female 2007\n172    Gentoo    Biscoe     48.7     15.1         222      5350   male 2007\n173    Gentoo    Biscoe     50.2     14.3         218      5700   male 2007\n174    Gentoo    Biscoe     45.1     14.5         215      5000 female 2007\n175    Gentoo    Biscoe     46.5     14.5         213      4400 female 2007\n176    Gentoo    Biscoe     46.3     15.8         215      5050   male 2007\n177    Gentoo    Biscoe     42.9     13.1         215      5000 female 2007\n178    Gentoo    Biscoe     46.1     15.1         215      5100   male 2007\n179    Gentoo    Biscoe     44.5     14.3         216      4100   &lt;NA&gt; 2007\n180    Gentoo    Biscoe     47.8     15.0         215      5650   male 2007\n181    Gentoo    Biscoe     48.2     14.3         210      4600 female 2007\n182    Gentoo    Biscoe     50.0     15.3         220      5550   male 2007\n183    Gentoo    Biscoe     47.3     15.3         222      5250   male 2007\n184    Gentoo    Biscoe     42.8     14.2         209      4700 female 2007\n185    Gentoo    Biscoe     45.1     14.5         207      5050 female 2007\n186    Gentoo    Biscoe     59.6     17.0         230      6050   male 2007\n187    Gentoo    Biscoe     49.1     14.8         220      5150 female 2008\n188    Gentoo    Biscoe     48.4     16.3         220      5400   male 2008\n189    Gentoo    Biscoe     42.6     13.7         213      4950 female 2008\n190    Gentoo    Biscoe     44.4     17.3         219      5250   male 2008\n191    Gentoo    Biscoe     44.0     13.6         208      4350 female 2008\n192    Gentoo    Biscoe     48.7     15.7         208      5350   male 2008\n193    Gentoo    Biscoe     42.7     13.7         208      3950 female 2008\n194    Gentoo    Biscoe     49.6     16.0         225      5700   male 2008\n195    Gentoo    Biscoe     45.3     13.7         210      4300 female 2008\n196    Gentoo    Biscoe     49.6     15.0         216      4750   male 2008\n197    Gentoo    Biscoe     50.5     15.9         222      5550   male 2008\n198    Gentoo    Biscoe     43.6     13.9         217      4900 female 2008\n199    Gentoo    Biscoe     45.5     13.9         210      4200 female 2008\n200    Gentoo    Biscoe     50.5     15.9         225      5400   male 2008\n201    Gentoo    Biscoe     44.9     13.3         213      5100 female 2008\n202    Gentoo    Biscoe     45.2     15.8         215      5300   male 2008\n203    Gentoo    Biscoe     46.6     14.2         210      4850 female 2008\n204    Gentoo    Biscoe     48.5     14.1         220      5300   male 2008\n205    Gentoo    Biscoe     45.1     14.4         210      4400 female 2008\n206    Gentoo    Biscoe     50.1     15.0         225      5000   male 2008\n207    Gentoo    Biscoe     46.5     14.4         217      4900 female 2008\n208    Gentoo    Biscoe     45.0     15.4         220      5050   male 2008\n209    Gentoo    Biscoe     43.8     13.9         208      4300 female 2008\n210    Gentoo    Biscoe     45.5     15.0         220      5000   male 2008\n211    Gentoo    Biscoe     43.2     14.5         208      4450 female 2008\n212    Gentoo    Biscoe     50.4     15.3         224      5550   male 2008\n213    Gentoo    Biscoe     45.3     13.8         208      4200 female 2008\n214    Gentoo    Biscoe     46.2     14.9         221      5300   male 2008\n215    Gentoo    Biscoe     45.7     13.9         214      4400 female 2008\n216    Gentoo    Biscoe     54.3     15.7         231      5650   male 2008\n217    Gentoo    Biscoe     45.8     14.2         219      4700 female 2008\n218    Gentoo    Biscoe     49.8     16.8         230      5700   male 2008\n219    Gentoo    Biscoe     46.2     14.4         214      4650   &lt;NA&gt; 2008\n220    Gentoo    Biscoe     49.5     16.2         229      5800   male 2008\n221    Gentoo    Biscoe     43.5     14.2         220      4700 female 2008\n222    Gentoo    Biscoe     50.7     15.0         223      5550   male 2008\n223    Gentoo    Biscoe     47.7     15.0         216      4750 female 2008\n224    Gentoo    Biscoe     46.4     15.6         221      5000   male 2008\n225    Gentoo    Biscoe     48.2     15.6         221      5100   male 2008\n226    Gentoo    Biscoe     46.5     14.8         217      5200 female 2008\n227    Gentoo    Biscoe     46.4     15.0         216      4700 female 2008\n228    Gentoo    Biscoe     48.6     16.0         230      5800   male 2008\n229    Gentoo    Biscoe     47.5     14.2         209      4600 female 2008\n230    Gentoo    Biscoe     51.1     16.3         220      6000   male 2008\n231    Gentoo    Biscoe     45.2     13.8         215      4750 female 2008\n232    Gentoo    Biscoe     45.2     16.4         223      5950   male 2008\n233    Gentoo    Biscoe     49.1     14.5         212      4625 female 2009\n234    Gentoo    Biscoe     52.5     15.6         221      5450   male 2009\n235    Gentoo    Biscoe     47.4     14.6         212      4725 female 2009\n236    Gentoo    Biscoe     50.0     15.9         224      5350   male 2009\n237    Gentoo    Biscoe     44.9     13.8         212      4750 female 2009\n238    Gentoo    Biscoe     50.8     17.3         228      5600   male 2009\n239    Gentoo    Biscoe     43.4     14.4         218      4600 female 2009\n240    Gentoo    Biscoe     51.3     14.2         218      5300   male 2009\n241    Gentoo    Biscoe     47.5     14.0         212      4875 female 2009\n242    Gentoo    Biscoe     52.1     17.0         230      5550   male 2009\n243    Gentoo    Biscoe     47.5     15.0         218      4950 female 2009\n244    Gentoo    Biscoe     52.2     17.1         228      5400   male 2009\n245    Gentoo    Biscoe     45.5     14.5         212      4750 female 2009\n246    Gentoo    Biscoe     49.5     16.1         224      5650   male 2009\n247    Gentoo    Biscoe     44.5     14.7         214      4850 female 2009\n248    Gentoo    Biscoe     50.8     15.7         226      5200   male 2009\n249    Gentoo    Biscoe     49.4     15.8         216      4925   male 2009\n250    Gentoo    Biscoe     46.9     14.6         222      4875 female 2009\n251    Gentoo    Biscoe     48.4     14.4         203      4625 female 2009\n252    Gentoo    Biscoe     51.1     16.5         225      5250   male 2009\n253    Gentoo    Biscoe     48.5     15.0         219      4850 female 2009\n254    Gentoo    Biscoe     55.9     17.0         228      5600   male 2009\n255    Gentoo    Biscoe     47.2     15.5         215      4975 female 2009\n256    Gentoo    Biscoe     49.1     15.0         228      5500   male 2009\n257    Gentoo    Biscoe     47.3     13.8         216      4725   &lt;NA&gt; 2009\n258    Gentoo    Biscoe     46.8     16.1         215      5500   male 2009\n259    Gentoo    Biscoe     41.7     14.7         210      4700 female 2009\n260    Gentoo    Biscoe     53.4     15.8         219      5500   male 2009\n261    Gentoo    Biscoe     43.3     14.0         208      4575 female 2009\n262    Gentoo    Biscoe     48.1     15.1         209      5500   male 2009\n263    Gentoo    Biscoe     50.5     15.2         216      5000 female 2009\n264    Gentoo    Biscoe     49.8     15.9         229      5950   male 2009\n265    Gentoo    Biscoe     43.5     15.2         213      4650 female 2009\n266    Gentoo    Biscoe     51.5     16.3         230      5500   male 2009\n267    Gentoo    Biscoe     46.2     14.1         217      4375 female 2009\n268    Gentoo    Biscoe     55.1     16.0         230      5850   male 2009\n269    Gentoo    Biscoe     44.5     15.7         217      4875   &lt;NA&gt; 2009\n270    Gentoo    Biscoe     48.8     16.2         222      6000   male 2009\n271    Gentoo    Biscoe     47.2     13.7         214      4925 female 2009\n272    Gentoo    Biscoe       NA       NA          NA        NA   &lt;NA&gt; 2009\n273    Gentoo    Biscoe     46.8     14.3         215      4850 female 2009\n274    Gentoo    Biscoe     50.4     15.7         222      5750   male 2009\n275    Gentoo    Biscoe     45.2     14.8         212      5200 female 2009\n276    Gentoo    Biscoe     49.9     16.1         213      5400   male 2009\n277 Chinstrap     Dream     46.5     17.9         192      3500 female 2007\n278 Chinstrap     Dream     50.0     19.5         196      3900   male 2007\n279 Chinstrap     Dream     51.3     19.2         193      3650   male 2007\n280 Chinstrap     Dream     45.4     18.7         188      3525 female 2007\n281 Chinstrap     Dream     52.7     19.8         197      3725   male 2007\n282 Chinstrap     Dream     45.2     17.8         198      3950 female 2007\n283 Chinstrap     Dream     46.1     18.2         178      3250 female 2007\n284 Chinstrap     Dream     51.3     18.2         197      3750   male 2007\n285 Chinstrap     Dream     46.0     18.9         195      4150 female 2007\n286 Chinstrap     Dream     51.3     19.9         198      3700   male 2007\n287 Chinstrap     Dream     46.6     17.8         193      3800 female 2007\n288 Chinstrap     Dream     51.7     20.3         194      3775   male 2007\n289 Chinstrap     Dream     47.0     17.3         185      3700 female 2007\n290 Chinstrap     Dream     52.0     18.1         201      4050   male 2007\n291 Chinstrap     Dream     45.9     17.1         190      3575 female 2007\n292 Chinstrap     Dream     50.5     19.6         201      4050   male 2007\n293 Chinstrap     Dream     50.3     20.0         197      3300   male 2007\n294 Chinstrap     Dream     58.0     17.8         181      3700 female 2007\n295 Chinstrap     Dream     46.4     18.6         190      3450 female 2007\n296 Chinstrap     Dream     49.2     18.2         195      4400   male 2007\n297 Chinstrap     Dream     42.4     17.3         181      3600 female 2007\n298 Chinstrap     Dream     48.5     17.5         191      3400   male 2007\n299 Chinstrap     Dream     43.2     16.6         187      2900 female 2007\n300 Chinstrap     Dream     50.6     19.4         193      3800   male 2007\n301 Chinstrap     Dream     46.7     17.9         195      3300 female 2007\n302 Chinstrap     Dream     52.0     19.0         197      4150   male 2007\n303 Chinstrap     Dream     50.5     18.4         200      3400 female 2008\n304 Chinstrap     Dream     49.5     19.0         200      3800   male 2008\n305 Chinstrap     Dream     46.4     17.8         191      3700 female 2008\n306 Chinstrap     Dream     52.8     20.0         205      4550   male 2008\n307 Chinstrap     Dream     40.9     16.6         187      3200 female 2008\n308 Chinstrap     Dream     54.2     20.8         201      4300   male 2008\n309 Chinstrap     Dream     42.5     16.7         187      3350 female 2008\n310 Chinstrap     Dream     51.0     18.8         203      4100   male 2008\n311 Chinstrap     Dream     49.7     18.6         195      3600   male 2008\n312 Chinstrap     Dream     47.5     16.8         199      3900 female 2008\n313 Chinstrap     Dream     47.6     18.3         195      3850 female 2008\n314 Chinstrap     Dream     52.0     20.7         210      4800   male 2008\n315 Chinstrap     Dream     46.9     16.6         192      2700 female 2008\n316 Chinstrap     Dream     53.5     19.9         205      4500   male 2008\n317 Chinstrap     Dream     49.0     19.5         210      3950   male 2008\n318 Chinstrap     Dream     46.2     17.5         187      3650 female 2008\n319 Chinstrap     Dream     50.9     19.1         196      3550   male 2008\n320 Chinstrap     Dream     45.5     17.0         196      3500 female 2008\n321 Chinstrap     Dream     50.9     17.9         196      3675 female 2009\n322 Chinstrap     Dream     50.8     18.5         201      4450   male 2009\n323 Chinstrap     Dream     50.1     17.9         190      3400 female 2009\n324 Chinstrap     Dream     49.0     19.6         212      4300   male 2009\n325 Chinstrap     Dream     51.5     18.7         187      3250   male 2009\n326 Chinstrap     Dream     49.8     17.3         198      3675 female 2009\n327 Chinstrap     Dream     48.1     16.4         199      3325 female 2009\n328 Chinstrap     Dream     51.4     19.0         201      3950   male 2009\n329 Chinstrap     Dream     45.7     17.3         193      3600 female 2009\n330 Chinstrap     Dream     50.7     19.7         203      4050   male 2009\n331 Chinstrap     Dream     42.5     17.3         187      3350 female 2009\n332 Chinstrap     Dream     52.2     18.8         197      3450   male 2009\n333 Chinstrap     Dream     45.2     16.6         191      3250 female 2009\n334 Chinstrap     Dream     49.3     19.9         203      4050   male 2009\n335 Chinstrap     Dream     50.2     18.8         202      3800   male 2009\n336 Chinstrap     Dream     45.6     19.4         194      3525 female 2009\n337 Chinstrap     Dream     51.9     19.5         206      3950   male 2009\n338 Chinstrap     Dream     46.8     16.5         189      3650 female 2009\n339 Chinstrap     Dream     45.7     17.0         195      3650 female 2009\n340 Chinstrap     Dream     55.8     19.8         207      4000   male 2009\n341 Chinstrap     Dream     43.5     18.1         202      3400 female 2009\n342 Chinstrap     Dream     49.6     18.2         193      3775   male 2009\n343 Chinstrap     Dream     50.8     19.0         210      4100   male 2009\n344 Chinstrap     Dream     50.2     18.7         198      3775 female 2009"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html#question-2",
    "href": "problem-set-keys/ps-key-03.html#question-2",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 2",
    "text": "Question 2\nUse arrange, filter, and select on a data frame. Let’s build this step by step to understand how pipes work:\n\nImport the data set data/data_transcript_exp_tidy.csv using read_csv() and here().\n\nStep 2a: First, just sort the tibble by expression data (count) from highest to lowest level using arrange(). Use desc() to get descending order.\n\nStep 2b: Then add filter() to keep only rows where count &gt; 100. Chain this with the pipe operator.\n\nStep 2c: Finally, add select() to choose all columns except for type. Use the - operator to exclude columns.\n\n\nexp_tbl &lt;- read_csv(here(\"data/bootcamp/data_transcript_exp_tidy.csv.gz\"))\n\nRows: 600 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ensembl_transcript_id, type, time, replicate\ndbl (1): count\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Step 2a: Just arrange first\nexp_tbl |&gt;\n  arrange(desc(count)) # desc() for descending order\n\n# A tibble: 600 × 5\n   ensembl_transcript_id      type  time  replicate count\n   &lt;chr&gt;                      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 ENST00000234590.8_121_1423 rna   0h    rep2      11144\n 2 ENST00000234590.8_121_1423 rna   0h    rep3      10619\n 3 ENST00000234590.8_121_1423 rna   0h    rep1       9802\n 4 ENST00000234590.8_121_1423 rna   14h   rep3       6012\n 5 ENST00000234590.8_121_1423 rna   14h   rep1       5292\n 6 ENST00000234590.8_121_1423 rna   14h   rep2       5090\n 7 ENST00000377482.9_300_1611 rna   14h   rep1       1396\n 8 ENST00000377482.9_300_1611 rna   0h    rep2       1377\n 9 ENST00000377482.9_300_1611 rna   0h    rep1       1311\n10 ENST00000377482.9_300_1611 rna   0h    rep3       1244\n# ℹ 590 more rows\n\n# Step 2b: Add the filter\nexp_tbl |&gt;\n  arrange(desc(count)) |&gt;\n  filter(count &gt; 100)\n\n# A tibble: 109 × 5\n   ensembl_transcript_id      type  time  replicate count\n   &lt;chr&gt;                      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 ENST00000234590.8_121_1423 rna   0h    rep2      11144\n 2 ENST00000234590.8_121_1423 rna   0h    rep3      10619\n 3 ENST00000234590.8_121_1423 rna   0h    rep1       9802\n 4 ENST00000234590.8_121_1423 rna   14h   rep3       6012\n 5 ENST00000234590.8_121_1423 rna   14h   rep1       5292\n 6 ENST00000234590.8_121_1423 rna   14h   rep2       5090\n 7 ENST00000377482.9_300_1611 rna   14h   rep1       1396\n 8 ENST00000377482.9_300_1611 rna   0h    rep2       1377\n 9 ENST00000377482.9_300_1611 rna   0h    rep1       1311\n10 ENST00000377482.9_300_1611 rna   0h    rep3       1244\n# ℹ 99 more rows\n\n# Step 2c: Add the select (use -type to exclude the type column)\nexp_tbl |&gt;\n  arrange(desc(count)) |&gt;\n  filter(count &gt; 100) |&gt;\n  select(-type)\n\n# A tibble: 109 × 4\n   ensembl_transcript_id      time  replicate count\n   &lt;chr&gt;                      &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 ENST00000234590.8_121_1423 0h    rep2      11144\n 2 ENST00000234590.8_121_1423 0h    rep3      10619\n 3 ENST00000234590.8_121_1423 0h    rep1       9802\n 4 ENST00000234590.8_121_1423 14h   rep3       6012\n 5 ENST00000234590.8_121_1423 14h   rep1       5292\n 6 ENST00000234590.8_121_1423 14h   rep2       5090\n 7 ENST00000377482.9_300_1611 14h   rep1       1396\n 8 ENST00000377482.9_300_1611 0h    rep2       1377\n 9 ENST00000377482.9_300_1611 0h    rep1       1311\n10 ENST00000377482.9_300_1611 0h    rep3       1244\n# ℹ 99 more rows"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html#question-3",
    "href": "problem-set-keys/ps-key-03.html#question-3",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 3",
    "text": "Question 3\nHow will you:\n\ncreate a new column log10count that contains log10 transformed count values using mutate() and log10() and\nrearrange the columns in the following order: ensembl_transcript_id, type, time, replicate, count, log10count using select().\n\nBefore showing the solution, remember: - mutate() adds new columns (or modifies existing ones) - it keeps all existing columns - select() chooses columns and can reorder them - list them in the order you want\n\nexp_tbl |&gt;\n  mutate(log10count = log10(count)) |&gt;\n  select(ensembl_transcript_id, type, time, replicate, count, log10count)\n\n# A tibble: 600 × 6\n   ensembl_transcript_id      type  time  replicate count log10count\n   &lt;chr&gt;                      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 ENST00000327044.6_51_2298  rna   0h    rep1        243      2.39 \n 2 ENST00000327044.6_51_2298  rna   0h    rep2        322      2.51 \n 3 ENST00000327044.6_51_2298  rna   0h    rep3        303      2.48 \n 4 ENST00000327044.6_51_2298  rna   14h   rep1        177      2.25 \n 5 ENST00000327044.6_51_2298  rna   14h   rep2        177      2.25 \n 6 ENST00000327044.6_51_2298  rna   14h   rep3        239      2.38 \n 7 ENST00000338591.7_360_2034 rna   0h    rep1         19      1.28 \n 8 ENST00000338591.7_360_2034 rna   0h    rep2         17      1.23 \n 9 ENST00000338591.7_360_2034 rna   0h    rep3         15      1.18 \n10 ENST00000338591.7_360_2034 rna   14h   rep1          9      0.954\n# ℹ 590 more rows"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html#question-4",
    "href": "problem-set-keys/ps-key-03.html#question-4",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 4",
    "text": "Question 4\nLet’s explore grouping operations step by step. We’ll build your understanding progressively, starting with simple examples and then combining concepts.\nStep 4a: First, try a simple grouping operation. Calculate the total count per transcript (ignoring time). Use:\n\n\ngroup_by() to group by transcript ID\n\nsummarize() to calculate the sum of counts\n\n.groups = \"drop\" to remove grouping afterward (good practice!)\n\n\n# Simple grouping - sum counts for each transcript across all conditions\nexp_tbl |&gt;\n  group_by(ensembl_transcript_id) |&gt;\n  summarize(\n    total_count = sum(count),\n    .groups = \"drop\" # This removes the grouping afterward - good practice!\n  )\n\n# A tibble: 100 × 2\n   ensembl_transcript_id        total_count\n   &lt;chr&gt;                              &lt;dbl&gt;\n 1 ENST00000054650.8_159_876           50.3\n 2 ENST00000054666.10_116_416         728  \n 3 ENST00000054668.5_220_418           22.5\n 4 ENST00000234590.8_121_1423       47959  \n 5 ENST00000263741.11_1328_1496       176. \n 6 ENST00000263741.11_315_1338        845  \n 7 ENST00000270708.11_75_1455         274  \n 8 ENST00000288774.7_29_1067           96.5\n 9 ENST00000291386.3_370_895          805  \n10 ENST00000307896.10_39_753           50.3\n# ℹ 90 more rows\n\n\nStep 4b: Now calculate a per-transcript sum, while keeping the time information (group by both transcript and time). This creates separate groups for each combination of transcript AND time:\n\nexp_tbl |&gt;\n  group_by(ensembl_transcript_id, time) |&gt;\n  summarize(\n    count_sum = sum(count),\n    .groups = \"drop\"\n  )\n\n# A tibble: 200 × 3\n   ensembl_transcript_id        time  count_sum\n   &lt;chr&gt;                        &lt;chr&gt;     &lt;dbl&gt;\n 1 ENST00000054650.8_159_876    0h         33.8\n 2 ENST00000054650.8_159_876    14h        16.5\n 3 ENST00000054666.10_116_416   0h        447  \n 4 ENST00000054666.10_116_416   14h       281  \n 5 ENST00000054668.5_220_418    0h          0  \n 6 ENST00000054668.5_220_418    14h        22.5\n 7 ENST00000234590.8_121_1423   0h      31565  \n 8 ENST00000234590.8_121_1423   14h     16394  \n 9 ENST00000263741.11_1328_1496 0h         97.5\n10 ENST00000263741.11_1328_1496 14h        79  \n# ℹ 190 more rows"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html#question-5",
    "href": "problem-set-keys/ps-key-03.html#question-5",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 5",
    "text": "Question 5\nCreate meaningful categories from your data using case_when(). This function lets you create new variables based on multiple conditions\nCategorize the expression levels in the count column into meaningful groups:\n\n“Low” for counts less than 50\n“Medium” for counts between 50 and 200 (inclusive of 50, exclusive of 200)\n“High” for counts between 200 and 1000 (inclusive of 200, exclusive of 1000)\n“Very High” for counts 1000 and above\n\nUse case_when() inside mutate() to create a new column called expression_level, then use count() to see how many transcripts fall into each category.\n\n# Categorize expression levels into meaningful groups\nexp_tbl |&gt;\n  mutate(\n    expression_level = case_when(\n      count &lt; 50 ~ \"Low\",\n      count &lt; 200 ~ \"Medium\",\n      count &lt; 1000 ~ \"High\",\n      count &gt;= 1000 ~ \"Very High\",\n      .default = \"undetermined\" # in case of NA values\n    )\n  ) |&gt;\n  count(expression_level, sort = TRUE)\n\n# A tibble: 4 × 2\n  expression_level     n\n  &lt;chr&gt;            &lt;int&gt;\n1 Low                413\n2 Medium             150\n3 High                25\n4 Very High           12"
  },
  {
    "objectID": "problem-set-keys/ps-key-05.html",
    "href": "problem-set-keys/ps-key-05.html",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "",
    "text": "🐧❤️🍕\n\nCodelibrary(tidyverse)\nlibrary(emo)\nlibrary(here)\nlibrary(gganimate)\nlibrary(palmerpenguins)\nlibrary(ragg)\n\nset.seed(42)\n\nanim &lt;- penguins |&gt;\n  drop_na() |&gt;\n  mutate(\n    emoji = case_when(\n      sex == \"female\" ~ emo::ji(\"pizza\"),\n      sex == \"male\" ~ emo::ji(\"penguin\")\n    )\n  ) |&gt;\n  mutate(\n    angle = sample(\n      0:360,\n      size = n(),\n      replace = TRUE\n    )\n  ) |&gt;\n  select(\n    emoji,\n    angle,\n    mass = body_mass_g,\n    flipper = flipper_length_mm,\n    year\n  ) |&gt;\n  ggplot(\n    aes(\n      x = mass,\n      y = flipper\n    )\n  ) +\n  geom_text(\n    aes(\n      label = emoji,\n      angle = angle\n    ),\n    size = 13,\n  ) +\n  coord_trans(x = \"log\", y = \"log\") +\n  labs(\n    title = paste0(\n      \"PENGUIN\",\n      emo::ji(\"penguin\"),\n      \"PIZZA\",\n      emo::ji(\"pizza\"),\n      \"PARTY\",\n      emo::ji(\"party\"),\n      collapse = \"\"\n    ),\n    x = paste0(\n      emo::ji(\"island\"),\n      \"maybe latitude or longitude\",\n      collapse = \"  \"\n    ),\n    y = paste0(emo::ji(\"sun\"), \"temperature (K)\", collapse = \"  \")\n  ) +\n  theme(\n    legend.position = \"none\",\n    axis.text = element_text(angle = 180),\n    plot.title = element_text(hjust = 0.5, size = 30),\n    axis.title = element_text(size = 30),\n    axis.text.x = element_text(size = 2),\n    axis.text.y = element_text(size = 2),\n    plot.background = element_rect(fill = \"#ffcc5c\"),\n    panel.background = element_rect(fill = \"#ffeead\"),\n    panel.grid.major = element_line(color = \"#ff6f69\"),\n    panel.grid.minor = element_line(color = \"#96ceb4\")\n  ) +\n  transition_states(\n    transition_length = 1,\n    state_length = 0.001,\n    year\n  ) +\n  enter_grow() +\n  exit_shrink() +\n  view_follow()\n\nppp_plot &lt;- animate(anim, device = \"ragg_png\", renderer = gifski_renderer())\n\nanim_save(\n  filename = \"penguin-pizza-party.gif\",\n  animation = ppp_plot,\n  path = here(\"img\")\n)"
  },
  {
    "objectID": "problem-sets/ps-02.html",
    "href": "problem-sets/ps-02.html",
    "title": "Problem Set 2 Key",
    "section": "",
    "text": "Each problem below is worth 4 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Aug 27.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-sets/ps-02.html#problem-set",
    "href": "problem-sets/ps-02.html#problem-set",
    "title": "Problem Set 2 Key",
    "section": "",
    "text": "Each problem below is worth 4 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Aug 27.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-sets/ps-02.html#question-1",
    "href": "problem-sets/ps-02.html#question-1",
    "title": "Problem Set 2 Key",
    "section": "Question 1",
    "text": "Question 1\nStart by loading the libraries you need for analysis below. When in doubt, start by loading the tidyverse package. You should also load here.\n\nlibrary(___)\nlibrary(___)\n\nNow import the dataset data_transcript_exp_subset using the readr package. Use read_csv() to import the file.\nThe file is located at data/data_transcript_exp_subset.csv.gz - use here() to create the complete path.\n\nexp_tbl &lt;- read_csv(___)\n\nexp_tbl"
  },
  {
    "objectID": "problem-sets/ps-02.html#question-2",
    "href": "problem-sets/ps-02.html#question-2",
    "title": "Problem Set 2 Key",
    "section": "Question 2",
    "text": "Question 2\nExplore the dataset. Is this dataset tidy? If not, why not?\nThis data frame is a subset (100 lines) of transcript-level gene expression data where transcript abundance was measured at two different time points of a certain treatment conducted in triplicates. The column names have the format of molecule_time_replicate\nFirst, explore the structure of the dataset using some of the functions we learned in class. Try using glimpse(), summary(), and names() to understand the data structure.\nAdd more code chunks as needed to separate the different steps of your exploration.\n\nx\n\n\nnames(x)\n\nComment on whether this dataset is tidy, and if not, list the reasons why.\nHint: In a tidy dataframe, every column represents a single variable and every row represents a single observation\nAnswer\n[YOUR ANSWER HERE]"
  },
  {
    "objectID": "problem-sets/ps-02.html#question-3",
    "href": "problem-sets/ps-02.html#question-3",
    "title": "Problem Set 2 Key",
    "section": "Question 3",
    "text": "Question 3\nHow will you reshape the data frame so that each row has only one experimental observation?\nBefore we reshape, let’s think about what we want:\n\nWhich column should stay the same? (The transcript ID)\nWhich columns contain the measurements? (All the others)\nWhat should we call the new column names?\n\nUse pivot_longer() to reshape the data. You’ll want to:\n\nKeep the ensembl_transcript_id column as-is (cols)\nCreate a new column for the condition names (names_to)\nCreate a new column for the values (values_to)\n\n\n# Reshape the data so each row is one observation\nexp_tbl_long &lt;-\n  pivot_longer(\n    x,\n    cols = ___,\n    names_to = ___,\n    values_to = ___\n  )\n\nexp_tbl_long\n\nQuestion 4\nHow will you modify the dataframe so that multiple variables are not present in a single column?\nUse separate_wider_delim() to split the condition column into separate variables. You need to:\n\nSpecify which column to separate (cols)\nSpecify the delimiter character (delim)\nProvide the new column names (names)\n\n\nexp_tbl_tidy &lt;-\n  separate_wider_delim(\n    exp_tbl_long,\n    cols = ___,\n    delim = ___,\n    names = ___\n  )\n\nexp_tbl_tidy\n\nQuestion 5\nHow will you save your output as a TSV file?\nUse write_tsv() from the readr package to save your tidy data. Provide the data object and a filename.\nHint: Use the readr cheatsheet at the bottom of this page to figure this out.\nAfter running your new code, you should have a new file called transcripts.tidy.tsv in your working directory.\n\nwrite_tsv(exp_tbl_tidy, \"transcripts.tidy.tsv\")\n\nQuestion 6\nCan you reverse the process? How would you go from tidy back to wide format?\nUse pivot_wider() to go from the tidy format back to the original wide format. You need to:\n\nSpecify where the new column names come from (names_from)\nSpecify where the values come from (values_from)\nSpecify how to combine the names (names_sep)\n\n\npivot_wider(\n  exp_tbl_tidy,\n  names_from = ___,\n  values_from = ___,\n  names_sep = ___\n)\n\nAfter this, your new data should look like the original tibble you started with."
  },
  {
    "objectID": "problem-sets/ps-04.html",
    "href": "problem-sets/ps-04.html",
    "title": "R Bootcamp Problem Set 4",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Aug 29"
  },
  {
    "objectID": "problem-sets/ps-04.html#problem-set",
    "href": "problem-sets/ps-04.html#problem-set",
    "title": "R Bootcamp Problem Set 4",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Aug 29"
  },
  {
    "objectID": "problem-sets/ps-04.html#grading-rubric",
    "href": "problem-sets/ps-04.html#grading-rubric",
    "title": "R Bootcamp Problem Set 4",
    "section": "Grading rubric",
    "text": "Grading rubric\n\nEverything is good: full points\nPartially correct answer: depends on how many steps are correct\nReasonable attempt: half points"
  },
  {
    "objectID": "problem-sets/ps-04.html#question-1-5-points",
    "href": "problem-sets/ps-04.html#question-1-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 1 5 points\n",
    "text": "Question 1 5 points\n\n\nLoad the tidyverse and here packages using library().\nImport datasets: data/data_rna_protein.csv.gz using read_csv() and here().\n\ndata_rna_protein.csv.gz: This is a combined dataset from an RNAseq and SILAC proteomics experiment, where a transcription factor (TF) was differentially expressed and the fold change in RNA and protein calculated between TF-expressing and non-expressing cells.\n\nlibrary(tidyverse)\nlibrary(here)\n\nexp_tbl &lt;- read_csv(\n  here(___)\n)"
  },
  {
    "objectID": "problem-sets/ps-04.html#question-2-5-points",
    "href": "problem-sets/ps-04.html#question-2-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 2 5 points\n",
    "text": "Question 2 5 points\n\nLet’s build a data processing workflow step by step. This teaches you how to build complex pipelines gradually - a key skill in data analysis.\nStep 1: First, explore the data so you know what you’re working with. Use glimpse() to see column types and summary() to see distributions:\n\n# Always explore your data first!\n\nStep 2: Select only the columns we need:\n\n\ngeneid (gene identifier)\n\niDUX4_logFC (RNA fold change)\n\niDUX4_fdr (RNA pvalue)\n\nhl.ratio (protein fold change)\n\npval (protein pvalue)\n\nUse select() and list the columns you want to keep:\n\nexp_tbl |&gt;\n  select(___)\n\nStep 3: Rename columns for clarity (this makes your code more readable).\nUse dplyr::rename() with the pattern new_name = old_name, ...:\n\nexp_tbl |&gt;\n  select(___) |&gt;\n  rename(\n    ___ = ___,\n    # etc\n  )\n\nStep 4: Clean the data by removing rows with missing values. Use drop_na() to remove rows with any missing values, and distinct() to remove duplicate rows:\n\nexp_tbl |&gt;\n  select(___) |&gt;\n  rename(\n    ___ = ___,\n    # etc\n  ) |&gt;\n  ___() |&gt; # Remove rows with any missing values\n  ___() # Remove duplicate rows\n\nStep 5: Finally, arrange the data and save it. Use arrange() to sort by RNA fold change (high to low), then protein fold change (low to high):\n\nexp_tbl_subset &lt;- exp_tbl |&gt;\n  select(___) |&gt;\n  rename(\n    ___ = ___,\n    # etc\n  ) |&gt;\n  ___() |&gt; # Remove rows with any missing values\n  ___() |&gt; # Remove duplicate rows\n  # Sort by RNA fold change (high to low), then protein fold change (low to high)\n  ___(___, ___)\n\nexp_tbl_subset"
  },
  {
    "objectID": "problem-sets/ps-04.html#question-3-5-points",
    "href": "problem-sets/ps-04.html#question-3-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 3 5 points\n",
    "text": "Question 3 5 points\n\nLet’s practice good data analysis habits by checking for potential issues. Quality control is essential in real data analysis.\nCheck for duplicates and missing values:\n\nUse count() to check for duplicate genes\nUse summarize() with across() to count missing values in all columns\nUse summary statistics to understand data distributions\n\n\n# Check for duplicate genes (there shouldn't be any after distinct())\nexp_tbl_subset |&gt;\n  count(___) |&gt;\n  ___(n &gt; 1) # Any genes appearing more than once?\n\n\n# Summary of missing values by column\nexp_tbl_subset |&gt;\n  summarize(\n    # first blank select variables\n    # second blank applies a function to count NA values\n    across(___, ___)\n  )\n\n\n# Look at the distribution of our main variables\nexp_tbl_subset |&gt;\n  summarize(\n    across(\n      # specify the variables to summarize\n      ___,\n      list(\n        # mean\n        mean = ~ mean(., na.rm = TRUE),\n        # now do median\n        ___ = ~ ___(., na.rm = TRUE),\n        # and sd\n        ___ = ~ ___(., na.rm = TRUE)\n      )\n    ),\n    .groups = \"drop\"\n  )"
  },
  {
    "objectID": "problem-sets/ps-04.html#question-4-5-points",
    "href": "problem-sets/ps-04.html#question-4-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 4 5 points\n",
    "text": "Question 4 5 points\n\nHow well do the overall rna_FC and protein_FC values correlate in this experiment? We’ll explore this with visualization and statistics.\nStep 1: Create a scatter plot of rna_FC vs protein_FC using ggplot(). Use:\n\n\naes() to map x and y variables\n\ngeom_point() to create the scatter plot\n\nlabs() to add informative axis labels and title\n\n\nggplot(\n  ___,\n  aes(\n    x = ___,\n    y = ___\n  )\n) +\n  # ad points\n  ___() +\n  # add labels\n  labs(\n    x = \"___\",\n    y = \"___\",\n    title = \"___\"\n  )\n\nStep 2: Add reference lines to help interpret the correlation. Use:\n\n\ngeom_abline(slope = 1, intercept = 0) for perfect correlation line\n\ngeom_smooth(method = \"lm\", se = FALSE) for the computed trend line\nadjust the geom_point() aesthetic to alpha = 0.6, making points slightly transparent for better visualization\n\n\nggplot(\n  ___,\n  aes(\n    x = ___,\n    y = ___\n  )\n) +\n  # Add transparent points (change the ???)\n  geom_???(alpha = 0.6) +\n  # Add the perfect correlation line (change the ???)\n  geom_???(slope = 1, intercept = 0, color = \"red\", linewidth = 1) +\n  # Add the computed trend line (change the ???)\n  geom_???(method = \"lm\", se = FALSE, color = \"blue\", linewidth = 1) +\n  labs(\n    x = \"___\",\n    y = \"___\",\n    title = \"___\"\n  )\n\nStep 3: Calculate the correlation coefficient using cor(). Use Spearman correlation since it’s robust to outliers. Use ?cor to see the function documentation. You will need to specify two vectors for the calculation, and it’s easiest to provide them using the $ operator to extract columns from the data frame.\n\nrna_prot_cor &lt;- cor(\n  # specify the first vector\n  ___,\n  # specify the second vector\n  ___,\n  method = \"spearman\"\n)\n\nrna_prot_cor\n\nAnswer\n[ YOUR ANSWER HERE ]"
  },
  {
    "objectID": "problem-sets/ps-04.html#submit",
    "href": "problem-sets/ps-04.html#submit",
    "title": "R Bootcamp Problem Set 4",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of this Posit Cloud project into the problem set on Canvas."
  },
  {
    "objectID": "resources/block-dna-resources.html",
    "href": "resources/block-dna-resources.html",
    "title": "Resources for the DNA block",
    "section": "",
    "text": "These studies below laid the methodological groundwork for high throughput chromatin characterization by DNA sequencing. Some of the authors are here at CU Anschutz!\n\n\n\n\n\n\nTip\n\n\n\nData sets from these studies would be excellent choices as starting points for your final projects.\n\n\n\n\nHesselberth JR, Chen X, Zhang Z, Sabo PJ, Sandstrom R, Reynolds AP, Thurman RE, Neph S, Kuehn MS, Noble WS, Fields S, Stamatoyannopoulos JA. Global mapping of protein-DNA interactions in vivo by digital genomic footprinting. Nat Methods. 2009 19305407; PMCID: PMC2668528. [Link]\n\n\n\nBuenrostro JD, Giresi PG, Zaba LC, Chang HY, Greenleaf WJ. Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position. Nat Methods. 2013 PMID: 24097267; PMCID: PMC3959825. [Link]\n\n\n\nRamachandran S, Ahmad K, Henikoff S. Transcription and Remodeling Produce Asymmetrically Unwrapped Nucleosomal Intermediates. Mol Cell. 2017 PMID: 29225036; PMCID: PMC6421108. [Link]\n\n\n\nSkene PJ, Henikoff S. An efficient targeted nuclease strategy for high-resolution mapping of DNA binding sites. Elife. 2017 PMID: 28079019; PMCID: PMC5310842. [Link]\nKaya-Okur HS, Wu SJ, Codomo CA, Pledger ES, Bryson TD, Henikoff JG, Ahmad K, Henikoff S. CUT&Tag for efficient epigenomic profiling of small samples and single cells. Nat Commun. 2019 PMID: 31036827; PMCID: PMC6488672. [Link]",
    "crumbs": [
      "Resources",
      "DNA Block resources"
    ]
  },
  {
    "objectID": "resources/block-dna-resources.html#foundational-work",
    "href": "resources/block-dna-resources.html#foundational-work",
    "title": "Resources for the DNA block",
    "section": "",
    "text": "These studies below laid the methodological groundwork for high throughput chromatin characterization by DNA sequencing. Some of the authors are here at CU Anschutz!\n\n\n\n\n\n\nTip\n\n\n\nData sets from these studies would be excellent choices as starting points for your final projects.\n\n\n\n\nHesselberth JR, Chen X, Zhang Z, Sabo PJ, Sandstrom R, Reynolds AP, Thurman RE, Neph S, Kuehn MS, Noble WS, Fields S, Stamatoyannopoulos JA. Global mapping of protein-DNA interactions in vivo by digital genomic footprinting. Nat Methods. 2009 19305407; PMCID: PMC2668528. [Link]\n\n\n\nBuenrostro JD, Giresi PG, Zaba LC, Chang HY, Greenleaf WJ. Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position. Nat Methods. 2013 PMID: 24097267; PMCID: PMC3959825. [Link]\n\n\n\nRamachandran S, Ahmad K, Henikoff S. Transcription and Remodeling Produce Asymmetrically Unwrapped Nucleosomal Intermediates. Mol Cell. 2017 PMID: 29225036; PMCID: PMC6421108. [Link]\n\n\n\nSkene PJ, Henikoff S. An efficient targeted nuclease strategy for high-resolution mapping of DNA binding sites. Elife. 2017 PMID: 28079019; PMCID: PMC5310842. [Link]\nKaya-Okur HS, Wu SJ, Codomo CA, Pledger ES, Bryson TD, Henikoff JG, Ahmad K, Henikoff S. CUT&Tag for efficient epigenomic profiling of small samples and single cells. Nat Commun. 2019 PMID: 31036827; PMCID: PMC6488672. [Link]",
    "crumbs": [
      "Resources",
      "DNA Block resources"
    ]
  },
  {
    "objectID": "resources/block-dna-resources.html#software-well-use-in-class",
    "href": "resources/block-dna-resources.html#software-well-use-in-class",
    "title": "Resources for the DNA block",
    "section": "Software we’ll use in class",
    "text": "Software we’ll use in class\n\nRead over the GViz vignette to understand how we’ll use it to vissualize genome-scale data on a reference sequence.\nRead over the valr vignette to understand how we’ll do BEDtools-like (see below) analysis within RStudio.\nLook over the ComplexHeatmap and EnrichedHeatmap documentation, especially XXX. These tools will help us make “meta-plots”: figures that plot genomic signals relative to features.",
    "crumbs": [
      "Resources",
      "DNA Block resources"
    ]
  },
  {
    "objectID": "resources/block-dna-resources.html#other-important-tools",
    "href": "resources/block-dna-resources.html#other-important-tools",
    "title": "Resources for the DNA block",
    "section": "Other important tools",
    "text": "Other important tools\nThese are other tools I’ll mention in class. We’re not going to use them directly, but they are important tools in upstream data processing and analysis.\n\nAlignment software\nBowtie2 and BWA are popular choices for short read alignment. They are fast, free, and well-maintained.\n\n\nPeak calling\nMACS is the gold-standard in peak calling. It models read coverage as a Poisson process, straightforward identification of regions of higher than expected coverage (i.e., peaks) to be identified using a single parameter (lambda) that captures the mean and variance of read coverage.\n\n\nInterval analysis\n\nBEDtools is the “Swiss Army knife” of genome interval analysis. It provides a host of command-line tools that can be linked together for powerful genome signal manipulation.",
    "crumbs": [
      "Resources",
      "DNA Block resources"
    ]
  },
  {
    "objectID": "resources/block-dna-resources.html#experimental-rigor-in-chromatin-analysis",
    "href": "resources/block-dna-resources.html#experimental-rigor-in-chromatin-analysis",
    "title": "Resources for the DNA block",
    "section": "Experimental rigor in chromatin analysis",
    "text": "Experimental rigor in chromatin analysis\nThese studies identified pervasive artifacts in genomewide chromatin analysis and provide recommendations and solutions to the issues.\nTeytelman L, Thurtle DM, Rine J, van Oudenaarden A. Highly expressed loci are vulnerable to misleading ChIP localization of multiple unrelated proteins. Proc Natl Acad Sci U S A. 2013 Nov 12;110(46):18602-7. doi: 10.1073/pnas.1316064110. Epub 2013 Oct 30. PMID: 24173036; PMCID: PMC3831989.\nShah RN, Grzybowski AT, Cornett EM, Johnstone AL, Dickson BM, Boone BA, Cheek MA, Cowles MW, Maryanski D, Meiners MJ, Tiedemann RL, Vaughan RM, Arora N, Sun ZW, Rothbart SB, Keogh MC, Ruthenburg AJ. Examining the Roles of H3K4 Methylation States with Systematically Characterized Antibodies. Mol Cell. 2018 Oct 4;72(1):162-177.e7. doi: 10.1016/j.molcel.2018.08.015. Epub 2018 Sep 20. PMID: 30244833; PMCID: PMC6173622.",
    "crumbs": [
      "Resources",
      "DNA Block resources"
    ]
  },
  {
    "objectID": "resources/bootcamp-resources.html",
    "href": "resources/bootcamp-resources.html",
    "title": "Bootcamp resources",
    "section": "",
    "text": "Installing R\nInstalling RStudio\n\n\n\n\n\nAdvanced R\nComputational Genomics with R\nR for Data Science (R4DS)\nFundamentals of Data Visualization\n\nQuick reference:\n\nData tidying\nYour labels are too small.. Use cowplot themes to automatically adjust.\n\n\n\n\n\nThe Tidyverse is a collection of libaries implementing a principled approach to data analysis.\nBioconductor is a collection of libraries focused on biological data analysis.\nggplot2\ncowplot\nggthemes\n\n\n\n\nThe tidyverse cheat sheets are indispensible references.\nQuick reference:\n\nRStudio\nRmarkdown\ntidyr\ndplyr\nggplot2\n\n\n\n\n\ngt\ngtExtras\ngt table making contests",
    "crumbs": [
      "Resources",
      "Bootcamp resources"
    ]
  },
  {
    "objectID": "resources/bootcamp-resources.html#r-rstudio",
    "href": "resources/bootcamp-resources.html#r-rstudio",
    "title": "Bootcamp resources",
    "section": "",
    "text": "Installing R\nInstalling RStudio\n\n\n\n\n\nAdvanced R\nComputational Genomics with R\nR for Data Science (R4DS)\nFundamentals of Data Visualization\n\nQuick reference:\n\nData tidying\nYour labels are too small.. Use cowplot themes to automatically adjust.\n\n\n\n\n\nThe Tidyverse is a collection of libaries implementing a principled approach to data analysis.\nBioconductor is a collection of libraries focused on biological data analysis.\nggplot2\ncowplot\nggthemes\n\n\n\n\nThe tidyverse cheat sheets are indispensible references.\nQuick reference:\n\nRStudio\nRmarkdown\ntidyr\ndplyr\nggplot2\n\n\n\n\n\ngt\ngtExtras\ngt table making contests",
    "crumbs": [
      "Resources",
      "Bootcamp resources"
    ]
  },
  {
    "objectID": "resources/bootcamp-resources.html#statistics",
    "href": "resources/bootcamp-resources.html#statistics",
    "title": "Bootcamp resources",
    "section": "Statistics",
    "text": "Statistics\n\nPractical Statistics for Data Scientists covers several fundamental concepts with code for both R and Python.\nModern Statistics for Modern Biology is written by two leading figures in computational biology and contains several examples using Bioconductor.\nStatistics for Biologists is a collection of articles on statistical topic.",
    "crumbs": [
      "Resources",
      "Bootcamp resources"
    ]
  },
  {
    "objectID": "resources/bootcamp-resources.html#miscellaneous",
    "href": "resources/bootcamp-resources.html#miscellaneous",
    "title": "Bootcamp resources",
    "section": "Miscellaneous",
    "text": "Miscellaneous\n\nProject-oriented workflows\nOrganizing projects\nHappy Git with R",
    "crumbs": [
      "Resources",
      "Bootcamp resources"
    ]
  }
]