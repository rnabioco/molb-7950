[
  {
    "objectID": "zzz.html",
    "href": "zzz.html",
    "title": "dummy file so that downlit ends up",
    "section": "",
    "text": "dummy file so that downlit ends up\nin the renv lock file.\n\nlibrary(downlit)\n# library(gitcreds)"
  },
  {
    "objectID": "resources/bootcamp-resources.html",
    "href": "resources/bootcamp-resources.html",
    "title": "Bootcamp resources",
    "section": "",
    "text": "Installing R\nInstalling RStudio\n\n\n\n\n\nAdvanced R\nComputational Genomics with R\nR for Data Science (R4DS)\nFundamentals of Data Visualization\n\nQuick reference:\n\nData tidying\nYour labels are too small.. Use cowplot themes to automatically adjust.\n\n\n\n\n\nThe Tidyverse is a collection of libaries implementing a principled approach to data analysis.\nBioconductor is a collection of libraries focused on biological data analysis.\nggplot2\ncowplot\nggthemes\n\n\n\n\nThe tidyverse cheat sheets are indispensible references.\nQuick reference:\n\nRStudio\nRmarkdown\ntidyr\ndplyr\nggplot2",
    "crumbs": [
      "Resources",
      "Bootcamp resources"
    ]
  },
  {
    "objectID": "resources/bootcamp-resources.html#r-rstudio",
    "href": "resources/bootcamp-resources.html#r-rstudio",
    "title": "Bootcamp resources",
    "section": "",
    "text": "Installing R\nInstalling RStudio\n\n\n\n\n\nAdvanced R\nComputational Genomics with R\nR for Data Science (R4DS)\nFundamentals of Data Visualization\n\nQuick reference:\n\nData tidying\nYour labels are too small.. Use cowplot themes to automatically adjust.\n\n\n\n\n\nThe Tidyverse is a collection of libaries implementing a principled approach to data analysis.\nBioconductor is a collection of libraries focused on biological data analysis.\nggplot2\ncowplot\nggthemes\n\n\n\n\nThe tidyverse cheat sheets are indispensible references.\nQuick reference:\n\nRStudio\nRmarkdown\ntidyr\ndplyr\nggplot2",
    "crumbs": [
      "Resources",
      "Bootcamp resources"
    ]
  },
  {
    "objectID": "resources/bootcamp-resources.html#statistics",
    "href": "resources/bootcamp-resources.html#statistics",
    "title": "Bootcamp resources",
    "section": "Statistics",
    "text": "Statistics\n\nPractical Statistics for Data Scientists covers several fundamental concepts with code for both R and Python.\nModern Statistics for Modern Biology is written by two leading figures in computational biology and contains several examples using Bioconductor.\nStatistics for Biologists is a collection of articles on statistical topic.",
    "crumbs": [
      "Resources",
      "Bootcamp resources"
    ]
  },
  {
    "objectID": "resources/bootcamp-resources.html#miscellaneous",
    "href": "resources/bootcamp-resources.html#miscellaneous",
    "title": "Bootcamp resources",
    "section": "Miscellaneous",
    "text": "Miscellaneous\n\nProject-oriented workflows\nOrganizing projects\nHappy Git with R",
    "crumbs": [
      "Resources",
      "Bootcamp resources"
    ]
  },
  {
    "objectID": "resources/block-dna-resources.html",
    "href": "resources/block-dna-resources.html",
    "title": "Resources for the DNA block",
    "section": "",
    "text": "These studies below laid the methodological groundwork for high throughput chromatin characterization by DNA sequencing. Some of the authors are here at CU Anschutz!\n\n\n\n\n\n\nTip\n\n\n\nData sets from these studies would be excellent choices as starting points for your final projects.\n\n\n\n\nHesselberth JR, Chen X, Zhang Z, Sabo PJ, Sandstrom R, Reynolds AP, Thurman RE, Neph S, Kuehn MS, Noble WS, Fields S, Stamatoyannopoulos JA. Global mapping of protein-DNA interactions in vivo by digital genomic footprinting. Nat Methods. 2009 19305407; PMCID: PMC2668528. [Link]\n\n\n\nBuenrostro JD, Giresi PG, Zaba LC, Chang HY, Greenleaf WJ. Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position. Nat Methods. 2013 PMID: 24097267; PMCID: PMC3959825. [Link]\n\n\n\nRamachandran S, Ahmad K, Henikoff S. Transcription and Remodeling Produce Asymmetrically Unwrapped Nucleosomal Intermediates. Mol Cell. 2017 PMID: 29225036; PMCID: PMC6421108. [Link]\n\n\n\nSkene PJ, Henikoff S. An efficient targeted nuclease strategy for high-resolution mapping of DNA binding sites. Elife. 2017 PMID: 28079019; PMCID: PMC5310842. [Link]\nKaya-Okur HS, Wu SJ, Codomo CA, Pledger ES, Bryson TD, Henikoff JG, Ahmad K, Henikoff S. CUT&Tag for efficient epigenomic profiling of small samples and single cells. Nat Commun. 2019 PMID: 31036827; PMCID: PMC6488672. [Link]",
    "crumbs": [
      "Resources",
      "DNA Block resources"
    ]
  },
  {
    "objectID": "resources/block-dna-resources.html#foundational-work",
    "href": "resources/block-dna-resources.html#foundational-work",
    "title": "Resources for the DNA block",
    "section": "",
    "text": "These studies below laid the methodological groundwork for high throughput chromatin characterization by DNA sequencing. Some of the authors are here at CU Anschutz!\n\n\n\n\n\n\nTip\n\n\n\nData sets from these studies would be excellent choices as starting points for your final projects.\n\n\n\n\nHesselberth JR, Chen X, Zhang Z, Sabo PJ, Sandstrom R, Reynolds AP, Thurman RE, Neph S, Kuehn MS, Noble WS, Fields S, Stamatoyannopoulos JA. Global mapping of protein-DNA interactions in vivo by digital genomic footprinting. Nat Methods. 2009 19305407; PMCID: PMC2668528. [Link]\n\n\n\nBuenrostro JD, Giresi PG, Zaba LC, Chang HY, Greenleaf WJ. Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position. Nat Methods. 2013 PMID: 24097267; PMCID: PMC3959825. [Link]\n\n\n\nRamachandran S, Ahmad K, Henikoff S. Transcription and Remodeling Produce Asymmetrically Unwrapped Nucleosomal Intermediates. Mol Cell. 2017 PMID: 29225036; PMCID: PMC6421108. [Link]\n\n\n\nSkene PJ, Henikoff S. An efficient targeted nuclease strategy for high-resolution mapping of DNA binding sites. Elife. 2017 PMID: 28079019; PMCID: PMC5310842. [Link]\nKaya-Okur HS, Wu SJ, Codomo CA, Pledger ES, Bryson TD, Henikoff JG, Ahmad K, Henikoff S. CUT&Tag for efficient epigenomic profiling of small samples and single cells. Nat Commun. 2019 PMID: 31036827; PMCID: PMC6488672. [Link]",
    "crumbs": [
      "Resources",
      "DNA Block resources"
    ]
  },
  {
    "objectID": "resources/block-dna-resources.html#software-well-use-in-class",
    "href": "resources/block-dna-resources.html#software-well-use-in-class",
    "title": "Resources for the DNA block",
    "section": "Software we’ll use in class",
    "text": "Software we’ll use in class\n\nRead over the GViz vignette to understand how we’ll use it to vissualize genome-scale data on a reference sequence.\nRead over the valr vignette to understand how we’ll do BEDtools-like (see below) analysis within RStudio.\nLook over the ComplexHeatmap and EnrichedHeatmap documentation, especially XXX. These tools will help us make “meta-plots”: figures that plot genomic signals relative to features.",
    "crumbs": [
      "Resources",
      "DNA Block resources"
    ]
  },
  {
    "objectID": "resources/block-dna-resources.html#other-important-tools",
    "href": "resources/block-dna-resources.html#other-important-tools",
    "title": "Resources for the DNA block",
    "section": "Other important tools",
    "text": "Other important tools\nThese are other tools I’ll mention in class. We’re not going to use them directly, but they are important tools in upstream data processing and analysis.\n\nAlignment software\nBowtie2 and BWA are popular choices for short read alignment. They are fast, free, and well-maintained.\n\n\nPeak calling\nMACS is the gold-standard in peak calling. It models read coverage as a Poisson process, straightforward identification of regions of higher than expected coverage (i.e., peaks) to be identified using a single parameter (lambda) that captures the mean and variance of read coverage.\n\n\nInterval analysis\n\nBEDtools is the “Swiss Army knife” of genome interval analysis. It provides a host of command-line tools that can be linked together for powerful genome signal manipulation.",
    "crumbs": [
      "Resources",
      "DNA Block resources"
    ]
  },
  {
    "objectID": "resources/block-dna-resources.html#experimental-rigor-in-chromatin-analysis",
    "href": "resources/block-dna-resources.html#experimental-rigor-in-chromatin-analysis",
    "title": "Resources for the DNA block",
    "section": "Experimental rigor in chromatin analysis",
    "text": "Experimental rigor in chromatin analysis\nThese studies identified pervasive artifacts in genomewide chromatin analysis and provide recommendations and solutions to the issues.\nTeytelman L, Thurtle DM, Rine J, van Oudenaarden A. Highly expressed loci are vulnerable to misleading ChIP localization of multiple unrelated proteins. Proc Natl Acad Sci U S A. 2013 Nov 12;110(46):18602-7. doi: 10.1073/pnas.1316064110. Epub 2013 Oct 30. PMID: 24173036; PMCID: PMC3831989.\nShah RN, Grzybowski AT, Cornett EM, Johnstone AL, Dickson BM, Boone BA, Cheek MA, Cowles MW, Maryanski D, Meiners MJ, Tiedemann RL, Vaughan RM, Arora N, Sun ZW, Rothbart SB, Keogh MC, Ruthenburg AJ. Examining the Roles of H3K4 Methylation States with Systematically Characterized Antibodies. Mol Cell. 2018 Oct 4;72(1):162-177.e7. doi: 10.1016/j.molcel.2018.08.015. Epub 2018 Sep 20. PMID: 30244833; PMCID: PMC6173622.",
    "crumbs": [
      "Resources",
      "DNA Block resources"
    ]
  },
  {
    "objectID": "problem-sets/ps-01.html",
    "href": "problem-sets/ps-01.html",
    "title": "Problem Set 1 Key",
    "section": "",
    "text": "Each problem below is worth 5 points.\nThe problem set is due 12pm on Aug 26.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-sets/ps-01.html#problem-set",
    "href": "problem-sets/ps-01.html#problem-set",
    "title": "Problem Set 1 Key",
    "section": "",
    "text": "Each problem below is worth 5 points.\nThe problem set is due 12pm on Aug 26.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-sets/ps-01.html#setup",
    "href": "problem-sets/ps-01.html#setup",
    "title": "Problem Set 1 Key",
    "section": "Setup",
    "text": "Setup\nStart by loading libraries you need analysis below. When in doubt, start by loading the tidyverse package.\n\nlibrary(___)"
  },
  {
    "objectID": "problem-sets/ps-01.html#question-1",
    "href": "problem-sets/ps-01.html#question-1",
    "title": "Problem Set 1 Key",
    "section": "Question 1",
    "text": "Question 1\nCreate 3 different vectors called x, y, and z:\n\n\nx should be character vector of length 5 (hint: use LETTERS or letters)\n\ny should be a numeric vector of length 5 (hint: try 1:5 or c(1, 2, 3, 4, 5))\n\nz should be a logical vector of length 5 (hint: use TRUE and FALSE values)\n\nUse length() to calculate the length of each vector."
  },
  {
    "objectID": "problem-sets/ps-01.html#question-2",
    "href": "problem-sets/ps-01.html#question-2",
    "title": "Problem Set 1 Key",
    "section": "Question 2",
    "text": "Question 2\nUsing the vectors you created above, create a new tibble with column names x, y, and z. Use the tibble() function to combine your vectors into a data frame.\nUse nrow() and ncol() to calculate the number of rows and columns, both with and without the pipe operator.\nUse glimpse() to get a quick overview of your tibble - this shows data types and first few values.\nWhat do you notice about the length of the vectors and the number of rows?\n\ntbl &lt;- tibble(___)\n\nnrow(___)\nncol(___)\n\n# Get a quick overview\nglimpse(___)\n\nAnswer\nThe length of the vectors and the number of rows are the same, because tibble columns are simply the vectors we started with."
  },
  {
    "objectID": "problem-sets/ps-01.html#question-3",
    "href": "problem-sets/ps-01.html#question-3",
    "title": "Problem Set 1 Key",
    "section": "Question 3",
    "text": "Question 3\nLet’s explore the penguins dataset that we loaded.\n\nLook at the number of rows with nrow() - this tells us how many penguins are in the dataset\nLook at the number of columns with ncol() - this tells us how many variables we measured\nLook at the column names with names() - this shows us what variables we have\nGet a glimpse of the data with glimpse() - this shows data types and sample values\n\n\n# Explore the penguins dataset\nnrow(___)\nncol(___)\nnames(___)\nglimpse(___)"
  },
  {
    "objectID": "problem-sets/ps-01.html#question-4",
    "href": "problem-sets/ps-01.html#question-4",
    "title": "Problem Set 1 Key",
    "section": "Question 4",
    "text": "Question 4\nNext we will think about data tidying. Let’s start by analyzing the penguins dataset.\nPart A: Is the penguins dataset tidy? To determine this, we need to think about the three principles of tidy data:\n\nEach variable forms a column\nEach observation forms a row\nEach type of observational unit forms a table\n\nLook at the penguins dataset and answer:\n\nWhat are the variables in the dataset? (Hint: use names(penguins) to see them)\nDoes each column represent a single variable?\nDoes each row represent a single penguin observation?\n\nPart B: Now let’s examine some datasets that are NOT tidy. Use data() to see available datasets, then look at these two examples:\nExample 1: anscombe - This is a classic statistics dataset.\n\n# Look at the anscombe dataset. Start by reading the help page with `?anscombe`\n\nIs anscombe tidy? Think about:\n\nWhat are the actual variables? (Hint: x and y coordinates for different datasets)\nHow many different datasets are encoded in the column names?\nWhat would a tidy version look like?\n\nExample 2: Choose another dataset - Pick one more dataset from data() and analyze whether it’s tidy:\n\n# Look at available datasets\ndata()\n\nIs this other data set tidy? Think about:\n\nWhat are the actual variables? (Hint: x and y coordinates for different datasets)\nHow many different datasets are encoded in the column names?\nWhat would a tidy version look like?\n\nPart C: Write a brief explanation (2-3 sentences) for each dataset about:\n\nWhether it’s tidy or not\nWhat makes it tidy/untidy\nWhat the variables actually represent\n\nYour Analysis:\npenguins: [Your answer here]\nanscombe: [Your answer here]\n[Your chosen dataset]: [Your answer here]"
  },
  {
    "objectID": "problem-sets/ps-01.html#submit",
    "href": "problem-sets/ps-01.html#submit",
    "title": "Problem Set 1 Key",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of the Posit Cloud project (NOT the HTML link) into the problem set on Canvas."
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html",
    "href": "problem-set-keys/ps-key-01.html",
    "title": "Problem Set 1 Key",
    "section": "",
    "text": "Each problem below is worth 8 points.\nThe problem set is due 12pm on Aug 30.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#problem-set",
    "href": "problem-set-keys/ps-key-01.html#problem-set",
    "title": "Problem Set 1 Key",
    "section": "",
    "text": "Each problem below is worth 8 points.\nThe problem set is due 12pm on Aug 30.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#setup",
    "href": "problem-set-keys/ps-key-01.html#setup",
    "title": "Problem Set 1 Key",
    "section": "Setup",
    "text": "Setup\nStart by loading libraries you need analysis below. When in doubt, start by loading the tidyverse package.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#question-1",
    "href": "problem-set-keys/ps-key-01.html#question-1",
    "title": "Problem Set 1 Key",
    "section": "Question 1",
    "text": "Question 1\nCreate 3 different vectors called x, y, and z:\n\n\nx should be character vector of length 5 (hint: use LETTERS or letters)\n\ny should be a numeric vector of length 5 (hint: try 1:5 or c(1, 2, 3, 4, 5))\n\nz should be a logical vector of length 5 (hint: use TRUE and FALSE values)\n\nUse length() to calculate the length of each vector.\n\nx &lt;- LETTERS[1:5]\ny &lt;- 1:5\nz &lt;- c(TRUE, TRUE, FALSE, FALSE, FALSE)\n\nx\n\n[1] \"A\" \"B\" \"C\" \"D\" \"E\"\n\ny\n\n[1] 1 2 3 4 5\n\nz\n\n[1]  TRUE  TRUE FALSE FALSE FALSE\n\n# Traditional way\nlength(x)\n\n[1] 5\n\nlength(y)\n\n[1] 5\n\nlength(z)\n\n[1] 5"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#question-2",
    "href": "problem-set-keys/ps-key-01.html#question-2",
    "title": "Problem Set 1 Key",
    "section": "Question 2",
    "text": "Question 2\nUsing the vectors you created above, create a new tibble with column names x, y, and z. Use the tibble() function to combine your vectors into a data frame.\nUse nrow() and ncol() to calculate the number of rows and columns, both with and without the pipe operator.\nUse glimpse() to get a quick overview of your tibble - this shows data types and first few values.\nWhat do you notice about the length of the vectors and the number of rows?\n\ntbl &lt;- tibble(x = x, y = y, z = z)\n\n# Traditional way\nnrow(tbl)\n\n[1] 5\n\nncol(tbl)\n\n[1] 3\n\n# Get a quick overview\nglimpse(tbl)\n\nRows: 5\nColumns: 3\n$ x &lt;chr&gt; \"A\", \"B\", \"C\", \"D\", \"E\"\n$ y &lt;int&gt; 1, 2, 3, 4, 5\n$ z &lt;lgl&gt; TRUE, TRUE, FALSE, FALSE, FALSE\n\n\nAnswer\nThe length of the vectors and the number of rows are the same, because tibble columns are simply the vectors we started with."
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#question-3",
    "href": "problem-set-keys/ps-key-01.html#question-3",
    "title": "Problem Set 1 Key",
    "section": "Question 3",
    "text": "Question 3\nLet’s explore the penguins dataset that we loaded.\n\nLook at the number of rows with nrow() - this tells us how many penguins are in the dataset\nLook at the number of columns with ncol() - this tells us how many variables we measured\nLook at the column names with names() - this shows us what variables we have\nGet a glimpse of the data with glimpse() - this shows data types and sample values\n\n\n# Explore the penguins dataset\nnrow(penguins)\n\n[1] 344\n\nncol(penguins)\n\n[1] 8\n\nnames(penguins)\n\n[1] \"species\"     \"island\"      \"bill_len\"    \"bill_dep\"    \"flipper_len\"\n[6] \"body_mass\"   \"sex\"         \"year\"       \n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species     &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Ad…\n$ island      &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgersen, Tor…\n$ bill_len    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, 42.0, …\n$ bill_dep    &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, 20.2, …\n$ flipper_len &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186, 180,…\n$ body_mass   &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, 4250, …\n$ sex         &lt;fct&gt; male, female, female, NA, female, male, female, male, NA, …\n$ year        &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#question-4",
    "href": "problem-set-keys/ps-key-01.html#question-4",
    "title": "Problem Set 1 Key",
    "section": "Question 4",
    "text": "Question 4\nNext we will think about data tidying. Let’s start by analyzing the penguins dataset.\nPart A: Is the penguins dataset tidy? To determine this, we need to think about the three principles of tidy data:\n\nEach variable forms a column\nEach observation forms a row\nEach type of observational unit forms a table\n\nLook at the penguins dataset and answer:\n\nWhat are the variables in the dataset? (Hint: use names(penguins) to see them)\nDoes each column represent a single variable?\nDoes each row represent a single penguin observation?\n\n\n# Look at the structure of penguins\npenguins |&gt; glimpse()\n\nRows: 344\nColumns: 8\n$ species     &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Ad…\n$ island      &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgersen, Tor…\n$ bill_len    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, 42.0, …\n$ bill_dep    &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, 20.2, …\n$ flipper_len &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186, 180,…\n$ body_mass   &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, 4250, …\n$ sex         &lt;fct&gt; male, female, female, NA, female, male, female, male, NA, …\n$ year        &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n# What are the variables?\nnames(penguins)\n\n[1] \"species\"     \"island\"      \"bill_len\"    \"bill_dep\"    \"flipper_len\"\n[6] \"body_mass\"   \"sex\"         \"year\"       \n\n# Look at a few rows\npenguins |&gt; head()\n\n  species    island bill_len bill_dep flipper_len body_mass    sex year\n1  Adelie Torgersen     39.1     18.7         181      3750   male 2007\n2  Adelie Torgersen     39.5     17.4         186      3800 female 2007\n3  Adelie Torgersen     40.3     18.0         195      3250 female 2007\n4  Adelie Torgersen       NA       NA          NA        NA   &lt;NA&gt; 2007\n5  Adelie Torgersen     36.7     19.3         193      3450 female 2007\n6  Adelie Torgersen     39.3     20.6         190      3650   male 2007\n\n\nAnswer: Yes, the penguins dataset is tidy because:\n\nEach column represents one variable (species, island, bill_length_mm, etc.)\nEach row represents one penguin observation\nAll observations are of the same type (penguin measurements)\n\nPart B: Now let’s examine some datasets that are NOT tidy. Use data() to see available datasets, then look at these two examples:\nExample 1: anscombe - This is a classic statistics dataset:\n\n# Look at the anscombe dataset\nanscombe\n\n   x1 x2 x3 x4    y1   y2    y3    y4\n1  10 10 10  8  8.04 9.14  7.46  6.58\n2   8  8  8  8  6.95 8.14  6.77  5.76\n3  13 13 13  8  7.58 8.74 12.74  7.71\n4   9  9  9  8  8.81 8.77  7.11  8.84\n5  11 11 11  8  8.33 9.26  7.81  8.47\n6  14 14 14  8  9.96 8.10  8.84  7.04\n7   6  6  6  8  7.24 6.13  6.08  5.25\n8   4  4  4 19  4.26 3.10  5.39 12.50\n9  12 12 12  8 10.84 9.13  8.15  5.56\n10  7  7  7  8  4.82 7.26  6.42  7.91\n11  5  5  5  8  5.68 4.74  5.73  6.89\n\nglimpse(anscombe)\n\nRows: 11\nColumns: 8\n$ x1 &lt;dbl&gt; 10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5\n$ x2 &lt;dbl&gt; 10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5\n$ x3 &lt;dbl&gt; 10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5\n$ x4 &lt;dbl&gt; 8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8\n$ y1 &lt;dbl&gt; 8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68\n$ y2 &lt;dbl&gt; 9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74\n$ y3 &lt;dbl&gt; 7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73\n$ y4 &lt;dbl&gt; 6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89\n\n\nIs anscombe tidy? Think about: - What are the actual variables? (Hint: x and y coordinates for different datasets) - How many different datasets are encoded in the column names? - What would a tidy version look like?\nExample 2: Choose another dataset - Pick one more dataset from data() and analyze whether it’s tidy:\n\n# Look at available datasets\ndata()\n\n# Choose one and examine it (examples: WorldPhones, UCBAdmissions, HairEyeColor)\n# Let's try WorldPhones as an example\nWorldPhones\n\n     N.Amer Europe Asia S.Amer Oceania Africa Mid.Amer\n1951  45939  21574 2876   1815    1646     89      555\n1956  60423  29990 4708   2568    2366   1411      733\n1957  64721  32510 5230   2695    2526   1546      773\n1958  68484  35218 6662   2845    2691   1663      836\n1959  71799  37598 6856   3000    2868   1769      911\n1960  76036  40341 8220   3145    3054   1905     1008\n1961  79831  43173 9053   3338    3224   2005     1076\n\n\n`\nPart C: Write a brief explanation (2-3 sentences) for each dataset about: 1. Whether it’s tidy or not 2. What makes it tidy/untidy 3. What the variables actually represent\nYour Analysis:\npenguins: The penguins dataset is tidy because each column represents a single variable (species, island, bill measurements, etc.), each row represents one penguin observation, and all data is the same type of observational unit (individual penguin measurements). The variables are clearly defined and there’s no mixing of different types of information in single columns.\nanscombe: The anscombe dataset is NOT tidy because it violates multiple tidy data principles. The actual variables are x-coordinates, y-coordinates, and dataset identifier, but the dataset identifier is encoded in the column names (x1, y1, x2, y2, etc.). Four different datasets are stored in one table, with each dataset’s x and y values spread across separate columns rather than being in rows with a dataset identifier column.\nWorldPhones: The WorldPhones dataset is NOT tidy because it has years as row names instead of a proper column, and regions are spread across columns rather than being values in a “region” variable. The actual variables should be year, region, and number of phones, but currently the year and region information is stored in the structure of the table rather than as data values. A tidy version would have one row per year-region combination."
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#submit",
    "href": "problem-set-keys/ps-key-01.html#submit",
    "title": "Problem Set 1 Key",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of the Posit Cloud project (NOT the HTML link) into the problem set on Canvas."
  },
  {
    "objectID": "prepare/prepare-03.html",
    "href": "prepare/prepare-03.html",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look over the dplyr cheatsheet.\nWe’ll be using the filter(), select(), mutate(), arrange(), group_by(), and summarise() functions. Pay special attention to the comparison operators and logical operators sections, as well as case_when() for conditional logic."
  },
  {
    "objectID": "prepare/prepare-03.html#prepare",
    "href": "prepare/prepare-03.html#prepare",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look over the dplyr cheatsheet.\nWe’ll be using the filter(), select(), mutate(), arrange(), group_by(), and summarise() functions. Pay special attention to the comparison operators and logical operators sections, as well as case_when() for conditional logic."
  },
  {
    "objectID": "prepare/prepare-01.html",
    "href": "prepare/prepare-01.html",
    "title": "R Bootcamp",
    "section": "",
    "text": "Important\n\n\n\nBefore class begins, login with your CU credentials at Posit Cloud: https://sso.posit.cloud/cu-anschutz"
  },
  {
    "objectID": "prepare/prepare-01.html#prepare",
    "href": "prepare/prepare-01.html#prepare",
    "title": "R Bootcamp",
    "section": "Prepare",
    "text": "Prepare\n📖 Read the syllabus\n📖 Read the support resources\n📖 Look over the RStudio cheatsheet"
  },
  {
    "objectID": "exercises/ex-05.html",
    "href": "exercises/ex-05.html",
    "title": "R Bootcamp - Day 5",
    "section": "",
    "text": "Introduce ggplot2 & today’s data sets (Exercise 1)\nUnderstand the basics of ggplot2 (Exercise 2, 3)\nGeom functions (Exercise 4-8)\nGeom_point properties (Exercise 9)\nPosition adjustments (Exercise 10)\nCoordinate and Scale Functions (Exercise 11)\nZooming into a plot (Exercise 12)\n\n\n\nFaceting (Exercise 13)\nThemes (Exercise 14)\nLabels & Legends (Exercise 15)\nAdding lines to plots (Exercise 16)\nMaking multi-panel figures (Exercise 17)\nSaving a plot (Exercise 18)"
  },
  {
    "objectID": "exercises/ex-05.html#class-4-5-outline",
    "href": "exercises/ex-05.html#class-4-5-outline",
    "title": "R Bootcamp - Day 5",
    "section": "",
    "text": "Introduce ggplot2 & today’s data sets (Exercise 1)\nUnderstand the basics of ggplot2 (Exercise 2, 3)\nGeom functions (Exercise 4-8)\nGeom_point properties (Exercise 9)\nPosition adjustments (Exercise 10)\nCoordinate and Scale Functions (Exercise 11)\nZooming into a plot (Exercise 12)\n\n\n\nFaceting (Exercise 13)\nThemes (Exercise 14)\nLabels & Legends (Exercise 15)\nAdding lines to plots (Exercise 16)\nMaking multi-panel figures (Exercise 17)\nSaving a plot (Exercise 18)"
  },
  {
    "objectID": "exercises/ex-05.html#shape-size-fill-color-and-transparency---exercise-9",
    "href": "exercises/ex-05.html#shape-size-fill-color-and-transparency---exercise-9",
    "title": "R Bootcamp - Day 5",
    "section": "shape, size, fill, color, and transparency - Exercise 9",
    "text": "shape, size, fill, color, and transparency - Exercise 9\nGet a diamonds subset.\nNote that aesthetics can also be defined within a geom.\nThis is useful if you use two different geoms that share an aesthetic."
  },
  {
    "objectID": "exercises/ex-05.html#position-adjustments---exercise-10",
    "href": "exercises/ex-05.html#position-adjustments---exercise-10",
    "title": "R Bootcamp - Day 5",
    "section": "Position adjustments - Exercise 10",
    "text": "Position adjustments - Exercise 10\nA stacked bar chart.\nDodged bars are easier to read (proportions are clearer)"
  },
  {
    "objectID": "exercises/ex-05.html#coordinate-and-scale-functions---exercise-11",
    "href": "exercises/ex-05.html#coordinate-and-scale-functions---exercise-11",
    "title": "R Bootcamp - Day 5",
    "section": "Coordinate and Scale Functions - Exercise 11",
    "text": "Coordinate and Scale Functions - Exercise 11\nLogarithmic axes - 1\nNote the difference between axis labels in these two examples.\n\nLogarithmic axes - 2\n\nFlipping coordinate system (swapping x and y)\n\nNow flip the axis.\nBrief aside: ggplot can handle on-the-fly data transformations.\nHere we log-transform carat and convert USD to CAD."
  },
  {
    "objectID": "exercises/ex-05.html#zooming-into-a-plot---exercise-12",
    "href": "exercises/ex-05.html#zooming-into-a-plot---exercise-12",
    "title": "R Bootcamp - Day 5",
    "section": "Zooming into a plot - Exercise 12",
    "text": "Zooming into a plot - Exercise 12\nWe might want to change the limits of x or y axes to zoom in."
  },
  {
    "objectID": "exercises/ex-05.html#faceting-to-plot-subsets-of-data-into-separate-panels---exercise-13",
    "href": "exercises/ex-05.html#faceting-to-plot-subsets-of-data-into-separate-panels---exercise-13",
    "title": "R Bootcamp - Day 5",
    "section": "Faceting to plot subsets of data into separate panels - Exercise 13",
    "text": "Faceting to plot subsets of data into separate panels - Exercise 13\nA density plot we’ve seen before.\nWhich variables can we use to subdivide the data?\n\nFaceted by cut\nLet’s also use facet_grid() to facet by two variables.\nFaceted by clarity and cut.\n\nScatter plot with facets."
  },
  {
    "objectID": "exercises/ex-05.html#themes---exercise-14",
    "href": "exercises/ex-05.html#themes---exercise-14",
    "title": "R Bootcamp - Day 5",
    "section": "Themes - Exercise 14",
    "text": "Themes - Exercise 14\nScatter plot with default theme.\nChange the theme with theme_bw().\nMy go-to is cowplot::theme_cowplot().\nIt implements much of the advice in the “Dataviz” book, i.e.. YOUR LABELS ARE TOO SMALL.\nWe’re not going to cover it, but you can also customize pre-existing themes."
  },
  {
    "objectID": "exercises/ex-05.html#labels-legends---exercise-15",
    "href": "exercises/ex-05.html#labels-legends---exercise-15",
    "title": "R Bootcamp - Day 5",
    "section": "Labels & Legends - Exercise 15",
    "text": "Labels & Legends - Exercise 15\nUse labs() to add / change plot labels."
  },
  {
    "objectID": "exercises/ex-05.html#how-to-add-a-line-to-a-plot-exercise-16",
    "href": "exercises/ex-05.html#how-to-add-a-line-to-a-plot-exercise-16",
    "title": "R Bootcamp - Day 5",
    "section": "How to add a line to a plot? (Exercise 16)",
    "text": "How to add a line to a plot? (Exercise 16)\n\nAlso try:"
  },
  {
    "objectID": "exercises/ex-05.html#how-to-combine-multiple-plots-into-a-figure-exercise-17",
    "href": "exercises/ex-05.html#how-to-combine-multiple-plots-into-a-figure-exercise-17",
    "title": "R Bootcamp - Day 5",
    "section": "How to combine multiple plots into a figure? (Exercise 17)",
    "text": "How to combine multiple plots into a figure? (Exercise 17)\nWe have 4 legends - can they be condensed?\nYes, but it is not exactly straightforward.\nneed to scroll below"
  },
  {
    "objectID": "exercises/ex-05.html#saving-plots-exercise-18",
    "href": "exercises/ex-05.html#saving-plots-exercise-18",
    "title": "R Bootcamp - Day 5",
    "section": "Saving plots (Exercise 18)",
    "text": "Saving plots (Exercise 18)\nSaves last plot as 5’ x 5’ file named “plot_final.png” in working directory.\nMatches file type to file extension."
  },
  {
    "objectID": "exercises/ex-03.html",
    "href": "exercises/ex-03.html",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "",
    "text": "Explore these data sets:\n\ndplyr::starwars\n\ndplyr::band_members, dplyr::band_instruments, dplyr::band_instruments2"
  },
  {
    "objectID": "exercises/ex-03.html#todays-datasets---exercise-1",
    "href": "exercises/ex-03.html#todays-datasets---exercise-1",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "",
    "text": "Explore these data sets:\n\ndplyr::starwars\n\ndplyr::band_members, dplyr::band_instruments, dplyr::band_instruments2"
  },
  {
    "objectID": "exercises/ex-03.html#arrange---exercise-2",
    "href": "exercises/ex-03.html#arrange---exercise-2",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "arrange - Exercise 2",
    "text": "arrange - Exercise 2"
  },
  {
    "objectID": "exercises/ex-03.html#filter---exercise-3",
    "href": "exercises/ex-03.html#filter---exercise-3",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "filter - Exercise 3",
    "text": "filter - Exercise 3\nfilter by membership\n\n# filter based on skin color\n\nConditions can be combined using & (and), | (or).\n\n# filter on skin and eye color\n\nselect - Exercise 4\nmutate (& pipe |&gt;)- Exercise 5\n\n# create a new column to display height in meters\n\n# using the pipe to feed data into multiple functions sequentially\n\n# mutate allows you to refer to columns that you’ve just created\n\n# output needs to be saved into a new dataframe since dplyr does not \"change\" the original dataframe\n\n# using if_else clauses with mutate"
  },
  {
    "objectID": "exercises/ex-03.html#case_when---exercise-6",
    "href": "exercises/ex-03.html#case_when---exercise-6",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "case_when - Exercise 6",
    "text": "case_when - Exercise 6\n\n# create categories based on height\n\n\n# multiple conditions with case_when\n\nsummarise - Exercise 7\ngroup_by + summarize - Exercise 8\n\n# multiple grouping variables"
  },
  {
    "objectID": "exercises/ex-03.html#across---exercise-9",
    "href": "exercises/ex-03.html#across---exercise-9",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "across - Exercise 9",
    "text": "across - Exercise 9\n\n# apply mean to multiple columns\n\n\n# apply multiple functions with list()\n\n\n# combine across() with group_by()"
  },
  {
    "objectID": "exercises/ex-01.html",
    "href": "exercises/ex-01.html",
    "title": "R Bootcamp - Day 1",
    "section": "",
    "text": "We are using RStudio through Posit Cloud for the class.\nLook at RStudio panels one at a time.\nEnvironment, History, Console, Files, Plots, Packages, Help, etc.\n\nSee menu:\nHelp &gt; Cheat Sheets &gt; RStudio IDE Cheat Sheet"
  },
  {
    "objectID": "exercises/ex-01.html#rstudio---exercise-1",
    "href": "exercises/ex-01.html#rstudio---exercise-1",
    "title": "R Bootcamp - Day 1",
    "section": "",
    "text": "We are using RStudio through Posit Cloud for the class.\nLook at RStudio panels one at a time.\nEnvironment, History, Console, Files, Plots, Packages, Help, etc.\n\nSee menu:\nHelp &gt; Cheat Sheets &gt; RStudio IDE Cheat Sheet"
  },
  {
    "objectID": "exercises/ex-01.html#r-as-a-calculator---exercise-2",
    "href": "exercises/ex-01.html#r-as-a-calculator---exercise-2",
    "title": "R Bootcamp - Day 1",
    "section": "R as a calculator - Exercise 2",
    "text": "R as a calculator - Exercise 2\n\nR can function like an advanced calculator\n\n\nTry simple math.\nAssign a numeric value to an object.\n\n\n&lt;- and = are assignment operators.\nBy convention, R programmers use &lt;-.\n\nx &lt;- 1 reads “set the value of x to 1”.\n\n. . .\n= and == are two different operators.\n\na = is used for assignment (e.g., x = 1)\na == tests for equivalence (e.g. x == 1 says “does x equal 1?”)"
  },
  {
    "objectID": "exercises/ex-01.html#functions-and-arguments---exercise-3",
    "href": "exercises/ex-01.html#functions-and-arguments---exercise-3",
    "title": "R Bootcamp - Day 1",
    "section": "Functions and arguments - Exercise 3",
    "text": "Functions and arguments - Exercise 3"
  },
  {
    "objectID": "exercises/ex-01.html#writing-a-simple-function---exercise-4",
    "href": "exercises/ex-01.html#writing-a-simple-function---exercise-4",
    "title": "R Bootcamp - Day 1",
    "section": "Writing a simple function - Exercise 4",
    "text": "Writing a simple function - Exercise 4"
  },
  {
    "objectID": "exercises/ex-01.html#data-types---exercise-5",
    "href": "exercises/ex-01.html#data-types---exercise-5",
    "title": "R Bootcamp - Day 1",
    "section": "Data types - Exercise 5",
    "text": "Data types - Exercise 5\n\nThere are many data types in R.\nWe’ll mainly use numeric, character, and logical."
  },
  {
    "objectID": "exercises/ex-01.html#vectors---exercise-6",
    "href": "exercises/ex-01.html#vectors---exercise-6",
    "title": "R Bootcamp - Day 1",
    "section": "Vectors - Exercise 6",
    "text": "Vectors - Exercise 6\nLet’s create some vectors.\n\nThe c function combines values together (e.g., c(1,2,3))\n\n. . ."
  },
  {
    "objectID": "exercises/ex-01.html#data-frames",
    "href": "exercises/ex-01.html#data-frames",
    "title": "R Bootcamp - Day 1",
    "section": "Data frames",
    "text": "Data frames\n\nA data.frame is a rectangle, where each column is a vector, and each row is a slice across vectors.\ndata.frame columns are vectors, and can have different types (numeric, character, factor, etc.).\nA data.frame is constructed with data.frame()."
  },
  {
    "objectID": "exercises/ex-01.html#data-frames-tibbles---exercise-7",
    "href": "exercises/ex-01.html#data-frames-tibbles---exercise-7",
    "title": "R Bootcamp - Day 1",
    "section": "Data frames & tibbles - Exercise 7",
    "text": "Data frames & tibbles - Exercise 7\nCreate a data.frame and tibble.\nNow echo the contents of df and tbl to the console and inspect"
  },
  {
    "objectID": "exercises/ex-01.html#r-packages---exercise-8",
    "href": "exercises/ex-01.html#r-packages---exercise-8",
    "title": "R Bootcamp - Day 1",
    "section": "R packages - Exercise 8",
    "text": "R packages - Exercise 8\nLet’s do the following to explore R packages:\n\nLook at the “Environment” panel in Rstudio\nExplore Global Environment\nExplore the contents of a package"
  },
  {
    "objectID": "exercises/ex-01.html#quarto-exercise---exercise-9",
    "href": "exercises/ex-01.html#quarto-exercise---exercise-9",
    "title": "R Bootcamp - Day 1",
    "section": "Quarto Exercise - Exercise 9",
    "text": "Quarto Exercise - Exercise 9\nLet’s do the following to explore Quarto documents:\n\nCreate a new Quarto document\nRender the document to see the output"
  },
  {
    "objectID": "exercises/ex-01.html#problem-sets-and-submission",
    "href": "exercises/ex-01.html#problem-sets-and-submission",
    "title": "R Bootcamp - Day 1",
    "section": "Problem sets and submission",
    "text": "Problem sets and submission\nYour first problem set is in problem-sets/ps-01.qmd"
  },
  {
    "objectID": "course-info/syllabus.html",
    "href": "course-info/syllabus.html",
    "title": "MOLB 7950 Syllabus",
    "section": "",
    "text": "MOLB 7950 is a hands-on tutorial of skills and theory needed to process, analyze, and visualize output from large biological data sets. We emphasize the R statistical computing environment.\n🗓️ Class will run from Aug 26 - Oct 29\n📍 Classes will be held in-person at locations found on the schedule page.\n🕘 Class time is 9:00-10:30am\nMOLB 7950 is a three credit hour course.\nThe course is divided into blocks:\n\n\nTHe Bootcamp block covers R programming and introduces important statistical concepts and approaches. We will also cover data types you will encounter during biological data analysis and approaches for their analysis.\nDuring the bootcamp block, we will meet everyday for 90 minutes to cover fundamental concepts you will need throughout the course.\n\n\n\nAfter Bootcamp, will cover experimental approaches used to analyze DNA and RNA. Each block spans ~4 weeks, with each week focused on a particular type of experiment (see below). Each block covers statistical concepts needed for rigorous analysis and analysis approaches to process raw data to results (tables and figures) using reproducible coding techniques.\nIn most weeks we will discuss and analyze data from a publication. You are responsible for reading the week’s material before class begins on Monday.\n\n\n\nThe DNA block covers genome sequencing for identifying mutations, and two approaches for analyzing chromatin state (ChIP-seq and MNase-seq).\nThe RNA block covers RNA-seq, alternative splicing, differential gene expression, and RNA:protein interactions.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#course-overview",
    "href": "course-info/syllabus.html#course-overview",
    "title": "MOLB 7950 Syllabus",
    "section": "",
    "text": "MOLB 7950 is a hands-on tutorial of skills and theory needed to process, analyze, and visualize output from large biological data sets. We emphasize the R statistical computing environment.\n🗓️ Class will run from Aug 26 - Oct 29\n📍 Classes will be held in-person at locations found on the schedule page.\n🕘 Class time is 9:00-10:30am\nMOLB 7950 is a three credit hour course.\nThe course is divided into blocks:\n\n\nTHe Bootcamp block covers R programming and introduces important statistical concepts and approaches. We will also cover data types you will encounter during biological data analysis and approaches for their analysis.\nDuring the bootcamp block, we will meet everyday for 90 minutes to cover fundamental concepts you will need throughout the course.\n\n\n\nAfter Bootcamp, will cover experimental approaches used to analyze DNA and RNA. Each block spans ~4 weeks, with each week focused on a particular type of experiment (see below). Each block covers statistical concepts needed for rigorous analysis and analysis approaches to process raw data to results (tables and figures) using reproducible coding techniques.\nIn most weeks we will discuss and analyze data from a publication. You are responsible for reading the week’s material before class begins on Monday.\n\n\n\nThe DNA block covers genome sequencing for identifying mutations, and two approaches for analyzing chromatin state (ChIP-seq and MNase-seq).\nThe RNA block covers RNA-seq, alternative splicing, differential gene expression, and RNA:protein interactions.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#schedule",
    "href": "course-info/syllabus.html#schedule",
    "title": "MOLB 7950 Syllabus",
    "section": "Schedule",
    "text": "Schedule\nClasses begin on August 26 and end on October 29. Dates are from the Fall 2025 Academic Calendar.\nDuring the Bootcamp block, classes will be held every day, Mon-Fri from 9:00-10:30am.\nDuring the DNA & RNA blocks, we will have in-class exercises and discussion on Mon-Wed-Fri 9:00-10:30am.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#location",
    "href": "course-info/syllabus.html#location",
    "title": "MOLB 7950 Syllabus",
    "section": "Location",
    "text": "Location\nClasses will be held in-person in a variety of different rooms. Please check the schedule page to see each class’s room assignment. All classes will be recorded and made available through Canvas.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#policies",
    "href": "course-info/syllabus.html#policies",
    "title": "MOLB 7950 Syllabus",
    "section": "Policies",
    "text": "Policies\n\nAttendance\nClass attendance is a firm expectation; frequent absences or tardiness are considered cause for a grade reduction.\nif you are sick, please let us know (e-mail Srinivas and Matt) and STAY HOME.\nAnticipated absences outside of sickness should be reported to the instructors of a given block as soon as possible to make plans for possible accommodation.\nWe will record all lectures on Panopto and they will be available online through Canvas.\n\n\nLate and missed work\nWe have a late work policy for homework assignments:\n\nIf a problem set set is late but within 24 hours of due date/time, the grade will be reduced by 50%\nIf a problem set is returned any later, no credit will be given.\nAll regrade requests must be discussed with the professor within one week of receiving your grade. There will be no grade changes after the final project.\n\n\n\nDiversity & Inclusiveness\nOur view is that students from all diverse backgrounds and perspectives will be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class iss a resource, strength, and benefit.\n\n\nDisability Policy\nStudents with disabilities who need accommodations are encouraged to contact the Office of Disability, Access & Inclusion as soon as possible to ensure that accommodations are implemented in a timely fashion.\n\n\nHonor code\nAcademic dishonesty will not be tolerated and is grounds for dismissal from the class with a failing grade (“F”). For other information, please consult the Graduate Student Handbook.\nChatGPT will probably be able to answer most coding questions you ask of it. While it is useful for fleshing out an initial approach from pseudocode, we do not recommend using it, as these conceptual approaches are an essential foundation for buildling expertise in bioinformatic analysis.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#problem-sets",
    "href": "course-info/syllabus.html#problem-sets",
    "title": "MOLB 7950 Syllabus",
    "section": "Problem Sets",
    "text": "Problem Sets\n\nProblem sets will be assigned at the end of each class.\nYou can use external resources but must explicitly cite where you have obtained code (both code you used directly and “paraphrased” code / code used as inspiration). Any reused code that is not explicitly cited will be treated as plagiarism.\nYou can discuss the content of assignments with others in this class. If you do so, you must acknowledge your collaborator(s) at the top of your assignment, for example: “Collaborators: Hillary and Bernie”. Failure to acknowledge collaborators will result in a grade of 0. You may not copy code and/or answers directly from another student. If you copy other work, both parties will receive a grade of 0.\nThe problem set with the lowest score for each student will be dropped.\nRather than copying someone’s work, ask for help. You are not alone in this course!",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#professionalism",
    "href": "course-info/syllabus.html#professionalism",
    "title": "MOLB 7950 Syllabus",
    "section": "Professionalism",
    "text": "Professionalism\n\nPlease refrain from texting or using your computer for anything other than coursework during class.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#assignments-and-grading",
    "href": "course-info/syllabus.html#assignments-and-grading",
    "title": "MOLB 7950 Syllabus",
    "section": "Assignments and Grading",
    "text": "Assignments and Grading\nThe course measures learning through daily problem sets, a final project, and your participation.\n\n\n\nType\n% of grade\n\n\n\n\nProblem Sets\n60\n\n\nFinal Project\n20\n\n\nParticipation\n20\n\n\n\nGrades will be assigned as follows:\n\n\n\nPercent total points\nGrade\n\n\n\n\n&gt;= 95\nA\n\n\n&gt;= 90\nA-\n\n\n&gt;= 85\nB+\n\n\n&gt;= 80\nB\n\n\n\n\nProblem sets\nWe reinforce concepts with problem sets assigned at the end of class that should take ~60 minutes to complete.\nProblems sets assigned on Friday will be more substantial, requiring ~1-2 hours to complete.\nTogether the problem sets constitute 60% of your grade.\n\n\n\n\n\n\n\n\n\n\nAssigned\nDue\nGrades By\nWho grades\nTime to complete (approx)\n\n\n\n\nMon @ 12pm\nTues @ 5pm\nWed @ 5pm\nInstructors / TAs\n60 min\n\n\nTue @ 12pm\nWed @ 5pm\nThurs @ 5pm\nInstructors / TAs\n60 min\n\n\nWed @ 12pm\nThurs @ 5pm\nFri @ 5pm\nInstructors / TAs\n60 min\n\n\nThurs @ 12pm\nFri @ 5pm\nTues @ 5pm\nInstructors / TAs\n60 min\n\n\nFri @ 12pm\nMon @ 5pm\nWed @ 5pm\nInstructors / TAs\n1-2 hr\n\n\n\n\n\nFinal projects\nFinal projects can be completed in groups of 1-3 people. Projects will involve analysis of existing public data sets and end with a short presentation the last week of class. The final project constitutes 20% of your grade.\n\n\nGrading Rubrics\n\nProblem Set Rubric\nProblem sets are worth 60% of your grade. Values in parentheses represent point values for each level from 20 points total. This rubric will be assessed at the end of the semester.\n\n\n\n\n\n\n\n\n\nCriteria\nExpert\nCompetent\nNeeds Improvement\n\n\n\n\nCoding style\nStudent has gone beyond what was expected and required, coding manual is followed, code is well commented\nCoding style lacks refinement and has some errors, but code is readable and has some comments\nMany errors in coding style, little attention paid to making the code human readable\n\n\nCoding strategy\nComplicated problem broken down into sub-problems that are individually much simpler. Code is efficient, correct, and minimal. Code uses appropriate data structure (list, data frame, vector/matrix/array). Code checks for common errors\nCode is correct, but could be edited down to leaner code. Some “hacking” instead of using suitable data structure. Some checks for errors.\nCode tackles complicated problem in one big chunk. Code is repetitive and could easily be functionalized. No anticipation of errors.\n\n\nPresentation: graphs\nGraph(s) carefully tuned for desired purpose. One graph illustrates one point\nGraph(s) well chosen, but with a few minor problems: inappropriate aspect ratios, poor labels.\nGraph(s) poorly chosen to support questions.\n\n\nPresentation: tables\nTable(s) carefully constructed to make it easy to perform important comparisons. Careful styling highlights important features.\nTable(s) generally appropriate but possibly some minor formatting deficiencies.\nTable(s) with too many, or inconsistent, decimal places. Table(s) not appropriate for questions and findings. Major display problems.\n\n\nAchievement, mastery, cleverness, creativity\nStudent has gone beyond what was expected and required, e.g., extraordinary effort, additional tools not addressed by this course, unusually sophisticated application of tools from course.\nTools and techniques from the course are applied very competently and, perhaps,somewhat creatively. Chosen task was acceptable, but fairly conservative in ambition.\nStudent does not display the expected level of mastery of the tools and techniques in this course. Chosen task was too limited in scope.\n\n\nEase of access for instructor, compliance with course conventions for submitted work\nAccess as easy as possible, code runs!\nSatisfactory\nNot an earnest effort to reduce friction and comply with conventions and/or code does not run\n\n\n\n\n\nParticipation rubric\nAttendance & participation is worth 20% of your grade. Values in parentheses represent point values for each level from 20 points total. This rubric will be assessed at the end of the semester.\n\n\n\n\n\n\n\n\n\nCriteria\nExpert\nCompetent\nNeeds improvement\n\n\n\n\nAttendance (physically present for class, or coordinating with instructor when absent)\nAttends class regularly (5)\nAttends most classes (4)\nAttends some classes (0-3)\n\n\nPreparation (activities required for in-class participation, like surveys and software installation)\nCompletes requested activities prior to class (5)\nCompletes most requested activities prior to class, sometimes needs to finish during class (4)\nRarely completes requested activities prior to class, often takes class time to complete (0-3)\n\n\nEngagement (in-class activities like coding exercises and discussion)\nActively engages in class activities (10)\nSometimes engages in class activities (8)\nDoesn’t engage in class activities (0-7)",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#related-coursework",
    "href": "course-info/syllabus.html#related-coursework",
    "title": "MOLB 7950 Syllabus",
    "section": "Related coursework",
    "text": "Related coursework\nIn previous iterations of this course, we taught command-line (bash, grep, awk, etc) and Python programming. These skills are useful, but for consistency we opted to focus on R programming and RStudio as an analysis environment.\nAMC also offers shorter workshops on specific analysis strategies that you might find helpful.\n\nMOLB 7900: Practical Computational Biology for Biologists — Python (Taliaferro and Ramachandran)\nMOLB 7910: Practical Computational Biology for Biologists — R/R Studio (Jagannathan and Mukherjee)",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#acknowldgements-attribution",
    "href": "course-info/syllabus.html#acknowldgements-attribution",
    "title": "MOLB 7950 Syllabus",
    "section": "Acknowldgements & Attribution",
    "text": "Acknowldgements & Attribution\n\nInstructor contributions\nSeveral people have contributed to course development over the past several years.\n\nSujatha Jagannathan contributed the original R bootcamp material.\nSrinivas Ramachandran contributed material for the DNA block, including lecture material and examples for yeast chromatin accessibility and factor mapping.\nMatt Taliaferro contributed material for the RNA block, including lecture material and examples for RNA expression and splicing analysis.\nKent Riemondy and Kristen Wells contributed material for single-cell RNA sequencing.\nJay Hesselberth and Neel Mukherjee revamped much of this material in Fall 2023.\n\n\n\nExternal resources\nWe have borrowed from several (open licensed) resources for course content, including:\n\nStats 545 at UBC, particularly their grading rubrics\nCourses from Mine Çetinkaya-Rundel, particularly inspiration for quarto websites",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus.html#land-acknowledgement",
    "href": "course-info/syllabus.html#land-acknowledgement",
    "title": "MOLB 7950 Syllabus",
    "section": "Land acknowledgement",
    "text": "Land acknowledgement\nThe University of Colorado honors and recognizes the many contributions of Indigenous peoples in our state. The University of Colorado acknowledges that it is located on the traditional territories and ancestral homelands of the Cheyenne, Arapaho, Ute and many other Native American nations. Their forced removal from these territories has caused devastating and lasting impacts. While the University of Colorado can never undo or rectify the devastation wrought on Indigenous peoples, we commit to improving and enhancing engagement with Indigenous peoples and issues locally and globally.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/problem-sets.html",
    "href": "course-info/problem-sets.html",
    "title": "MOLB 7950 — Problem Sets",
    "section": "",
    "text": "We reinforce concepts with problem sets assigned at the end of each class. During the main blocks, problem sets on Mon and Wed should take ~60 minutes to complete. Problems sets assigned on Friday will be more substantial, requiring ~1-2 hours to complete. Together the problem sets constitute 60% of your grade.\n\n\n\nProblem sets are distributed as Posit Cloud assignments. You will work on problem sets in an Rmarkdown document in the assignment. When complete, complete your assignment by submitting the URL from your Posit Cloud assignment into the assignment submission on Canvas. We will grade your problem directly in the Posit Cloud assignment.\n\n\n\n\n\n\n\n\n\n\nAssigned\nDue\nGrades By\nWho grades\nTime to complete (approx)\n\n\n\n\nMon @ 12pm\nTues @ 5pm\nWed @ 5pm\nInstructors / TAs\n60 min\n\n\nTue @ 12pm\nWed @ 5pm\nThurs @ 5pm\nInstructors / TAs\n60 min\n\n\nWed @ 12pm\nThurs @ 5pm\nFri @ 5pm\nInstructors / TAs\n60 min\n\n\nThurs @ 12pm\nFri @ 5pm\nTues @ 5pm\nInstructors / TAs\n60 min\n\n\nFri @ 12pm\nMon @ 5pm\nWed @ 5pm\nInstructors / TAs\n1-2 hr\n\n\n\n\n\n\nProblem sets are worth 60% of your grade. Values in parentheses represent point values for each level from 20 points total. This rubric will be assessed at the end of the semester.\n\n\n\n\n\n\n\n\n\nCriteria\nExpert\nCompetent\nNeeds Improvement\n\n\n\n\nCoding style\nStudent has gone beyond what was expected and required, coding manual is followed, code is well commented\nCoding style lacks refinement and has some errors, but code is readable and has some comments\nMany errors in coding style, little attention paid to making the code human readable\n\n\nCoding strategy\nComplicated problem broken down into sub-problems that are individually much simpler. Code is efficient, correct, and minimal. Code uses appropriate data structure (list, data frame, vector/matrix/array). Code checks for common errors\nCode is correct, but could be edited down to leaner code. Some “hacking” instead of using suitable data structure. Some checks for errors.\nCode tackles complicated problem in one big chunk. Code is repetitive and could easily be functionalized. No anticipation of errors.\n\n\nPresentation: graphs\nGraph(s) carefully tuned for desired purpose. One graph illustrates one point\nGraph(s) well chosen, but with a few minor problems: inappropriate aspect ratios, poor labels.\nGraph(s) poorly chosen to support questions.\n\n\nPresentation: tables\nTable(s) carefully constructed to make it easy to perform important comparisons. Careful styling highlights important features.\nTable(s) generally appropriate but possibly some minor formatting deficiencies.\nTable(s) with too many, or inconsistent, decimal places. Table(s) not appropriate for questions and findings. Major display problems.\n\n\nAchievement, mastery, cleverness, creativity\nStudent has gone beyond what was expected and required, e.g., extraordinary effort, additional tools not addressed by this course, unusually sophisticated application of tools from course.\nTools and techniques from the course are applied very competently and, perhaps,somewhat creatively. Chosen task was acceptable, but fairly conservative in ambition.\nStudent does not display the expected level of mastery of the tools and techniques in this course. Chosen task was too limited in scope.\n\n\nEase of access for instructor, compliance with course conventions for submitted work\nAccess as easy as possible, code runs!\nSatisfactory\nNot an earnest effort to reduce friction and comply with conventions and/or code does not run",
    "crumbs": [
      "Assignments",
      "Problet Set Overview"
    ]
  },
  {
    "objectID": "course-info/problem-sets.html#problem-set-overview",
    "href": "course-info/problem-sets.html#problem-set-overview",
    "title": "MOLB 7950 — Problem Sets",
    "section": "",
    "text": "We reinforce concepts with problem sets assigned at the end of each class. During the main blocks, problem sets on Mon and Wed should take ~60 minutes to complete. Problems sets assigned on Friday will be more substantial, requiring ~1-2 hours to complete. Together the problem sets constitute 60% of your grade.\n\n\n\nProblem sets are distributed as Posit Cloud assignments. You will work on problem sets in an Rmarkdown document in the assignment. When complete, complete your assignment by submitting the URL from your Posit Cloud assignment into the assignment submission on Canvas. We will grade your problem directly in the Posit Cloud assignment.\n\n\n\n\n\n\n\n\n\n\nAssigned\nDue\nGrades By\nWho grades\nTime to complete (approx)\n\n\n\n\nMon @ 12pm\nTues @ 5pm\nWed @ 5pm\nInstructors / TAs\n60 min\n\n\nTue @ 12pm\nWed @ 5pm\nThurs @ 5pm\nInstructors / TAs\n60 min\n\n\nWed @ 12pm\nThurs @ 5pm\nFri @ 5pm\nInstructors / TAs\n60 min\n\n\nThurs @ 12pm\nFri @ 5pm\nTues @ 5pm\nInstructors / TAs\n60 min\n\n\nFri @ 12pm\nMon @ 5pm\nWed @ 5pm\nInstructors / TAs\n1-2 hr\n\n\n\n\n\n\nProblem sets are worth 60% of your grade. Values in parentheses represent point values for each level from 20 points total. This rubric will be assessed at the end of the semester.\n\n\n\n\n\n\n\n\n\nCriteria\nExpert\nCompetent\nNeeds Improvement\n\n\n\n\nCoding style\nStudent has gone beyond what was expected and required, coding manual is followed, code is well commented\nCoding style lacks refinement and has some errors, but code is readable and has some comments\nMany errors in coding style, little attention paid to making the code human readable\n\n\nCoding strategy\nComplicated problem broken down into sub-problems that are individually much simpler. Code is efficient, correct, and minimal. Code uses appropriate data structure (list, data frame, vector/matrix/array). Code checks for common errors\nCode is correct, but could be edited down to leaner code. Some “hacking” instead of using suitable data structure. Some checks for errors.\nCode tackles complicated problem in one big chunk. Code is repetitive and could easily be functionalized. No anticipation of errors.\n\n\nPresentation: graphs\nGraph(s) carefully tuned for desired purpose. One graph illustrates one point\nGraph(s) well chosen, but with a few minor problems: inappropriate aspect ratios, poor labels.\nGraph(s) poorly chosen to support questions.\n\n\nPresentation: tables\nTable(s) carefully constructed to make it easy to perform important comparisons. Careful styling highlights important features.\nTable(s) generally appropriate but possibly some minor formatting deficiencies.\nTable(s) with too many, or inconsistent, decimal places. Table(s) not appropriate for questions and findings. Major display problems.\n\n\nAchievement, mastery, cleverness, creativity\nStudent has gone beyond what was expected and required, e.g., extraordinary effort, additional tools not addressed by this course, unusually sophisticated application of tools from course.\nTools and techniques from the course are applied very competently and, perhaps,somewhat creatively. Chosen task was acceptable, but fairly conservative in ambition.\nStudent does not display the expected level of mastery of the tools and techniques in this course. Chosen task was too limited in scope.\n\n\nEase of access for instructor, compliance with course conventions for submitted work\nAccess as easy as possible, code runs!\nSatisfactory\nNot an earnest effort to reduce friction and comply with conventions and/or code does not run",
    "crumbs": [
      "Assignments",
      "Problet Set Overview"
    ]
  },
  {
    "objectID": "course-info/final-projects.html",
    "href": "course-info/final-projects.html",
    "title": "MOLB 7950 – Final Projects",
    "section": "",
    "text": "Please submit a short proposal for your final projects with the following information.\n\nthe names of people you are working with\na description of the data set you will be working worth. This can refer to a publication and/or contain a link to public data available at NCBI GEO.\na hypothesis (tentative) you will be testing\na few bullets on your planned analysis approach.\n\nPlease include this information in a quarto document in a new Posit cloud project.",
    "crumbs": [
      "Assignments",
      "Final Project Overview"
    ]
  },
  {
    "objectID": "course-info/final-projects.html#short-proposal",
    "href": "course-info/final-projects.html#short-proposal",
    "title": "MOLB 7950 – Final Projects",
    "section": "",
    "text": "Please submit a short proposal for your final projects with the following information.\n\nthe names of people you are working with\na description of the data set you will be working worth. This can refer to a publication and/or contain a link to public data available at NCBI GEO.\na hypothesis (tentative) you will be testing\na few bullets on your planned analysis approach.\n\nPlease include this information in a quarto document in a new Posit cloud project.",
    "crumbs": [
      "Assignments",
      "Final Project Overview"
    ]
  },
  {
    "objectID": "course-info/final-projects.html#overview",
    "href": "course-info/final-projects.html#overview",
    "title": "MOLB 7950 – Final Projects",
    "section": "Overview",
    "text": "Overview\n\nFinal projects can involve groups of 1-3 people.\n\nProjects are choose your own adventure:\n\nThe resource documents contain data sets in from human S. cerevisiae. For example, sub-nucleosomal fragments provide a DNA-based signal to understand chromatin transactions that lead to transcription.\nYou could find a data set on NCBI GEO of interest (e.g., relevant to your thesis work), and work it up with salmon, DEseq, and exploratory analysis. We are happy to help you work through the pseudo-alignment steps.\nYou can start with your own sequencing data (bulk/single-cell RNA seq, DNA sequencing).",
    "crumbs": [
      "Assignments",
      "Final Project Overview"
    ]
  },
  {
    "objectID": "course-info/final-projects.html#deliverables",
    "href": "course-info/final-projects.html#deliverables",
    "title": "MOLB 7950 – Final Projects",
    "section": "Deliverables",
    "text": "Deliverables\n\nA Quarto document with code, plots, interpretations, and next steps.\nIf you work in a group, list the members of the group at the top of the document, and make it clear which parts are your work by adding your initials to code chunks.\nShort presentations (5-8 minutes) by the groups the week of Nov 1. Presentations should include 1-2 slides of background, a hypothesis for the approach, code output (table or graph) that addresses the hypothesis, and one or more tests of the statistical significance of the observation.",
    "crumbs": [
      "Assignments",
      "Final Project Overview"
    ]
  },
  {
    "objectID": "course-info/final-projects.html#grading-and-rubric",
    "href": "course-info/final-projects.html#grading-and-rubric",
    "title": "MOLB 7950 – Final Projects",
    "section": "Grading and rubric",
    "text": "Grading and rubric\nThe final project will be worth 20% of your grade and we will use the grading scheme outlined in the grading rubric.\nEach individual in a group will be evaluated separately, so contributions must be clearly marked in the document, using e.g. using chunk labels:\n\n```{r}\n#| label: plotting-code-by-jay-h\n#| eval: false\n#| fig.alt: \"Description of the plot - PLEASE FILL IN\"\nggplot(mtcars, aes(hp, mpg)) +\n  geom_point()\n```",
    "crumbs": [
      "Assignments",
      "Final Project Overview"
    ]
  },
  {
    "objectID": "course-info/support.html",
    "href": "course-info/support.html",
    "title": "MOLB 7950 — Getting help",
    "section": "",
    "text": "Course discussion will be through the Slack MOLB7950 organization.\nGuidelines for using Slack:\n\nUse dedicated channels for discussion in #class, questions about your #problem-sets, and your #final-project\nYou can ask for help by tagging the TAs in the #class channel. If you post @ta help, someone will start a thread where you can ask a question.\nIf needed, we can talk face-to-face via the /zoom integration.\n\n\n\n\n\nOur TAs will be available Tues-Thurs afternoons from 1-2:30pm.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-info/support.html#how-to-get-help",
    "href": "course-info/support.html#how-to-get-help",
    "title": "MOLB 7950 — Getting help",
    "section": "",
    "text": "Course discussion will be through the Slack MOLB7950 organization.\nGuidelines for using Slack:\n\nUse dedicated channels for discussion in #class, questions about your #problem-sets, and your #final-project\nYou can ask for help by tagging the TAs in the #class channel. If you post @ta help, someone will start a thread where you can ask a question.\nIf needed, we can talk face-to-face via the /zoom integration.\n\n\n\n\n\nOur TAs will be available Tues-Thurs afternoons from 1-2:30pm.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-info/team.html",
    "href": "course-info/team.html",
    "title": "MOLB 7950 — Teaching Team",
    "section": "",
    "text": "TA office hours will be 1-2:30 PM on Tues and Thurs. Please coordinate with the TAs to determine whether you want to meet in person or virtually. You can also use slack to ask questions outside of office hours.\n\n\n\n\n\n\n\n\n\nInstructor\nE-mail\n\n\n\n\nNeel Mukherjee\n\n\n\nJay Hesselberth\n\n\n\nSrinivas Ramachandran\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstructor\nE-mail\n\n\n\n\nNathaly Limon de la Rosa\n\n\n\nIlin Joshi",
    "crumbs": [
      "Course information",
      "Teaching team"
    ]
  },
  {
    "objectID": "course-info/team.html#teaching-team-and-office-hours",
    "href": "course-info/team.html#teaching-team-and-office-hours",
    "title": "MOLB 7950 — Teaching Team",
    "section": "",
    "text": "TA office hours will be 1-2:30 PM on Tues and Thurs. Please coordinate with the TAs to determine whether you want to meet in person or virtually. You can also use slack to ask questions outside of office hours.\n\n\n\n\n\n\n\n\n\nInstructor\nE-mail\n\n\n\n\nNeel Mukherjee\n\n\n\nJay Hesselberth\n\n\n\nSrinivas Ramachandran\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstructor\nE-mail\n\n\n\n\nNathaly Limon de la Rosa\n\n\n\nIlin Joshi",
    "crumbs": [
      "Course information",
      "Teaching team"
    ]
  },
  {
    "objectID": "exercises/ex-02.html",
    "href": "exercises/ex-02.html",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "",
    "text": "Explore table1, table2, table3, table4a, table4b, and table5, which all display the number of TB cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000.\n\nR provides many functions to examine features of a data object\n\nView() - To open the table up in an excel-like interface - not recommended for large tables\nclass() - what kind of object is it (high-level)?\ntypeof() - what is the object’s data type (low-level)?\nis_tibble() - use is.? to confirm data type\nstr() - what is the structure of the object?\nattributes() - does it have any metadata?\nLet’s explore table1\n\nSome of the useful functions for data.frames / tibbles are as follows:\n\n\nhead() - shows first 6 rows\n\ntail() - shows last 6 rows\n\ndim() - returns the dimensions of data frame (i.e. number of rows and number of columns)\n\nnrow() - number of rows\n\nncol() - number of columns\n\nnames() or colnames() - both show the names attribute for a data frame\nglimpse()"
  },
  {
    "objectID": "exercises/ex-02.html#data-sets-for-tidying---exercise-2",
    "href": "exercises/ex-02.html#data-sets-for-tidying---exercise-2",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "",
    "text": "Explore table1, table2, table3, table4a, table4b, and table5, which all display the number of TB cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000."
  },
  {
    "objectID": "exercises/ex-02.html#getting-familiar-with-the-data---exercise-3",
    "href": "exercises/ex-02.html#getting-familiar-with-the-data---exercise-3",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "",
    "text": "R provides many functions to examine features of a data object\n\nView() - To open the table up in an excel-like interface - not recommended for large tables\nclass() - what kind of object is it (high-level)?\ntypeof() - what is the object’s data type (low-level)?\nis_tibble() - use is.? to confirm data type\nstr() - what is the structure of the object?\nattributes() - does it have any metadata?\nLet’s explore table1"
  },
  {
    "objectID": "exercises/ex-02.html#getting-familiar-with-the-data---exercise-4",
    "href": "exercises/ex-02.html#getting-familiar-with-the-data---exercise-4",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "",
    "text": "Some of the useful functions for data.frames / tibbles are as follows:\n\n\nhead() - shows first 6 rows\n\ntail() - shows last 6 rows\n\ndim() - returns the dimensions of data frame (i.e. number of rows and number of columns)\n\nnrow() - number of rows\n\nncol() - number of columns\n\nnames() or colnames() - both show the names attribute for a data frame\nglimpse()"
  },
  {
    "objectID": "exercises/ex-02.html#pivot_wider---exercise-6",
    "href": "exercises/ex-02.html#pivot_wider---exercise-6",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "pivot_wider - Exercise 6",
    "text": "pivot_wider - Exercise 6\nWhat will the output look like?\nIf you want to save the output, assign it to a new variable. This new variable will appear in your Environment tab."
  },
  {
    "objectID": "exercises/ex-02.html#pivot_longer---exercise-7",
    "href": "exercises/ex-02.html#pivot_longer---exercise-7",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "pivot_longer - Exercise 7",
    "text": "pivot_longer - Exercise 7\nWhat will the output look like?"
  },
  {
    "objectID": "exercises/ex-02.html#separate_wider_delim---exercise-8",
    "href": "exercises/ex-02.html#separate_wider_delim---exercise-8",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "separate_wider_delim - Exercise 8",
    "text": "separate_wider_delim - Exercise 8\nWhat will the output look like?\nseparate_rows - Exercise 9"
  },
  {
    "objectID": "exercises/ex-02.html#unite---exercise-10",
    "href": "exercises/ex-02.html#unite---exercise-10",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "unite - Exercise 10",
    "text": "unite - Exercise 10"
  },
  {
    "objectID": "exercises/ex-02.html#missing-values",
    "href": "exercises/ex-02.html#missing-values",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "Missing values",
    "text": "Missing values"
  },
  {
    "objectID": "exercises/ex-04.html#todays-datasets",
    "href": "exercises/ex-04.html#todays-datasets",
    "title": "R Bootcamp - Day 4",
    "section": "Today’s datasets",
    "text": "Today’s datasets\nIn this class, we will use a data set from ggplot2: diamonds contains thousands of gem prices and qualities.\nThere are many interesting data sets you can install as R packages for learning to manipulate and plot data:\n\nbabynames\ngapminder\npalmerpenguins"
  },
  {
    "objectID": "exercises/ex-04.html#getting-familiar-with-the-data---exercise-1",
    "href": "exercises/ex-04.html#getting-familiar-with-the-data---exercise-1",
    "title": "R Bootcamp - Day 4",
    "section": "Getting familiar with the data - Exercise 1",
    "text": "Getting familiar with the data - Exercise 1"
  },
  {
    "objectID": "exercises/ex-04.html#the-syntax-of-ggplot",
    "href": "exercises/ex-04.html#the-syntax-of-ggplot",
    "title": "R Bootcamp - Day 4",
    "section": "The syntax of ggplot()\n",
    "text": "The syntax of ggplot()"
  },
  {
    "objectID": "exercises/ex-04.html#making-a-plot-step-by-step-exercise-2",
    "href": "exercises/ex-04.html#making-a-plot-step-by-step-exercise-2",
    "title": "R Bootcamp - Day 4",
    "section": "Making a plot step-by-step (Exercise 2)",
    "text": "Making a plot step-by-step (Exercise 2)\n\nInitialize a plot with data.\nNext, specify the coordinate system.\nAdd a geom (geom_point).\nMap aesthetics to other variables.\n\nReduce overplotting by adjusting the transparency of points."
  },
  {
    "objectID": "exercises/ex-04.html#looking-under-the-hood-of-ggplot-exercise-3",
    "href": "exercises/ex-04.html#looking-under-the-hood-of-ggplot-exercise-3",
    "title": "R Bootcamp - Day 4",
    "section": "Looking under the hood of ggplot (Exercise 3)",
    "text": "Looking under the hood of ggplot (Exercise 3)"
  },
  {
    "objectID": "exercises/ex-04.html#ggplot-is-powerfully-simple-for-making-complex-plots",
    "href": "exercises/ex-04.html#ggplot-is-powerfully-simple-for-making-complex-plots",
    "title": "R Bootcamp - Day 4",
    "section": "ggplot is powerfully simple for making complex plots",
    "text": "ggplot is powerfully simple for making complex plots\nWhy can’t I just do this?"
  },
  {
    "objectID": "exercises/ex-04.html#geom-functions",
    "href": "exercises/ex-04.html#geom-functions",
    "title": "R Bootcamp - Day 4",
    "section": "Geom functions",
    "text": "Geom functions\n\nUse a geom function to represent data points, use the geom aesthetic properties to represent variables.\nEach function returns a plot layer.\nThere are many geoms in ggplot that are specific to plots with 1, 2, or 3 variables\n\nMake a bar plot.\n\nUpdate the bar plot aesthetics.\n\nChange to a density plot.\n\nColor the density plot.\n\nPlot subsets by mapping fill to cut\n\nUse ggridges to plot staggered subsets.\nhttps://wilkelab.org/ggridges/"
  },
  {
    "objectID": "exercises/ex-04.html#geom-functions-for-two-variables",
    "href": "exercises/ex-04.html#geom-functions-for-two-variables",
    "title": "R Bootcamp - Day 4",
    "section": "Geom functions for two variables",
    "text": "Geom functions for two variables\nMake a column plot.\nSame data with a box plot.\n\nBox plot, with fill color by cut.\nViolin plot with fill color by cut."
  },
  {
    "objectID": "exercises/ex-04.html#continuous-x-continuous-y---exercise-6",
    "href": "exercises/ex-04.html#continuous-x-continuous-y---exercise-6",
    "title": "R Bootcamp - Day 4",
    "section": "continuous x, continuous y - Exercise 6",
    "text": "continuous x, continuous y - Exercise 6\nSubset diamonds to see points more clearly.\nMake a scatter plot.\nNow add a smoothing line.\nHere we can combine geoms to see points & the fit"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MOLB 7950: Informatics and Statistics for Molecular Biology",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMOLB 7950 - Fall 2025 Schedule\n\n\nClasses held in-person from 9:00-10:30am in AHSB 2200\n\n\n\nDate\nBlock\nTopic\nInstructor\nTitle\n\nLinks\n\n\n\nPrepare\nSlides\nExercises\nHW\nKey\n\n\n\n\nWeek 1\n\n\n01\nMon, Aug 25, 2025\nBootcamp\nR\nHesselberth\nIntro to R & RStudio\n📖\n📄\n💪\n🧠\n🔑\n\n\n02\nTue, Aug 26, 2025\nBootcamp\nR\nHesselberth\nTidy data & tidyr\n📖\n📄\n💪\n🧠\n🔑\n\n\n03\nWed, Aug 27, 2025\nBootcamp\nR\nHesselberth\ndplyr\n📖\n📄\n💪\n.\n.\n\n\n04\nThu, Aug 28, 2025\nBootcamp\nR\nHesselberth\nggplot2\n📖\n📄\n💪\n.\n.\n\n\n05\nFri, Aug 29, 2025\nBootcamp\nR\nHesselberth\nggplot2\n.\n📄\n💪\n.\n.\n\n\nWeek 2\n\n\n06\nMon, Sep 1, 2025\n-\n-\n-\nNO CLASS - LABOR DAY\n.\n.\n.\n.\n.\n\n\n07\nTue, Sep 2, 2025\nBootcamp\nR\nHesselberth\ntidyverse odds & ends\n.\n.\n.\n.\n.\n\n\n08\nWed, Sep 3, 2025\nBootcamp\nR\nHesselberth\nputting it all together\n.\n.\n.\n.\n.\n\n\n09\nThu, Sep 4, 2025\nBootcamp\nR\nHesselberth\nputting it all together\n.\n.\n.\n.\n.\n\n\n10\nFri, Sep 5, 2025\nBootcamp\nStatistics\nMukherjee\nStats intro and history\n.\n.\n.\n.\n.\n\n\nWeek 3\n\n\n11\nMon, Sep 8, 2025\nBootcamp\nStatistics\nMukherjee\nProbability and descriptive stats\n.\n.\n.\n.\n.\n\n\n12\nTue, Sep 9, 2025\nBootcamp\nStatistics\nMukherjee\nHypothesis testing\n.\n.\n.\n.\n.\n\n\n13\nWed, Sep 10, 2025\nBootcamp\nStatistics\nMukherjee\nHypothesis testing\n.\n.\n.\n.\n.\n\n\n14\nThu, Sep 11, 2025\nBootcamp\nStatistics\nMukherjee\nExploratory data analysis\n.\n.\n.\n.\n.\n\n\n15\nFri, Sep 12, 2025\nBootcamp\nStatistics\nMukherjee\nBig data concerns\n.\n.\n.\n.\n.\n\n\nWeek 4\n\n\n16\nMon, Sep 15, 2025\nDNA\nMapping chromatin structure and transactions\nHesselberth\nExperimental overview\n.\n.\n.\n.\n.\n\n\n17\nWed, Sep 17, 2025\nDNA\nChromatin-centric methods\nHesselberth\nInformation from fragment length distributions\n.\n.\n.\n.\n.\n\n\n18\nFri, Sep 19, 2025\nDNA\nChromatin-centric methods\nHesselberth\nMeta-plots and heatmaps\n.\n.\n.\n.\n.\n\n\nWeek 5\n\n\n19\nMon, Sep 22, 2025\nDNA\nWhere do proteins bind in the genome?\nHesselberth\nExperimental overview\n.\n.\n.\n.\n.\n\n\n20\nWed, Sep 24, 2025\nDNA\nFactor-centric methods\nHesselberth\nPeak calling\n.\n.\n.\n.\n.\n\n\n21\nFri, Sep 26, 2025\nDNA\nFactor-centric methods\nHesselberth\nSequence motif analysis\n.\n.\n.\n.\n.\n\n\nWeek 6\n\n\n22\nMon, Sep 29, 2025\nRNA\nRNA-seq Overview\nMukherjee\nConcepts and techniques\n.\n.\n.\n.\n.\n\n\n23\nWed, Oct 1, 2025\nRNA\nImport, filtering, QC\nMukherjee\nmetrics and sample similarity\n.\n.\n.\n.\n.\n\n\n24\nFri, Oct 3, 2025\nRNA\nDifferential Gene Expression\nMukherjee\nDESeq2\n.\n.\n.\n.\n.\n\n\nWeek 7\n\n\n25\nMon, Oct 6, 2025\nRNA\nAlternative Splicing\nMukherjee\nrMATS\n.\n.\n.\n.\n.\n\n\n26\nWed, Oct 8, 2025\nRNA\nReview Proposals\nHesselberth\nReview Proposals\n.\n.\n.\n.\n.\n\n\n27\nFri, Oct 10, 2025\nRNA\nRBP-RNA 1\nMukherjee\nCLIP-seq\n.\n.\n.\n.\n.\n\n\nWeek 8\n\n\n28\nMon, Oct 13, 2025\nRNA\nRBP-RNA 2\nMukherjee\nData integrations\n.\n.\n.\n.\n.\n\n\n29\nWed, Oct 15, 2025\nRNA\nLong-read sequencing\nHesselberth\n-\n.\n.\n.\n.\n.\n\n\n30\nFri, Oct 17, 2025\n-\n-\n-\nNO CLASS: MOLB RETREAT\n.\n.\n.\n.\n.\n\n\nWeek 9\n\n\n31\nMon, Oct 20, 2025\nRNA\nSingle-cell\nWells-Wrasman\n-\n.\n.\n.\n.\n.\n\n\n32\nWed, Oct 22, 2025\nRNA\nSingle-cell\nWells-Wrasman\n-\n.\n.\n.\n.\n.\n\n\n33\nFri, Oct 24, 2025\n-\n-\n-\nNO CLASS: CSDV RETREAT\n.\n.\n.\n.\n.\n\n\nWeek 10\n\n\n34\nMon, Oct 27, 2025\nFinal\n-\n-\nFinal project presentations\n.\n.\n.\n.\n.\n\n\n35\nWed, Oct 29, 2025\nFinal\n-\n-\nFinal project presentations\n.\n.\n.\n.\n.",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "prepare/prepare-02.html",
    "href": "prepare/prepare-02.html",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look over the tidyr cheatsheet.\nWe’ll be using the pivot_*, separate(), and unite() functions, and discuss handling NA values. We won’t cover the nesting appproaches tomorrow so you can skip for now (skip the back page)."
  },
  {
    "objectID": "prepare/prepare-02.html#prepare",
    "href": "prepare/prepare-02.html#prepare",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look over the tidyr cheatsheet.\nWe’ll be using the pivot_*, separate(), and unite() functions, and discuss handling NA values. We won’t cover the nesting appproaches tomorrow so you can skip for now (skip the back page)."
  },
  {
    "objectID": "prepare/prepare-04.html",
    "href": "prepare/prepare-04.html",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look over the ggplot2 cheatsheet.\nWe’ll be using the basic ggplot2 structure with ggplot(), aes(), and various geom_*() functions like geom_point(), geom_bar(), and geom_histogram(). Pay special attention to the aesthetics section (color, size, shape) and the faceting functions facet_wrap() and facet_grid()."
  },
  {
    "objectID": "prepare/prepare-04.html#prepare",
    "href": "prepare/prepare-04.html#prepare",
    "title": "R Bootcamp",
    "section": "",
    "text": "Look over the ggplot2 cheatsheet.\nWe’ll be using the basic ggplot2 structure with ggplot(), aes(), and various geom_*() functions like geom_point(), geom_bar(), and geom_histogram(). Pay special attention to the aesthetics section (color, size, shape) and the faceting functions facet_wrap() and facet_grid()."
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html",
    "href": "problem-set-keys/ps-key-02.html",
    "title": "Problem Set 2 Key",
    "section": "",
    "text": "Each problem below is worth 4 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Aug 27.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html#problem-set",
    "href": "problem-set-keys/ps-key-02.html#problem-set",
    "title": "Problem Set 2 Key",
    "section": "",
    "text": "Each problem below is worth 4 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Aug 27.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html#question-1",
    "href": "problem-set-keys/ps-key-02.html#question-1",
    "title": "Problem Set 2 Key",
    "section": "Question 1",
    "text": "Question 1\nStart by loading the libraries you need for analysis below. When in doubt, start by loading the tidyverse package. You should also load here.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950\n\n\nNow import the dataset data_transcript_exp_subset using the readr package. Use read_csv() to import the file.\nThe file is located at data/data_transcript_exp_subset.csv.gz - use here() to create the complete path.\n\nx &lt;- read_csv(here(\"data/bootcamp/data_transcript_exp_subset.csv.gz\"))\n\nRows: 100 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): ensembl_transcript_id\ndbl (6): rna_0h_rep1, rna_0h_rep2, rna_0h_rep3, rna_14h_rep1, rna_14h_rep2, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html#question-2",
    "href": "problem-set-keys/ps-key-02.html#question-2",
    "title": "Problem Set 2 Key",
    "section": "Question 2",
    "text": "Question 2\nExplore the dataset. Is this dataset tidy? If not, why not?\nThis data frame is a subset (100 lines) of transcript-level gene expression data where transcript abundance was measured at two different time points of a certain treatment conducted in triplicates. The column names have the format of molecule_time_replicate\nFirst, explore the structure of the dataset using some of the functions we learned in class. Try using glimpse(), summary(), and names() to understand the data structure.\n\nx\n\n# A tibble: 100 × 7\n   ensembl_transcript_id        rna_0h_rep1 rna_0h_rep2 rna_0h_rep3 rna_14h_rep1\n   &lt;chr&gt;                              &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n 1 ENST00000327044.6_51_2298          243         322         303         177   \n 2 ENST00000338591.7_360_2034          19          17          15           9   \n 3 ENST00000379389.4_176_647           45          53          48          11   \n 4 ENST00000379370.6_1158_6186         42          50          52          32   \n 5 ENST00000379339.5_212_1352          17          19          25           3   \n 6 ENST00000263741.11_1328_1496        27.5        33.7        36.3        22.5 \n 7 ENST00000360001.10_285_1350        158         170.        171.        121   \n 8 ENST00000263741.11_315_1338        148.        162.        158.        116.  \n 9 ENST00000379198.3_138_1002          11          21          23           6   \n10 ENST00000347370.6_475_1096          27.3        23.8        28.5         7.33\n# ℹ 90 more rows\n# ℹ 2 more variables: rna_14h_rep2 &lt;dbl&gt;, rna_14h_rep3 &lt;dbl&gt;\n\n\n\n# Let's explore the data more systematically\n# Look at the column names\nnames(x)\n\n[1] \"ensembl_transcript_id\" \"rna_0h_rep1\"           \"rna_0h_rep2\"          \n[4] \"rna_0h_rep3\"           \"rna_14h_rep1\"          \"rna_14h_rep2\"         \n[7] \"rna_14h_rep3\"         \n\n\n\nsummary(x)\n\n ensembl_transcript_id  rna_0h_rep1       rna_0h_rep2        rna_0h_rep3      \n Length:100            Min.   :   0.00   Min.   :    0.00   Min.   :    0.00  \n Class :character      1st Qu.:  10.70   1st Qu.:   11.88   1st Qu.:   11.12  \n Mode  :character      Median :  27.41   Median :   31.05   Median :   31.91  \n                       Mean   : 173.31   Mean   :  196.08   Mean   :  186.10  \n                       3rd Qu.:  87.08   3rd Qu.:  105.00   3rd Qu.:   88.33  \n                       Max.   :9802.00   Max.   :11144.00   Max.   :10619.00  \n  rna_14h_rep1       rna_14h_rep2       rna_14h_rep3     \n Min.   :   0.000   Min.   :   0.000   Min.   :   0.000  \n 1st Qu.:   3.875   1st Qu.:   3.962   1st Qu.:   5.000  \n Median :  10.435   Median :   9.665   Median :   9.665  \n Mean   : 102.875   Mean   :  93.370   Mean   : 111.515  \n 3rd Qu.:  41.000   3rd Qu.:  38.750   3rd Qu.:  48.750  \n Max.   :5292.000   Max.   :5090.000   Max.   :6012.000  \n\n\n\nglimpse(x)\n\nRows: 100\nColumns: 7\n$ ensembl_transcript_id &lt;chr&gt; \"ENST00000327044.6_51_2298\", \"ENST00000338591.7_…\n$ rna_0h_rep1           &lt;dbl&gt; 243.00, 19.00, 45.00, 42.00, 17.00, 27.50, 158.0…\n$ rna_0h_rep2           &lt;dbl&gt; 322.00, 17.00, 53.00, 50.00, 19.00, 33.67, 169.6…\n$ rna_0h_rep3           &lt;dbl&gt; 303.00, 15.00, 48.00, 52.00, 25.00, 36.33, 171.3…\n$ rna_14h_rep1          &lt;dbl&gt; 177.00, 9.00, 11.00, 32.00, 3.00, 22.50, 121.00,…\n$ rna_14h_rep2          &lt;dbl&gt; 177.00, 5.00, 5.00, 31.00, 0.00, 29.17, 124.17, …\n$ rna_14h_rep3          &lt;dbl&gt; 239.00, 8.00, 14.00, 30.00, 2.00, 27.33, 155.33,…\n\n\nComment on whether this dataset is tidy, and if not, list the reasons why.\nHint: In a tidy dataframe, every column represents a single variable and every row represents a single observation\nAnswer\nIt is not tidy because: 1. The time points and replicates are not in their own columns 2. Multiple variables (molecule type, time, replicate) are encoded in column names 3. Each row contains multiple observations (different time points and replicates)"
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html#question-3",
    "href": "problem-set-keys/ps-key-02.html#question-3",
    "title": "Problem Set 2 Key",
    "section": "Question 3",
    "text": "Question 3\nHow will you reshape the data frame so that each row has only one experimental observation?\nBefore we reshape, let’s think about what we want:\n\nWhich column should stay the same? (The transcript ID)\nWhich columns contain the measurements? (All the others)\nWhat should we call the new column names?\n\nUse pivot_longer() to reshape the data. You’ll want to:\n\nKeep the ensembl_transcript_id column as-is (use cols = -ensembl_transcript_id)\nCreate a new column for the condition names (use names_to = \"condition\")\nCreate a new column for the values (use values_to = \"count\")\n\n\n# Reshape the data so each row is one observation\nx_long &lt;-\n  pivot_longer(\n    x,\n    cols = -ensembl_transcript_id, # everything except the ID column\n    names_to = \"condition\", # new column for the condition names\n    values_to = \"count\" # new column for the count values\n  )\n\nx_long\n\n# A tibble: 600 × 3\n   ensembl_transcript_id      condition    count\n   &lt;chr&gt;                      &lt;chr&gt;        &lt;dbl&gt;\n 1 ENST00000327044.6_51_2298  rna_0h_rep1    243\n 2 ENST00000327044.6_51_2298  rna_0h_rep2    322\n 3 ENST00000327044.6_51_2298  rna_0h_rep3    303\n 4 ENST00000327044.6_51_2298  rna_14h_rep1   177\n 5 ENST00000327044.6_51_2298  rna_14h_rep2   177\n 6 ENST00000327044.6_51_2298  rna_14h_rep3   239\n 7 ENST00000338591.7_360_2034 rna_0h_rep1     19\n 8 ENST00000338591.7_360_2034 rna_0h_rep2     17\n 9 ENST00000338591.7_360_2034 rna_0h_rep3     15\n10 ENST00000338591.7_360_2034 rna_14h_rep1     9\n# ℹ 590 more rows\n\n\nQuestion 4\nHow will you modify the dataframe so that multiple variables are not present in a single column?\nUse separate_wider_delim() to split the condition column into separate variables. You need to:\n\nSpecify which column to separate (condition)\nSpecify the delimiter character (delim = \"_\")\nProvide the new column names (names = c(\"molecule\", \"timepoint\", \"replicate\"))\n\n\nx_tidy &lt;-\n  separate_wider_delim(\n    x_long,\n    condition,\n    delim = \"_\",\n    names = c(\"molecule\", \"timepoint\", \"replicate\")\n  )\n\nx_tidy\n\n# A tibble: 600 × 5\n   ensembl_transcript_id      molecule timepoint replicate count\n   &lt;chr&gt;                      &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;\n 1 ENST00000327044.6_51_2298  rna      0h        rep1        243\n 2 ENST00000327044.6_51_2298  rna      0h        rep2        322\n 3 ENST00000327044.6_51_2298  rna      0h        rep3        303\n 4 ENST00000327044.6_51_2298  rna      14h       rep1        177\n 5 ENST00000327044.6_51_2298  rna      14h       rep2        177\n 6 ENST00000327044.6_51_2298  rna      14h       rep3        239\n 7 ENST00000338591.7_360_2034 rna      0h        rep1         19\n 8 ENST00000338591.7_360_2034 rna      0h        rep2         17\n 9 ENST00000338591.7_360_2034 rna      0h        rep3         15\n10 ENST00000338591.7_360_2034 rna      14h       rep1          9\n# ℹ 590 more rows\n\n\nQuestion 5\nHow will you save your output as a TSV file?\nUse write_tsv() from the readr package to save your tidy data. Provide the data object and a filename.\nHint: Use the readr cheatsheet at the bottom of this page to figure this out.\nAfter running your new code, you should have a new file called transcripts.tidy.tsv in your working directory.\n\nwrite_tsv(x_tidy, \"transcripts.tidy.tsv\")\n\nQuestion 6\nCan you reverse the process? How would you go from tidy back to wide format?\nUse pivot_wider() to go from the tidy format back to the original wide format. You need to:\n\nSpecify where the new column names come from (names_from = c(molecule, timepoint, replicate))\nSpecify where the values come from (values_from = count)\nSpecify how to combine the names (names_sep = \"_\")\n\n\n# Going back to wide format\npivot_wider(\n  x_tidy,\n  names_from = c(molecule, timepoint, replicate),\n  values_from = count,\n  names_sep = \"_\"\n)\n\n# A tibble: 100 × 7\n   ensembl_transcript_id        rna_0h_rep1 rna_0h_rep2 rna_0h_rep3 rna_14h_rep1\n   &lt;chr&gt;                              &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n 1 ENST00000327044.6_51_2298          243         322         303         177   \n 2 ENST00000338591.7_360_2034          19          17          15           9   \n 3 ENST00000379389.4_176_647           45          53          48          11   \n 4 ENST00000379370.6_1158_6186         42          50          52          32   \n 5 ENST00000379339.5_212_1352          17          19          25           3   \n 6 ENST00000263741.11_1328_1496        27.5        33.7        36.3        22.5 \n 7 ENST00000360001.10_285_1350        158         170.        171.        121   \n 8 ENST00000263741.11_315_1338        148.        162.        158.        116.  \n 9 ENST00000379198.3_138_1002          11          21          23           6   \n10 ENST00000347370.6_475_1096          27.3        23.8        28.5         7.33\n# ℹ 90 more rows\n# ℹ 2 more variables: rna_14h_rep2 &lt;dbl&gt;, rna_14h_rep3 &lt;dbl&gt;"
  },
  {
    "objectID": "problem-sets/ps-02.html",
    "href": "problem-sets/ps-02.html",
    "title": "Problem Set 2 Key",
    "section": "",
    "text": "Each problem below is worth 4 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Aug 27.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-sets/ps-02.html#problem-set",
    "href": "problem-sets/ps-02.html#problem-set",
    "title": "Problem Set 2 Key",
    "section": "",
    "text": "Each problem below is worth 4 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Aug 27.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-sets/ps-02.html#question-1",
    "href": "problem-sets/ps-02.html#question-1",
    "title": "Problem Set 2 Key",
    "section": "Question 1",
    "text": "Question 1\nStart by loading the libraries you need for analysis below. When in doubt, start by loading the tidyverse package. You should also load here.\n\nlibrary(___)\nlibrary(___)\n\nNow import the dataset data_transcript_exp_subset using the readr package. Use read_csv() to import the file.\nThe file is located at data/data_transcript_exp_subset.csv.gz - use here() to create the complete path.\n\nexp_tbl &lt;- read_csv(___)\n\nexp_tbl"
  },
  {
    "objectID": "problem-sets/ps-02.html#question-2",
    "href": "problem-sets/ps-02.html#question-2",
    "title": "Problem Set 2 Key",
    "section": "Question 2",
    "text": "Question 2\nExplore the dataset. Is this dataset tidy? If not, why not?\nThis data frame is a subset (100 lines) of transcript-level gene expression data where transcript abundance was measured at two different time points of a certain treatment conducted in triplicates. The column names have the format of molecule_time_replicate\nFirst, explore the structure of the dataset using some of the functions we learned in class. Try using glimpse(), summary(), and names() to understand the data structure.\nAdd more code chunks as needed to separate the different steps of your exploration.\n\nx\n\n\nnames(x)\n\nComment on whether this dataset is tidy, and if not, list the reasons why.\nHint: In a tidy dataframe, every column represents a single variable and every row represents a single observation\nAnswer\n[YOUR ANSWER HERE]"
  },
  {
    "objectID": "problem-sets/ps-02.html#question-3",
    "href": "problem-sets/ps-02.html#question-3",
    "title": "Problem Set 2 Key",
    "section": "Question 3",
    "text": "Question 3\nHow will you reshape the data frame so that each row has only one experimental observation?\nBefore we reshape, let’s think about what we want:\n\nWhich column should stay the same? (The transcript ID)\nWhich columns contain the measurements? (All the others)\nWhat should we call the new column names?\n\nUse pivot_longer() to reshape the data. You’ll want to:\n\nKeep the ensembl_transcript_id column as-is (cols)\nCreate a new column for the condition names (names_to)\nCreate a new column for the values (values_to)\n\n\n# Reshape the data so each row is one observation\nexp_tbl_long &lt;-\n  pivot_longer(\n    x,\n    cols = ___,\n    names_to = ___,\n    values_to = ___\n  )\n\nexp_tbl_long\n\nQuestion 4\nHow will you modify the dataframe so that multiple variables are not present in a single column?\nUse separate_wider_delim() to split the condition column into separate variables. You need to:\n\nSpecify which column to separate (cols)\nSpecify the delimiter character (delim)\nProvide the new column names (names)\n\n\nexp_tbl_tidy &lt;-\n  separate_wider_delim(\n    exp_tbl_long,\n    cols = ___,\n    delim = ___,\n    names = ___\n  )\n\nexp_tbl_tidy\n\nQuestion 5\nHow will you save your output as a TSV file?\nUse write_tsv() from the readr package to save your tidy data. Provide the data object and a filename.\nHint: Use the readr cheatsheet at the bottom of this page to figure this out.\nAfter running your new code, you should have a new file called transcripts.tidy.tsv in your working directory.\n\nwrite_tsv(exp_tbl_tidy, \"transcripts.tidy.tsv\")\n\nQuestion 6\nCan you reverse the process? How would you go from tidy back to wide format?\nUse pivot_wider() to go from the tidy format back to the original wide format. You need to:\n\nSpecify where the new column names come from (names_from)\nSpecify where the values come from (values_from)\nSpecify how to combine the names (names_sep)\n\n\npivot_wider(\n  exp_tbl_tidy,\n  names_from = ___,\n  values_from = ___,\n  names_sep = ___\n)\n\nAfter this, your new data should look like the original tibble you started with."
  },
  {
    "objectID": "resources/block-rna-resources.html",
    "href": "resources/block-rna-resources.html",
    "title": "Resources for the RNA block",
    "section": "",
    "text": "These studies below laid the methodological groundwork for RNA-sequencing, ribosome profiling, and mapping binding sites of RNA-binding proteins using UV-crosslinking based approaches (CLIP-seq/PAR-CLIP).\n\n\nMortazavi A, Williams BA, McCue K, Schaeffer L, Wold B. Mapping and quantifying mammalian transcriptomes by RNA-Seq. Nat Methods. 2008 Jul;5(7):621-8. doi: 10.1038/nmeth.1226. Epub 2008 May 30. PMID: 18516045. [Link]\n\n\n\nIngolia NT, Ghaemmaghami S, Newman JR, Weissman JS. Genome-wide analysis in vivo of translation with nucleotide resolution using ribosome profiling. Science. 2009 Apr 10;324(5924):218-23. doi: 10.1126/science.1168978. Epub 2009 Feb 12. PMID: 19213877; PMCID: PMC2746483.[Link]\n\n\n\nUle J, Jensen KB, Ruggiu M, Mele A, Ule A, Darnell RB. CLIP identifies Nova-regulated RNA networks in the brain. Science. 2003 Nov 14;302(5648):1212-5. doi: 10.1126/science.1090095. PMID: 14615540. [Link]\nHafner M, Landthaler M, Burger L, Khorshid M, Hausser J, Berninger P, Rothballer A, Ascano M Jr, Jungkamp AC, Munschauer M, Ulrich A, Wardle GS, Dewell S, Zavolan M, Tuschl T. Transcriptome-wide identification of RNA-binding protein and microRNA target sites by PAR-CLIP. Cell. 2010 Apr 2;141(1):129-41. doi: 10.1016/j.cell.2010.03.009. PMID: 20371350; PMCID: PMC2861495. [Link]",
    "crumbs": [
      "Resources",
      "RNA Block resources"
    ]
  },
  {
    "objectID": "resources/block-rna-resources.html#foundational-work",
    "href": "resources/block-rna-resources.html#foundational-work",
    "title": "Resources for the RNA block",
    "section": "",
    "text": "These studies below laid the methodological groundwork for RNA-sequencing, ribosome profiling, and mapping binding sites of RNA-binding proteins using UV-crosslinking based approaches (CLIP-seq/PAR-CLIP).\n\n\nMortazavi A, Williams BA, McCue K, Schaeffer L, Wold B. Mapping and quantifying mammalian transcriptomes by RNA-Seq. Nat Methods. 2008 Jul;5(7):621-8. doi: 10.1038/nmeth.1226. Epub 2008 May 30. PMID: 18516045. [Link]\n\n\n\nIngolia NT, Ghaemmaghami S, Newman JR, Weissman JS. Genome-wide analysis in vivo of translation with nucleotide resolution using ribosome profiling. Science. 2009 Apr 10;324(5924):218-23. doi: 10.1126/science.1168978. Epub 2009 Feb 12. PMID: 19213877; PMCID: PMC2746483.[Link]\n\n\n\nUle J, Jensen KB, Ruggiu M, Mele A, Ule A, Darnell RB. CLIP identifies Nova-regulated RNA networks in the brain. Science. 2003 Nov 14;302(5648):1212-5. doi: 10.1126/science.1090095. PMID: 14615540. [Link]\nHafner M, Landthaler M, Burger L, Khorshid M, Hausser J, Berninger P, Rothballer A, Ascano M Jr, Jungkamp AC, Munschauer M, Ulrich A, Wardle GS, Dewell S, Zavolan M, Tuschl T. Transcriptome-wide identification of RNA-binding protein and microRNA target sites by PAR-CLIP. Cell. 2010 Apr 2;141(1):129-41. doi: 10.1016/j.cell.2010.03.009. PMID: 20371350; PMCID: PMC2861495. [Link]",
    "crumbs": [
      "Resources",
      "RNA Block resources"
    ]
  },
  {
    "objectID": "resources/block-rna-resources.html#software",
    "href": "resources/block-rna-resources.html#software",
    "title": "Resources for the RNA block",
    "section": "Software",
    "text": "Software\n\nAlignment software\nSTAR and minimap2 are popular choices for short read alignment. They are fast, free, and well-maintained.\n\n\nTranscript Quantification\nSalmon is a pseuodoalignment based approach for quantifying transcripts from RNA-seq data. See the salmon documentation and documentation for importing salmon data into R using txipmort\n\n\nPeak calling\nPARalyzer is the gold-standard in peak calling for PAR-CLIP data. It models read coverage and nucleotide conversions using a kernel density estimate classification to generate a high-resolution map of RNA-protein interaction sites.",
    "crumbs": [
      "Resources",
      "RNA Block resources"
    ]
  }
]